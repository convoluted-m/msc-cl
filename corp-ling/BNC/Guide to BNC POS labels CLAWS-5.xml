<div xml:id="posguide"><head> Wordclass Tagging in BNC XML</head>

<p>This section is a revised version of the <title>Manual to accompany
The British National Corpus (Version 2) with Improved Word-class
Tagging</title> by Geoffrey Leech and Nicholas Smith, originally
distributed in HTML form with the BNC World Edition, and available
from the BNC Website at <ptr
target="http://www.natcorp.ox.ac.uk/docs/bnc2postag_manual.htm"/>.</p>

<div xml:id="overview"><head>Introduction</head>

<p>The wordclass tagging<note place="foot">The terms "POS-tagging" and
"wordclass tagging" are used interchangeably in this manual.</note>
has not changed significantly between the BNC World edition (2001) and
the BNC XML edition (2006). In particular, no attempt has been made to
completely retag the corpus, desirable though this might be.  Changes
have been made in the treatment of multiword units and some additional
annotation has been provided (see <ptr target="#extra-annot"/> , but
in most respects the wordclass information provided by the corpus now
is identical to that provided with the first release of the BNC in
1994.
  </p>

 <p> The BNC is wordclass-tagged using a set of 57 tags (known as C5)
 which we refer to as the "BNC Basic Tagset". (There are also 4
 punctuation tags, excluded from consideration here.) Each C5 tag
 represents a grammatical class of words represented by a three
 character code such as <code>NN1</code> for
 "singular common noun". The codes are, in many cases, mnemonic.</p>

<!-- <p>
 Additionally, a two-million-word subcorpus of the BNC, the "Sampler
 Corpus", was tagged using a richer, more detailed tagset (known as
 C7) which we refer to as the "BNC Enriched Tagset". This Sampler
 Corpus is distributed independently of the whole BNC. The tagging of
 the Sampler Corpus has been thoroughly corrected by manual
 post-editing of the automatic tagging, and may be assumed to be
 almost error-free.</p>
 -->
<p>The BNC, consisting of c.100 million words, was tagged
automatically, using the CLAWS4 automatic tagger developed by Roger
Garside at Lancaster, and a second program, known as Template Tagger,
developed by Mike Pacey and Steve Fligelstone. Further details are given <ref
target="#prog">below</ref>, and also in <ref target="#refs">Garside
and Leech 1997</ref>
chapters 7-9.  With such a large corpus, there was no opportunity to
undertake post-editing<note place="foot">The only exceptions to this
statement are: (i) the file F9M, which contains the Rap poetry "City
Psalms" by Benjamin Zephaniah. It was thoroughly hand-corrected
because the tagger, not familiar with Jamaican Creole, had produced an
inordinate number of tagging errors. (ii) files identified as
containing many foreign and classical expressions, as mentioned <ref
target="#overview">above</ref>. </note> i.e. disambiguation and
correction of tagging errors produced by the automatic tagger, and so
the errors (about 1.15 per cent of all words) remain. In addition, 
the corpus contains ambiguous taggings (c.3.75 per cent of all words),
shown in the form of ambiguity tags (also called ‘portmanteau tags’),
consisting of two C5 tags linked by a hyphen:
e.g. <code>VVD-VVN</code>. These tags indicate that the automatic
tagger was unable to determine, with sufficient confidence, which was
the correct category, and so left two possibilities for users to
disambiguate themselves, if they should wish to do so. For example, in
the case of <code>VVD-VVN</code>, the first (more likely) tag, say for a word such as
<hi rend="italic">wanted</hi>, is <code>VVD</code>: past tense of lexical verb; and the second (less
likely) tag is <code>VVN</code>: past participle of lexical verb. On the whole,
the likelihood of the first tag of an ambiguity tag being correct is
better than 3 to 1 — see, however, details of individual tags in <ptr
target="#table-1"/> of the error report document.  </p>

<p> After the automatic tagging, some manual tagging was undertaken to
correct some particularly blatant errors, mainly foreign or classical
words embedded in English text. CLAWS is not very successful at
detecting these foreign words and tagging them with their appropriate
tag (UNC), except when they form part of established expressions such
as <hi rend="italic">ad hoc</hi> or <hi rend="italic">nom de plume</hi> - in which case they are
normally given tags appropriate to their grammatical function, e.g. as
nouns or adverbs.  </p><p> The main purpose of the <ref
target="#errorRates">report on estimated error rates</ref> is to
document the rather small percentage of ambiguities and errors
remaining in the tagged BNC, so that users of the corpus can assess
the accuracy of the tagging for their own purposes. Since not
surprisingly we have been unable to inspect each of the 100 million
tags in the BNC, we have had to estimate ambiguity rates and error
rates on the basis of a manual post-editing of a corpus sample of
50,000 words. The estimate is based on twenty-four 2,000-word text
extracts and two 1,000-word extracts, selected so as to be as far as
possible representative of the whole corpus. <!--(The texts from which
these extracts are taken are listed in an <ref
target="#appendix">Appendix to the error report</ref>. Like the BNC as
a whole, the sample for manual analysis contains 10 per cent of spoken
data.)--></p>
 </div>

 <div xml:id="tokenization"><head>Tokenization: splitting the text into words</head>

 <p>Regarding the segmentation of a text into individual word-tokens
 (called tokenization), our tagging practice in general follows the
 default assumption that an orthographic word (separated by spaces from adjacent words,
 with or without punctuation) is the appropriate
 unit for wordclass tagging. There are, however, exceptions to
 this. For example, a single orthographic word may consist of more
 than one grammatical word: in the case of enclitic verb contractions
 (as in <hi rend="italic">she’s, they’ll, we’re</hi>) and negative contractions (as
 in <hi rend="italic">don’t, isn’t, won’t</hi>), it is appropriate to assign two
 diferent wordclass tags to the same orthographic word.  A full list
 of such contracted forms recognized by CLAWS and preserved in the XML
 markup is given in section <ptr target="#defrobs"/>.
 </p>

<p>Also quite frequent is the opposite circumstance, where two or more
orthographic words are given a single wordclass tag: e.g. multiword
adverbs such as <hi rend="italic">of course</hi> and <hi rend="italic">in short</hi>, and
multiword prepositions such as <hi rend="italic">instead of</hi> and <hi rend="italic">up to</hi>
are each assigned a single word tag (<code>AV0</code> for adverbs,
<code>PRP</code> for prepositions). Sometimes, whether such
orthographic sequences are to be treated as a single word for tagging
purposes depends on the context and its interpretation. <hi rend="italic">In
short</hi> is in some circumstances not an adverb but a sequence of
preposition + adjective (eg. <hi rend="italic">in short sharp bursts</hi> ). <hi rend="italic">Up
to</hi> in some contexts needs to be treated as a sequence of two
grammatical words: adverbial-particle +
preposition-or-infinitive-marker (eg. <hi rend="italic">We had to phone her up to
get the code.</hi>). </p> 

<p>In the BNC XML edition, these multiword
units are marked using an additional XML element (<gi>mw</gi>) which
carries the wordclass assigned to the whole sequence. Within the
<gi>mw</gi> element, the individual orthographic words are also
marked, using the <gi>w</gi> element in the same way as elsewhere. For
example, the multiword unit <hi rend="italic">of course</hi> is marked up as
follows: 

<eg><![CDATA[<mw c5="AV0"> 
  <w c5="PRF" hw="of" pos="PREP">of </w> 
  <w c5="NN1" hw="course" pos="SUBST">course </w>
</mw>]]></eg>. Wordclass tags for the constituent tags of multiword
units were automatically inserted using the table reproduced in <ptr
target="#defrobs"/>; there may therefore be residual
errors in their usage.</p>

 <p> In one respect, we have allowed the orthographic occurrence of
 spaces to be criterial. This is in the tagging of compound words such
 as <hi rend="italic">markup, mark-up</hi> and <hi rend="italic">mark up</hi>. Since English
 orthographic practice is often variable in such matters, the same
 ‘compound’ expression may occur in the corpus tagged as two words (if
 they are separated by spaces) or as one word (if the sequence is
 printed solid or with a hyphen). Thus <hi rend="italic">mark up</hi> (as a noun)
 will be tagged <code>NN1 AVP</code>, whereas <hi rend="italic">markup</hi> or
 <hi rend="italic">mark-up</hi> will be tagged simply <code>NN1</code>. </p>

 </div>

 <div xml:id="guide"><head>Tagging Guidelines and Borderline
 Cases</head> <p>Many detailed decisions have to be made in deciding
 how to draw the line between the correct and the incorrect assignment
 of a tag. So that the concept of what is a ‘correct’ or ‘accurate’
 annotation can be determined, there have to be detailed guidelines of
 tagging practice. These are constitute the <ref
 target="#guidelines">Wordclass Tagging Guidelines</ref>. </p>

<p>The
 Guidelines have to give much attention to borderline phenomena, where
 the distinction between (say) an adjective and a verb participle in
 -ing is unclear, and to clarify criteria for differentiating them.
 To promote consistency of tagging practice, the guidelines may even
 impose somewhat arbitrary dividing lines between one word class and
 another. Consider the case of a word such as <hi rend="italic">setting</hi>, which may be a
 present participle form of a verb(<code>VVG</code>), an adjective (<code>AJ0</code>) or a singular
 common noun (<code>NN1</code>). The difference may be illustrated by the three
 examples:
 <list>
 <item>
 Oil prices are <hi rend="italic">rising</hi> again. (verb, <code>VVG</code>)</item>
 <item>
 the <hi rend="italic">rising</hi> sun (adjective, <code>AJ0</code>)</item>
 <item>
 the attempted <hi rend="italic">rising</hi> was put down (noun, <code>NN1</code>)</item>
 </list></p>
 
<p> The assignment of an example of ‘Verb+ing’ to the adjective
category relies heavily on a semantic criterion, viz.  the ability to
paraphrase Verb+ing Noun by ‘Noun + Relative Clause that/which/who be
Verb+ing’ or ‘that/which/who Verb(s)’ (e.g. <hi rend="italic">the
rising sun</hi> = the sun which is/was rising; <hi rend="italic">a
working mother</hi> = a mother who works). These contrast with a case
such as <hi rend="italic">dining table</hi>, where the first word <hi
rend="italic">dining</hi> is judged to be a noun. The reason for this
is that the paraphrasable meaning of the expression is not ‘a table
which is/was dining or dines’, but rather ‘a table (used) for
dining’. Although somewhat arbitrary, this relative clause test is
well established in English grammatical literature, and such criteria
are useful in enabling a reasonable degree of consistency in tagging
practice to be achieved, so that the success rate of corpus tagging
can be checked and evaluated. (See further <ptr target="#m3adj-nn"/>)
 </p>
<p>
 It also has to be recognized that some borderline cases may
 occasionally have to be considered unresolvable. We may conclude, for
 example, that the word <hi rend="italic">Hatching</hi> (occurring as
 a heading on its own, without any syntactic context) could be equally
 well analysed <code>VVG</code> or <code>NN1</code>, and in such a case one would
 be tempted to leave the ambiguity (<code>VVG-NN1</code>) in the
 corpus, showing uncertainty where any grammarian would be likely to
 acknowledge it. However, in our calculations of ambiguity, we have
 adhered to the common assumption that ideally, all tags should be
 correctly disambiguated. Other examples of unresolvability from the
 sample texts are:
 <list>
 <item>
 the importance of <hi rend="italic">weaving</hi> in the East (verb or noun? - <code>VVG-NN1</code>)</item>
 <item>
  <hi rend="italic">Armed</hi> with the knowledge (past participle verb or adjective? - <code>VVN-AJ0</code>)</item>
 <item>the <hi rend="italic">Lord</hi> is my shepherd (common noun or proper noun? - <code>NN1-NP0</code>)</item></list>
 </p><p>
 In practice, in our post-edited sample, we chose the first tag to be correct in these cases. </p></div>

 <div xml:id="ambiguity"><head>Ambiguity tags, and the principle of asymmetry</head>
 <p>As in the first version of the BNC, we have introduced only a limited number of ambiguity tags, to deal with 
  particular cases where the tagger has difficulty in distinguishing two categories, and where incorrect taggings 
  would otherwise result rather frequently. Ambiguity tags involve only the following 18 wordclass labels, and each of the ambiguity tags allows only two labels to be named:
 <list>
 <item><code>AJ0</code> general adjective (positive)</item>
 <item><code>AV0</code> general adverb</item>
 <item><code>AVP</code> adverbial particle 	</item>
 <item><code>AVQ</code> wh- adverb</item>
 <item><code>CJS</code> general subordinator</item>
 <item><code>CJT</code> subordinator: that 	</item>
 <item><code>CRD</code> cardinal numeral </item>
 <item><code>DT0</code> determiner-pronoun</item>
 <item><code>NN1</code> singular common noun</item> 
 <item><code>NN2</code> plural common noun	</item>
 <item><code>NP0</code> proper noun	</item>
 <item><code>PNI</code> indefinite pronoun</item>
 <item><code>PRP</code> general preposition</item>
 <item><code>VVB</code> lexical verb: finite base form</item>
 <item><code>VVD</code> lexical verb: past tense;</item>
 <item><code>VVG</code> lexical verb: present participle (-ing form)</item>
 <item><code>VVN</code> lexical verb: past participle</item> 
 <item><code>VVZ</code> lexical verb: -s form</item>
</list> </p><p>
 The permitted ambiguity tags are listed in the Wordclass tagging
 guidelines (<ptr target="#pm"/>).  </p>

<p> It will be noted that overall 30 ambiguity tags are recognized. We
also observe that each ambiguity tag (eg <code>VVD-VVN</code>) is
matched by another ambiguity tag which is its mirror image (eg
<code>VVN-VVD</code>). The ordering of tags is significant: it is the
first of the two tags which is estimated by the tagger to be the more
likely. Hence the interpretation of an ambiguity tag X-Y may be
expressed as follows: <q>There is not sufficient confidence to choose
between tags X and Y; however, X is considered to be more likely.</q>
 </p>
 </div>

 <div xml:id="guidelines">
 <head>Guidelines to the Wordclass Tagging</head>
 
 <div xml:id="section1">
 <head>Preliminaries</head>
 <div xml:id="tagset"><head>The BNC basic tagset</head>
<p>For completeness, we begin by listing the C5 tagset used throughout
the BNC, followed by the ambiguity codes used:

 <table >
 <row role="label">
 <cell>Tag</cell>
 <cell>Description</cell>
 </row>
 <row><cell><ref target="#m2adj">AJ0</ref></cell>
 <cell>Adjective (general or positive) (e.g. <hi rend="italic">good</hi>, <hi rend="italic">old</hi>, <hi rend="italic">beautiful</hi>)</cell>
 </row>
 <row><cell><ref target="#m2adj">AJC</ref></cell>
 <cell>Comparative adjective (e.g. <hi rend="italic">better</hi>, <hi rend="italic">older</hi>)</cell>
 </row>
 <row><cell><ref target="#m2adj">AJS</ref></cell>
 <cell>Superlative adjective (e.g. <hi rend="italic">best</hi>, <hi rend="italic">oldest</hi>)</cell>
 </row>
 <row><cell><ref target="#m2art">AT0</ref></cell>
 <cell>Article (e.g. <hi rend="italic">the</hi>, <hi rend="italic">a</hi>, <hi rend="italic">an</hi>, <hi rend="italic">no</hi>)</cell>
 </row>
 <row><cell><ref target="#m2adv">AV0</ref></cell>
 <cell>General adverb: an adverb not subclassified as AVP or AVQ (see below) (e.g. <hi rend="italic">often</hi>, <hi rend="italic">well</hi>, <hi rend="italic">longer</hi> (adv.), <hi rend="italic">furthest</hi>.</cell>
 </row>
 <row><cell><ref target="#m2prep">AVP</ref></cell>
 <cell>Adverb particle (e.g. <hi rend="italic">up</hi>, <hi rend="italic">off</hi>, <hi rend="italic">out</hi>)</cell>
 </row>
 <row><cell><ref target="#m2adv">AVQ</ref></cell>
 <cell>Wh-adverb (e.g. <hi rend="italic">when</hi>, <hi rend="italic">where</hi>, <hi rend="italic">how</hi>, <hi rend="italic">why</hi>, <hi rend="italic">wherever</hi>) </cell>
 </row>
 <row><cell><ref target="#m2conj">CJC</ref></cell>
 <cell>Coordinating conjunction (e.g. <hi rend="italic">and</hi>, <hi rend="italic">or</hi>, <hi rend="italic">but</hi>)</cell>
 </row>
 <row><cell><ref target="#m2conj">CJS</ref></cell>
 <cell>Subordinating conjunction (e.g. <hi rend="italic">although</hi>, <hi rend="italic">when</hi>)</cell>
 </row>
 <row><cell><ref target="#m2conj">CJT</ref></cell>
 <cell>The subordinating conjunction <hi rend="italic">that</hi> </cell>
 </row>
 <row><cell><ref target="#m2num">CRD</ref></cell>
 <cell>Cardinal number (e.g. <hi rend="italic">one</hi>, <hi rend="italic">3</hi>, <hi rend="italic">fifty-five</hi>, <hi rend="italic">3609</hi>)</cell>
 </row>
 <row><cell><ref target="#m2art">DPS</ref></cell>
 <cell>Possessive determiner-pronoun (e.g. <hi rend="italic">your</hi>, <hi rend="italic">their</hi>, <hi rend="italic">his</hi>)</cell>
 </row>
 <row><cell><ref target="#m2art">DT0</ref></cell>
 <cell>General determiner-pronoun: i.e. a determiner-pronoun which is not a DTQ or an AT0. </cell>
 </row>
 <row><cell><ref target="#m2art">DTQ</ref></cell>
 <cell>Wh-determiner-pronoun (e.g. <hi rend="italic">which</hi>, <hi rend="italic">what</hi>, <hi rend="italic">whose</hi>, <hi rend="italic">whichever</hi>) </cell>
 </row>
  <row><cell><ref target="#m2misc_ex0">EX0</ref></cell>
 <cell>Existential there, i.e. <hi rend="italic">there</hi> occurring in the <hi rend="italic">there is</hi> ... or <hi rend="italic">there are</hi> ... construction</cell>
 </row>
 <row><cell><ref target="#m2misc_itj">ITJ</ref></cell>
 <cell>Interjection or other isolate (e.g. <hi rend="italic">oh</hi>, <hi rend="italic">yes</hi>, <hi rend="italic">mhm</hi>, <hi rend="italic">wow</hi>)</cell>
 </row>
 <row><cell><ref target="#m2nn">NN0</ref></cell>
 <cell>Common noun, neutral for number (e.g. <hi rend="italic">aircraft</hi>, <hi rend="italic">data</hi>, <hi rend="italic">committee</hi>) </cell>
 </row>
 <row><cell><ref target="#m2nn">NN1</ref></cell>
 <cell>Singular common noun (e.g. <hi rend="italic">pencil</hi>, <hi rend="italic">goose</hi>, <hi rend="italic">time</hi>, <hi rend="italic">revelation</hi>)</cell>
 </row>
 <row><cell><ref target="#m2nn">NN2</ref></cell>
 <cell>Plural common noun (e.g. <hi rend="italic">pencils</hi>, <hi rend="italic">geese</hi>, <hi rend="italic">times</hi>, <hi rend="italic">revelations</hi>)</cell>
 </row>
 <row><cell><ref target="#m2np0">NP0</ref></cell>
 <cell>Proper noun (e.g. <hi rend="italic">London</hi>, <hi rend="italic">Michael</hi>, <hi rend="italic">Mars</hi>, <hi rend="italic">IBM</hi>) </cell>
 </row>
 <row><cell><ref target="#m2ord">ORD</ref></cell>
 <cell>Ordinal numeral (e.g. <hi rend="italic">first</hi>, <hi rend="italic">sixth</hi>, <hi rend="italic">77th</hi>, <hi rend="italic">last</hi>) .</cell>
 </row>
 <row><cell><ref target="#m2art">PNI</ref></cell>
 <cell>Indefinite pronoun (e.g. <hi rend="italic">none</hi>, <hi rend="italic">everything</hi>, <hi rend="italic">one</hi> [as pronoun], <hi rend="italic">nobody</hi>)</cell>
 </row>
 <row><cell><ref target="#m2art">PNP</ref></cell>
 <cell>Personal pronoun (e.g. <hi rend="italic">I</hi>, <hi rend="italic">you</hi>, <hi rend="italic">them</hi>, <hi rend="italic">ours</hi>)</cell>
 </row>
 <row><cell><ref target="#m2art">PNQ</ref></cell>
 <cell>Wh-pronoun (e.g. <hi rend="italic">who</hi>, <hi rend="italic">whoever</hi>, <hi rend="italic">whom</hi>)</cell>
 </row>
 <row><cell><ref target="#m2art">PNX</ref></cell>
 <cell>Reflexive pronoun (e.g. <hi rend="italic">myself</hi>, <hi rend="italic">yourself</hi>, <hi rend="italic">itself</hi>, <hi rend="italic">ourselves</hi>)</cell>
 </row>
 <row><cell><ref target="#m2misc_pos">POS</ref></cell>
 <cell>The possessive or genitive marker <hi rend="italic">'s </hi>or <hi rend="italic">'</hi></cell>
 </row>
 <row><cell><ref target="#m2prep">PRF</ref></cell>
 <cell>The preposition <hi rend="italic">of</hi></cell>
 </row>
 <row><cell><ref target="#m2prep">PRP</ref></cell>
 <cell>Preposition (except for <hi rend="italic">of</hi>) (e.g. <hi rend="italic">about</hi>, <hi rend="italic">at</hi>, <hi rend="italic">in</hi>, <hi rend="italic">on</hi>, <hi rend="italic">on behalf of</hi>, <hi rend="italic">with</hi>)</cell>
 </row>
 <row><cell>PUL</cell>
 <cell>Punctuation: left bracket - i.e. <hi rend="italic">( </hi>or <hi rend="italic">[</hi></cell>
 </row>
 <row><cell>PUN</cell>
 <cell>Punctuation: general separating mark - i.e<hi rend="italic">. . , ! , : ; -</hi> or <hi rend="italic">?</hi></cell>
 </row>
 <row><cell>PUQ</cell>
 <cell>Punctuation: quotation mark - i.e. <hi rend="italic">' </hi>or <hi rend="italic">"</hi></cell>
 </row>
 <row><cell>PUR</cell>
 <cell>Punctuation: right bracket - i.e. <hi rend="italic">)</hi> or <hi rend="italic">]</hi></cell>
 </row>
 <row><cell><ref target="#m2misc_to0">TO0</ref></cell>
 <cell>Infinitive marker <hi rend="italic">to</hi> </cell>
 </row>
 <row><cell><ref target="#m2misc_unc">UNC</ref></cell>
 <cell>Unclassified items which are not appropriately considered as items of the English lexicon.</cell>
 </row>
 <row><cell><ref target="#m2vb">VBB</ref></cell>
 <cell>The present tense forms of the verb BE, except for <hi rend="italic">is</hi>, <hi rend="italic">'s</hi>: i.e. <hi rend="italic">am</hi>, <hi rend="italic">are</hi>, <hi rend="italic">'m</hi>, <hi rend="italic">'re</hi> and <hi rend="italic">be</hi> [subjunctive or imperative]</cell>
 </row>
 <row><cell><ref target="#m2vb">VBD</ref></cell>
 <cell>The past tense forms of the verb BE: <hi rend="italic">was</hi> and <hi rend="italic">were</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VBG</ref></cell>
 <cell>The -ing form of the verb BE: <hi rend="italic">being</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VBI</ref></cell>
 <cell>The infinitive form of the verb BE: <hi rend="italic">be</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VBN</ref></cell>
 <cell>The past participle form of the verb BE: <hi rend="italic">been</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VBZ</ref></cell>
 <cell>The -s form of the verb BE: <hi rend="italic">is</hi>, <hi rend="italic">'s</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VDB</ref></cell>
 <cell>The finite base form of the verb BE: <hi rend="italic">do</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VDD</ref></cell>
 <cell>The past tense form of the verb DO: <hi rend="italic">did</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VDG</ref></cell>
 <cell>The -ing form of the verb DO: <hi rend="italic">doing</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VDI</ref></cell>
 <cell>The infinitive form of the verb DO: <hi rend="italic">do</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VDN</ref></cell>
 <cell>The past participle form of the verb DO: <hi rend="italic">done</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VDZ</ref></cell>
 <cell>The -s form of the verb DO: <hi rend="italic">does</hi>, <hi rend="italic">'s</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VHB</ref></cell>
 <cell>The finite base form of the verb HAVE: <hi rend="italic">have</hi>, <hi rend="italic">'ve</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VHD</ref></cell>
 <cell>The past tense form of the verb HAVE: <hi rend="italic">had</hi>, <hi rend="italic">'d</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VHG</ref></cell>
 <cell>The -ing form of the verb HAVE: <hi rend="italic">having</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VHI</ref></cell>
 <cell>The infinitive form of the verb HAVE: <hi rend="italic">have</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VHN</ref></cell>
 <cell>The past participle form of the verb HAVE: <hi rend="italic">had</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VHZ</ref></cell>
 <cell>The -s form of the verb HAVE: <hi rend="italic">has</hi>, <hi rend="italic">'s</hi></cell>
 </row>
 <row><cell><ref target="#m2vb">VM0</ref></cell>
 <cell>Modal auxiliary verb (e.g. <hi rend="italic">will</hi>, <hi rend="italic">would</hi>, <hi rend="italic">can</hi>, <hi rend="italic">could</hi>, <hi rend="italic">'ll</hi>, <hi rend="italic">'d</hi>)</cell>
 </row>
 <row><cell><ref target="#m2vb">VVB</ref></cell>
 <cell>The finite base form of lexical verbs (e.g. <hi rend="italic">forget</hi>, <hi rend="italic">send</hi>, <hi rend="italic">live</hi>, <hi rend="italic">return</hi>) [Including the imperative and present subjunctive]</cell>
 </row>
 <row><cell><ref target="#m2vb">VVD</ref></cell>
 <cell>The past tense form of lexical verbs (e.g. <hi rend="italic">forgot</hi>, <hi rend="italic">sent</hi>, <hi rend="italic">lived</hi>, <hi rend="italic">returned</hi>)</cell>
 </row>
 <row><cell><ref target="#m2vb">VVG</ref></cell>
 <cell>The -ing form of lexical verbs (e.g. <hi rend="italic">forgetting</hi>, <hi rend="italic">sending</hi>, <hi rend="italic">living</hi>, <hi rend="italic">returning</hi>)</cell>
 </row>
 <row><cell><ref target="#m2vb">VVI</ref></cell>
 <cell>The infinitive form of lexical verbs (e.g. <hi rend="italic">forget</hi>, <hi rend="italic">send</hi>, <hi rend="italic">live</hi>, <hi rend="italic">return</hi>)</cell>
 </row>
 <row><cell><ref target="#m2vb">VVN</ref></cell>
 <cell>The past participle form of lexical verbs (e.g. <hi rend="italic">forgotten</hi>, <hi rend="italic">sent</hi>, <hi rend="italic">lived</hi>, <hi rend="italic">returned</hi>)</cell>
 </row>
 <row><cell><ref target="#m2vb">VVZ</ref></cell>
 <cell>The -s form of lexical verbs (e.g. <hi rend="italic">forgets</hi>, <hi rend="italic">sends</hi>, <hi rend="italic">lives</hi>, <hi rend="italic">returns</hi>)</cell>
 </row>
 <row><cell><ref target="#m2misc_xx0">XX0</ref></cell>
 <cell>The negative particle <hi rend="italic">not</hi> or <hi rend="italic">n't </hi></cell>
 </row>
 <row><cell><ref target="#m2misc_zz0">ZZ0</ref></cell>
 <cell>Alphabetical symbols (e.g. <hi rend="italic">A</hi>, <hi rend="italic">a</hi>, <hi rend="italic">B</hi>, <hi rend="italic">b</hi>, <hi rend="italic">c</hi>, <hi rend="italic">d</hi>)</cell>
 </row>
 </table>
 </p>
 
 <p>Total number of wordclass tags in the BNC basic tagset = 57, plus 4 punctuation tags</p>
 
 <div xml:id="pm"><head>Ambiguity Tag list</head>

 <p> In addition, there are 30 "Ambiguity Tags". These are applied
 wherever the probabilities assigned by the <ref target="#prog">CLAWS
 automatic tagger</ref> to its first and second choice tags were
 considered too low for reliable disambiguation. So, for example, the
 ambiguity tag <code>AJ0-AV0</code> indicates that the choice between
 adjective (<code>AJ0</code>) and adverb (<code>AV0</code>) is left
 open, although the tagger has a preference for an adjective
 reading. The mirror tag, <code>AV0-AJ0</code>, again shows
 adjective-adverb ambiguity, but this time the more likely reading is
 the adverb.</p>

 <table >
 <row role="label">
 <cell> Ambiguity tag</cell>
 <cell>Ambiguous between</cell>
 <cell> More probable tag</cell>
 </row>
  <row>
   <cell>
    AJ0-NN1
   </cell>
   <cell>AJ0 or NN1</cell>
   <cell>AJ0</cell>
  </row>
  <row>
   <cell>
    AJ0-VVD
   </cell>
   <cell>AJ0 or VVD</cell>
   <cell>AJ0</cell>
  </row>
  <row>
   <cell>
    AJ0-VVG
   </cell>
   <cell>AJ0 or VVG</cell>
   <cell>AJ0</cell>
  </row>
  <row>
   <cell>
    AJ0-VVN
   </cell>
   <cell>AJ0 or VVN</cell>
   <cell>AJ0</cell>
  </row>
  <row>
   <cell>
    AV0-AJ0
   </cell>
   <cell>AV0 or AJ0</cell>
   <cell>AV0</cell>
  </row>
  <row>
   <cell>
    AVP-PRP
   </cell>
   <cell>AVP or PRP</cell>
   <cell>AVP</cell>
  </row>
  <row>
   <cell>
    AVQ-CJS
   </cell>
   <cell>AVQ or CJS</cell>
   <cell>AVQ</cell>
  </row>
  <row>
   <cell>
    CJS-AVQ
   </cell>
   <cell>CJS or AVQ</cell>
   <cell>CJS</cell>
  </row>
  <row>
   <cell>
    CJS-PRP
   </cell>
   <cell>CJS or PRP</cell>
   <cell>CJS</cell>
  </row>
  <row>
   <cell>
    CJT-DT0
   </cell>
   <cell>CJT or DT0</cell>
   <cell>CJT</cell>
  </row>
  <row>
   <cell>
    CRD-PNI
   </cell>
   <cell>CRD or PNI</cell>
   <cell>CRD</cell>
  </row>
  <row>
   <cell>
    DT0-CJT
   </cell>
   <cell>DT0 or CJT</cell>
   <cell>DT0</cell>
  </row>
  <row>
   <cell>
    NN1-AJ0
   </cell>
   <cell>NN1 or AJ0</cell>
   <cell>NN1</cell>
  </row>
  <row>
   <cell>
    NN1-NP0
   </cell>
   <cell>NN1 or NP0</cell>
   <cell>NN1</cell>
  </row>
  <row>
   <cell>
    NN1-VVB
   </cell>
   <cell>NN1 or VVB</cell>
   <cell>NN1</cell>
  </row>
  <row>
   <cell>
    NN1-VVG
   </cell>
   <cell>NN1 or VVG</cell>
   <cell>NN1</cell>
  </row>
  <row>
   <cell>
    NN2-VVZ
   </cell>
   <cell>NN2 or VVZ</cell>
   <cell>NN2</cell>
  </row>
  <row>
   <cell>
    NP0-NN1
   </cell>
   <cell>NP0 or NN1</cell>
   <cell>NP0</cell>
  </row>
  <row>
   <cell>
    PNI-CRD
   </cell>
   <cell>PNI or CRD</cell>
   <cell>PNI</cell>
  </row>
  <row>
   <cell>
    PRP-AVP
   </cell>
   <cell>PRP or AVP</cell>
   <cell>PRP</cell>
  </row>
  <row>
   <cell>
    PRP-CJS
   </cell>
   <cell>PRP or CJS</cell>
   <cell>PRP</cell>
  </row>
  <row>
   <cell>
    VVB-NN1
   </cell>
   <cell>VVB or NN1</cell>
   <cell>VVB</cell>
  </row>
  <row>
   <cell>
    VVD-AJ0
   </cell>
   <cell>VVD or AJ0</cell>
   <cell>VVD</cell>
  </row>
  <row>
   <cell>
    VVD-VVN
   </cell>
   <cell>VVD or VVN</cell>
   <cell>VVD</cell>
  </row>
  <row>
   <cell>
    VVG-AJ0
   </cell>
   <cell>VVG or AJ0</cell>
   <cell>VVG</cell>
  </row>
  <row>
   <cell>
    VVG-NN1
   </cell>
   <cell>VVG or NN1</cell>
   <cell>VVG</cell>
  </row>
  <row>
   <cell>
    VVN-AJ0
   </cell>
   <cell>VVN or AJ0</cell>
   <cell>VVN</cell>
  </row>
  <row>
   <cell>
    VVN-VVD
   </cell>
   <cell>VVN or VVD</cell>
   <cell>VVN</cell>
  </row>
  <row>
   <cell>
    VVZ-NN2
   </cell>
   <cell>VVZ or NN2</cell>
   <cell>VVZ</cell>
  </row>
 </table>
 <p>Total number of wordclass tags including punctuation and ambiguity tags = 91.</p></div>
 </div>

 
 <div xml:id="m1token"><head>Appearance of wordclass tags and citations</head>

 <p> Throughout this section, we show text examples in a simplified format
 which is different from the XML contained in the corpus but which
 will highlight the particular tag that is being discussed.  The XML
 tagging (used to mark, for example, paragraph and pause markers) is
 not relevant to the present discussion and will usually
not be displayed in the output from software such as concordance
generators or search engines. </p>

 <p>As was noted above, each word in the corpus is marked by an XML
 <gi>w</gi> element which provides three additional pieces of
 information the wordclass, carried by the <ident>c5</ident>
 attribute, a headword or lemma derived from the word, carried by the
 <ident>hw</ident> attribute, and a simplified wordclass derived from
 the c5 value, carried by the <ident>pos</ident> attribute. </p>
 
<p>In the XML source therefore, we will see sentences like this:

<eg><![CDATA[<w c5="AV0" hw="apparently" pos="ADV">apparently </w>
<w c5="PNP" hw="we" pos="PRON">we </w>
<w c5="VVB" hw="eat" pos="VERB">eat </w>
<w c5="DT0" hw="more" pos="ADJ">more </w>
<w c5="NN1" hw="chocolate" pos="SUBST">chocolate </w>
<w c5="CJS" hw="than" pos="CONJ">than </w>
<w c5="DT0" hw="any" pos="ADJ">any </w>
<w c5="AJ0" hw="other" pos="ADJ">other </w>
<w c5="NN1" hw="country" pos="SUBST">country</w>
<c c5="PUN">.</c>]]></eg> 

For simplicity of discussion throughout this section we have chosen
not to present examples in this way, but instead to suppress the bulk
of the XML markup. Only the wordclass attribute of the word (or
words) being in question, we have preserved this and placed it
<emph>after</emph> the word it relates to in the example
sentences. Under <ref target="#m2conj">subordinating
conjunctions</ref>, for instance, the citation above appears as
follows: 
<q rend="display"> ...apparently we eat more chocolate than_CJS any other country. [G3U.1000]</q> 
This is purely as an aid to
reading the present document; in the corpus itself, all wordclass
tagging is represented using the XML conventions shown above. </p>

<p>As noted above, any example from the BNC can be identified by means
of the text identifier (a three character code such as GRU) and the
number of the <gi>s</gi> element within it. We use this method
throughout the following examples, where they are taken from the BNC.
Thus, the example above is taken from s-unit 1000 of text G3U. In 
sections <ptr target="#m3"/> and <ptr target="#m4"/> below, we
occasionally cite cases where the POS-tagging in the corpus does not
match the tag given in the citation, in that it is either an error or
an ambiguity tag. This is to give an idea of the contexts in which the
resolution of ambiguities has been less reliable. We list the tag
found in the corpus next to the file reference with an asterisk,
eg. in <ref target="#m4well">well</ref> we give the ideal tag as
<code>VVB</code>, but the actual tag as <code>AV0</code>: <q rend="display">
Tears well_VVB up in my eyes.[BN3.5 *AV0] </q>

 Note also that we occasionally use invented examples, rather than
 corpus citations, especially where a contrast between categories is
 being made. </p>
 
 <div xml:id="contracted">
 <head>Appearance and tagging of contracted forms</head>
 <p>Contracted forms — including enclitics, eg <hi rend="italic">he's</hi>, <hi rend="italic">she'll</hi>,
 negatives eg <hi rend="italic">don't</hi> and <hi rend="italic">can't</hi>, and 'fused words', eg
 <hi rend="italic">wanna</hi> and <hi rend="italic">gimme</hi> — are broken down by the tagger into their
 component parts, with each part being assigned its own tags. No spaces are introduced in
 POS-tagged contracted words: <q rend="display">doesn't = does_VDZ n't_XX0<lb/>
dunno = Du_VDB n_XX0 no_VVI<lb/>
wanna = wan_VVB na_TO0 or wan_VVB na_AT0<lb/>
gimme = Gim_VVB me_PNP   </q></p>

  <p>This procedure sometimes results in strange-looking word
  divisions, particularly with the fused words. However, they do
  provide a ready means of comparison with the full forms, such as
  <hi rend="italic">want_VVB to_TO0</hi> and <hi rend="italic">give_VVB me_PNP.</hi>
 </p>

 <p>Note that in the case of <hi rend="italic">ain't</hi> it has been tricky to
 resolve the tag of the first part ( <hi rend="italic">ai </hi>)
 satisfactorily. Therefore in all contexts we have tagged this as an
 unclassified word, followed by the negative particle. <q rend="display"> 
 Ai_UNC n't_XX0 got yours yet [KCT.1281]</q>
 </p>
 </div>
 
 <div xml:id="multiwords">
 
<head>Appearance and tagging of multiwords</head>

 <p>The term `multiwords' denotes multiple-word combinations to which
 CLAWS assigns a single wordclass tag - for example, a complex
 preposition, an adverbial, or a foreign expression naturalised into
 English as a compound noun. In the XML version of the corpus, these
 sequences are explicitly marked using an XML element
 (<gi>mw</gi>). The individual orthographic words of which the
 sequence is composed are also marked, in the same way as other words,
 using the <gi>w</gi> element. </p>

<p>For example, as noted above, in the XML source of the corpus, the multiword
sequence <hi rend="italic">of course</hi> is tagged as follows:
<q rend="display"><![CDATA[<mw c5="AV0">  
  <w c5="PRF" lemma="of" pos="PREP">of </w>
  <w c5="NN1" lemma="course" pos="SUBST">course </w>
</mw>]]></q>
When displaying examples which contain multiwords in this chapter, we
display only the wordclass of the outermost <gi>mw</gi> element. Its
boundaries are indicated, where possible, by extra highlighting:
<q rend="display"><emph>Of course_AV0</emph> I can.  [H9V.212]</q> 
</p>

<p>The wordclass tags assigned to constituent parts of multiword items
are listed in <ptr target="#defrobs"/>. This part of the wordclass
tagging was done automatically during the XML conversion process, and
has not been checked by CLAWS. </p>

 <p>Note that some multiwords can represent different categories
 according to context, e.g.  <hi rend="italic">in between</hi> in: <q rend="display"> The
 stage <emph>in between_PRP</emph> the original negative and the dupe
 is called an interpositive [FB8.295] <lb/> The truth lies somewhere
 <emph>in between_AV0</emph> [ABK.2834] </q></p>

 <p>Moreover, sometimes it is more appropriate to tag a word
 combination as consisting of ordinary words than as a multiword
 sequence, as in the case of <hi rend="italic">but for</hi> below: <q rend="display"><lb/>
 but_CJC for_PRP years now darkness has been growing [F99.2027]
 cf. <lb/> which they would not have done <emph>but
 for_PRP</emph> the presence of the police. [H81.766] 
 </q></p>
 </div>
 
<div xml:id="slash">
 <head>Words joined by the slash character </head>
 <p>Words which are joined together by a slash ( / ) but no whitespace, such as
 <hi rend="italic">and/or</hi>, are not split up in tagged versions of the text. 
 
<list>
 <item>if they are of the same wordclass they are assigned the same tag;</item>
 <item>if they are of different wordclasses, the whole sequence is assigned the
 'unclassified' tag, UNC.</item>
 </list>
 </p>
 <p>Examples:<q rend="display"><lb/> 
   A title and/or_CJC an author's name [H0S.358]<lb/>
    You should be a graduate in Electrical/Electronic_AJ0 Engineering, Physics , Mathematics , Computing or a related discipline. [CJU.1049]
 </q></p>
</div>
 
 </div>
 </div> <!-- preliminaries -->
 <anchor
 xml:id="m2nn"/>
 
 <div xml:id="m2">
 <head>Introduction to Word Classes</head>
 <div xml:id="nouns">
 <head>Nouns</head>
<!-- <p><hi rend="italic">Basic tags:</hi><q rend="display"><lb/> NN1, NN2, NN0 = common nouns<lb/> NP0 = proper nouns</q></p>
 <p><hi rend="italic">Ambiguity tags: </hi><q rend="display"><lb/> NN1-NP0, NN1-VVB, NN1-VVG, NN2-VVZ <lb/> NP0-NN1,
 VVB-NN1, VVG-NN1, VVZ-NN2 </q></p>-->
 <div xml:id="commonN">
 <head> Common nouns</head>
 <p>Singular common nouns are tagged <code>NN1</code>, while plurals take <code>NN2</code>:
<q rend="display">   A child_NN1.<lb/>
   Several children_NN2<lb/>
  An air_NN1 of distinction_NN1<lb/>
  Fifteen miles_NN2 away 
 </q></p>
 <p>Nouns which are morphologically invariant for number or which can take either a singular or plural verb, (so-called
 `neutral for number') are tagged <code>NN0</code>:<q rend="display">
  Now the government_NN0 is considering new warnings on steroids ... [K24.3057]<lb/>
 ... the Government_NN0 are putting people's lives in jeopardy. [A7W.518] <lb/>
 I caught a fish_NN0.[KBW.316] <lb/>
 I had caught four fish_NN0 with hardly any effort[B0P.1387] </q></p>
 <p>We make no special distinction between common nouns that can be mass (or `non-count')
 nouns (eg <hi rend="italic">water, cheese</hi>), and other common nouns. All are tagged <code>NN1</code> when
 singular and <code>NN2</code> when plural: <q rend="display">
  Cheese_NN1 is a protein of high biological value. [ABB.1950] <lb/>
three cheeses_NN2. [CH6.7834] <lb/>
A car_NN1 glistens in the distance_NN1. [HH0.1035] <lb/>
Three cars_NN2, two lorries_NN2 and a motorbike_NN1! [CHR.290] </q></p>

 <p>In general we try to tag abbreviations for common nouns (and other word classes) as if
 they were written as full forms. Abbreviations for measurement nouns are generally
 tagged <code>NN0</code> as they are invariant for number. <q rend="display">
   Crewe are top of div_NN1 3 by 8 points [J1C.961] (where div = division)<lb/>
   1 km_NN0<lb/> 
  400 km_NN0 (km = 'kilometre' or 'kilometres') <lb/>
     1 oz_NN0. <lb/>
  6 oz_NN0 (oz = 'ounce' or 'ounces')
 </q></p>

 <p>Nouns such as <hi rend="italic">hundred, hundreds, dozens, gross</hi>, are all tagged as numbers,
 <code>CRD</code>, rather than nouns. </p>
 </div>
 <div xml:id="m2np0"> <head>Proper nouns</head>
 <p>The tag <code>NP0</code> ideally should denote any kind of proper noun, but in practice the
 open-endedness of naming expressions makes it difficult to capture all possible types
 consistently. We have confined its coverage mainly to personal and
 geographical names, and to names of days of the week or months of the
 year.  Within these, some rather arbitrary borderlines have had to be drawn. <!--Users of
  version 1 of the corpus should be aware of a few small but important <ref
   target="#changes">changes in BNC2</ref>.-->

<q rend="display">  Sally_NP0<lb/>  Joe_NP0 Bloggs_NP0<lb/> 
Madame_NP0 Pompadour_NP0<lb/>  
Leonardo_NP0 da_NP0 Vinci_NP0<lb/> 
 London_NP0<lb/> Lake_NP0 Tanganyika_NP0<lb/> New_NP0 York_NP0<lb/>
April_NP0<lb/>
</q>
 </p>
<list type="gloss">
<label>Number</label>

 <item>Note that the distinction between singular and plural proper
 nouns is not indicated in the tagset, plural proper nouns being a
 comparative rarity:
<q rend="display">John_NP0 Smith_NP0. All of the Smiths_NP0. </q></item>
<label>Multiwords</label>
 <item>Note also that proper nouns are <emph>not</emph> processed as
 multiwords (though there may be good linguistic reasons for doing
 so). Each word in such a sequence gets its own tag.</item>

<label>Initials</label>
<item><p>A person's initials preceding a surname are tagged <code>NP0</code>,
 just as the surname itself. The choice whether to use a space and/or full-stop between
 initials (eg <hi rend="italic">J.F.</hi> or <hi rend="italic">J. F.</hi> or <hi rend="italic">J F</hi> or
 <hi rend="italic">JF</hi>) is determined  by the original source text; the tagged version follows
 the same format. 
 <q rend="display"> John F. Kennedy = John_NP0 F._NP0 Kennedy_NP0<lb/>
J. F. Kennedy = J._NP0 F._NP0 Kennedy_NP0<lb/>
J.F. Kennedy = J.F._NP0 Kennedy_NP0 </q></p> 

<p>In the spoken part of the BNC, however, the components
 of names — and, in fact, most words — that are spelt aloud as individual letters,
 such as <hi rend="italic">I B M</hi>, and <hi rend="italic">J R</hi> in <hi rend="italic">J R Hartley</hi>, are not
 tagged <code>NP0</code> but <code>ZZ0</code> (letter of the
 alphabet). See further <ptr
 target="#m2misc_zz0"/></p></item>
<label>Nouns of style</label>
 <item><p> Preceding a proper noun, or sequence of proper nouns, style (or title) nouns with
 uppercase initial capitals are tagged <code>NP0</code>: 
  <q rend="display"> Pastor_NP0 Tokes_NP0 <lb/> Chairman_NP0 Mao_NP0 <lb/> Sub-Lieutenant_NP0 R_NP0 C_NP0 V_NP0 Wynn_NP0<lb/> Sister_NP0 Wendy_NP0 </q></p>
<p> Contrast the last example with the following:
<q rend="display"> You remember your sister_NN1 Wendy_NP0... [HGJ.800] </q>
 where <hi rend="italic">Wendy</hi> is in apposition to a common noun <hi rend="italic">sister</hi>,
 in lowercase letters. </p>
 </item>
<label>Geographical names</label>
 <item><p>For names of towns, streets, countries and states, seas, oceans, lakes, rivers,
 mountains and other geographical placenames, the general rule is to tag as <code>NPO</code>. If
 the word <hi rend="italic">the</hi> precedes, it is tagged <code>AT0</code>: 
 <q rend="display"> East_NP0 Timor_NP0<lb/> South_NP0 Carolina_NP0<lb/> Baker_NP0 Street_NP0<lb/> West_NP0 Harbour_NP0 Lane_NP0<lb/> the_AT0 United_NP0 Kingdom_NP0<lb/> the_AT0 Baltic_NP0<lb/> the_AT0 Indian_NP0 Ocean_NP0<lb/> Mount_NP0 St_NP0 Helens_NP0<lb/> the_AT0 Alps_NP0 </q></p> 
<p>  Other tags are used for the constituents of more verbose (especially political)
 descriptions of placenames, or those that are not typically marked on maps:
 <q rend="display"> Latin_AJ0 America_NP0 <lb/> Western_AJ0 Europe_NP0 <lb/> the_AT0 Western_AJ0 Region_NN1 <lb/>  the_AT0 People_NN0's_POS Republic_NN1 of_PRF China_NP0 <lb/> the_AT0 Dominican_AJ0 Republic_NN1 <lb/> the_AT0 Sultanate_NN1 of_PRF Oman_NP0 
 </q></p>
<p> The examples show a little arbitrariness in application. For
example, contrast
<q rend="display">the_AT0 United_NP0 States_NP0<lb/> the_AT0 Soviet_AJ0 Union_NN1 <lb/>
</q></p>
<p>Multiword names containing a compass point, ie. those beginning
 <hi rend="italic">North</hi>, <hi rend="italic">South</hi>, <hi rend="italic">East</hi>, <hi rend="italic">West</hi>,
 <hi rend="italic">North East</hi>, <hi rend="italic">South-west</hi> etc. nearly always become <code>NP0</code>,
 whereas those with <hi rend="italic">Northern</hi>, <hi rend="italic">Southern</hi>,
 <hi rend="italic">Eastern</hi>, <hi rend="italic">Western</hi> follow the non-NP0 pattern. Rare
 exceptions are: 
 <q rend="display"> Northern_NP0 Ireland_NP0<lb/> Western_NP0 Samoa_NP0 </q></p>
 </item>
<label>Non-personal and non-geographical names</label>
 <item>Where  names of organisations, sports teams, commercial products (incl
 newspapers), shops, restaurants, horses, ships etc. 
consist of <emph>ordinary words</emph> (common nouns, adjectives etc.),
 they receive <emph>ordinary tags</emph> (<code>NN1</code>,
 <code>AJ0</code> etc.). Only if a  word used as part of a name is an existing NP0 (typically a personal or
 geographical name), or a specially-coined word, is it tagged
 <code>NP0</code>.  Some examples follow:
 
 <list type="gloss">
 <label> <!-- start NONPERSONALNAMESlist --> Organisations, sports teams etc.</label>
 <item><q rend="display"> Cable_NN1 and_CJC Wireless_NN1<lb/>
 Procter_NP0 and_CJC Gamble_NP0<lb/>
 Acorn_NN1 Marketing_NN1 Limited_AJ0<lb/>
 Minolta_NP0;    IBM_NP0; NATO_NP0<lb/>
 Wolverhampton_NP0 Wanderers_NN2 (
 football_NN1 club_NN1 )<lb/>
  Tottenham_NP0 Hotspur_NP0 (football_NN1 club_NN1 )<lb/>
 The_AT0 Chicago_NP0 Bears_NN2<lb/>
  Spartak_NP0 Moscow_NP0<lb/>
 World_NN1 Health_NN1 Organisation_NN1<lb/>
 Oxfam_NP0 </q>
 There is a slight inconsistency here, in that acronyms of organisation names
 (WHO, NATO, IBM etc.) take <code>NP0</code>, whereas the expanded forms of these names take
 regular tags.  </item>
 <label> Products (including newspapers and magazines)</label>
 <item><p> <q rend="display"> Windows_NN2 software_NN1<lb/>
 Weetabix_NP0 <lb/>
 Lancashire_NP0 Evening_NN1 Post_NN1<lb/>
 Mars_NP0 bars_NN2<lb/>
 Time_NN1 Magazine_NN1<lb/>
 Scotchgard_NP0 <lb/>
 The_AT0 Reader_NN1 's_POS Digest_NN1<lb/>
 Perrier_NP0 water_NN1</q>
</p>
<p>Company names may sometimes be used to represent product names; in such
  cases the same tags apply. For example: <q rend="display"> John drives a Volkswagen_NP0 Golf_NN1<lb/>
 John drives a Volkswagen_NP0. <lb/></q></p></item>
 <label>Shops, pubs, restaurants, hotels, horses, ships etc. </label>
<item><q rend="display">Body_NN1 Shop_NN1<lb/>
 Mothercare_NP0<lb/>
 The_AT0 Grand_AJ0 Theatre_NN1<lb/>
 Sainsburys_NP0 supermarket_NN1<lb/>
 The_AT0 King_NN1 's_POS Arms_NN2<lb/>
 The_AT0 Ritz_NP0<lb/>
 Red_AJ0 Rum_NN1<lb/>
Aldaniti_NP0 <lb/>
 The_AT0 Bounty_NN1<lb/>
 The_AT0 Titanic_NP0</q>
 Here again <code>NP0</code> is reserved for parts of names that are specially coined, or
 derived from existing personal/geographical proper nouns. </item>
 </list>
 <!-- end NONPERSONALNAMESlist -->
 </item></list>
<!--
 <item xml:id="changes"><emph>Changes in NP0 assignment since BNC1</emph>
 <p> In the first release of the BNC, the use of NP0 tags applied a little more widely. The
 geographical category tagged NP0 used to include names of buildings and other
 institutions. Names of newspapers and magazines used to be treated separately from other
 products and tagged NP0. </p>
 <p>NOTE THAT IN BNC2 and BNC XML BOTH THESE TYPES NOW TAKE ORDINARY (non-NP0) TAGS: 
 <list
 type="gloss">
 <label>Buildings and institutions</label>
 <item>
  <Label>BNC1:</Label><q rend="display"><lb/>
  Blackpool_NP0 Tower_NP0
  <lb/>Prospect_NP0 Theatre_NP0 Company_NN0 
   <lb/>Austro-Hungarian_NP0 Empire_NP0
 <lb/>
 <Label>BNC 2 and BNC XML:</Label>
  <lb/>
 Blackpool_NP0 Tower_NN1  [B22.1633]
 <lb/>Prospect_NN1 Theatre_NN1 Company_NN!  [A06.1942] <lb/>
   Austro-Hungarian_AJ0 Empire
  [G3B.616] 
 </item>
 <label>Newspapers and magazines</label>
 <item>
  <Label>BNC1:</Label> <lb/>
  the_AT0 Daily_NP0 Mail_NP0
  <lb/>Railway_NP0 Gazette_NP0<lb/>
  <Label>BNC2 and BNC XML:</Label>
  <lb/>the_AT0 Daily_AJ0 Mail_NN1 [D95.334] <lb/>
  Railway_NN1
 Gazette_NN1 [HWM.1850]
 </item>
 </list>
-->

 </div>
 </div>
 
  <div xml:id="m2vb"><head>Verbs </head>
<list type="gloss">
<label>type</label>
<item>The second character of a verb tag marks the type of verb as
follows:
<table rend="center">
<row><cell>B</cell><cell>Forms of <hi rend="italic">be</hi> (<code>VBB VBD VBG VBI VBN VBZ</code>)</cell></row>
<row><cell>D</cell><cell>Forms of <hi rend="italic">do</hi> (<code> VDB VDD VDG VDI VDN VDZ</code>)</cell></row>
<row><cell>H</cell><cell>Forms of <hi rend="italic">have</hi> (<code> VHB VHD VHG VHI VHN VHZ</code>)</cell></row>
<row><cell>M</cell><cell>Other modal verbs (<code>VM0</code>)</cell></row>
<row><cell>V</cell><cell>Lexical verb (<code>VVB VVD VVG VVI VVN
VVZ</code>)</cell></row>
</table>
</item>
<!--
 <p><hi rend="italic">Ambiguity tags: </hi><eg><lb/>
 VVB-NN1 VVD-VVN VVD-AJ0 VVG-AJ0 VVG-NN1 VVZ-NN2 = verb more probable<lb/>
 NN1-VVB VVN-VVD AJ0-VVD AJ0-VVG NN1-VVG NN2-VVZ = verb less probable</q></p>
 -->

 
 <label>Inflection</label><item>The third character of a verb tag
 marks the verb inflection as follows:
 <table rend="center">
<row><cell>B</cell><cell>base form finite</cell></row>
<row><cell>D</cell><cell> past tense</cell></row>
<row><cell>Z</cell><cell> 3rd person sing present</cell></row>
<row><cell>N</cell><cell> past participle</cell></row>
<row><cell>I</cell><cell> infinitive</cell></row>
<row><cell>G</cell><cell> present participle</cell></row>
 </table>
 </item>
 <label>be, have, and do</label>
 <item><p> Auxiliary and main uses of these verbs are not distinguished: .
 <q rend="display"> she is_VBZ playing her best tennis for six years. [CH3.1382] 
<lb/> she is_VBZ just a star. [CH3.6939] <lb/>John has_VHZ built a set
 of bookshelves. [C9X.121]<lb/> John has_VHZ great courage. [CA9.1869]
 <lb/>We did_VDD n't_XX0 see anybody. [KB2.702] <lb/>They do_VDB nice
 work. [ANY.514]  </q>
</p> 
<p> Note the variant form of <hi rend="italic">have</hi> in non-standard English:
 <q rend="display"> they shouldn't of_VHI left it the last minute [KD8.7288] 
<lb/> That could of_VHI been 'bout us [B38.322] </q></p> 
</item> 

   <label>Lexical verbs </label> 
<item> Tags beginning VV- apply to all other (lexical) verbs. 
 <q rend="display"> She travels_VVZ in every Saturday morning. [KRH.4013]<lb/>  The young kids want_VVB to dance_VVI and have fun [CHA.1599]<lb/> I thought_VVD he looked_VVD a sad sort of a boy. [CDY.2831]<lb/> ...after running_VVG out of coal, the crew were forced_VVN to burn_VVI timber and resin [HPS.269]</q>
 </item>
 <label>Modals</label> 
 <item><p>All modals are tagged <code>VM0</code>. We do not differentiate between so-called past and present forms: 
 <q rend="display"> We can_VM0 go there.<lb/> We could_VM0 go there.<lb/> We
 used_VM0 to_TO0 go there every year.</q></p>
<p> The form <hi rend="italic">let's</hi> is treated as one verb:
 <q rend="display"> Let's_VM0 go_VVI! [A61.1443] </q></p>
 </item>

 <label>Contracted forms </label>
 <item><p>Contracted forms (<hi rend="italic">can't</hi>, <hi rend="italic">won't</hi>, <hi rend="italic">gimme</hi>, <hi rend="italic">dunno</hi> etc) are split into their component parts, which are tagged individually.
 <q rend="display">  Are_VBBn't_XX0 you coming?[A0R.2215]<lb/> 
  I du_VDB n_XX0 no_VVI [KR0.23] </q></p>
<!-- <p>
 It is not always clear if and where they should be divided. Please refer to 
 <ref url="fused.htm">the list of contracted forms</ref>. 
 (See also above on <ref target="#contracted">appearance of contracted forms</ref>)-->
 </item>
 <label>Subjunctives and Imperatives</label>
 <item>No special tags are used for these:
<q rend="display"> She suggested that they get_VVB married. [CBC.12107]
<lb/> Please be_VBB patient. [CHJ.899]<lb/> Do_VDBn't_XX0 just stand
 there watching! [ACB.3470] </q></item>

<label>Catenative or semi-auxiliary verbs</label>
<item>Again, no special tagging is used for such forms as <hi rend="italic">going
to</hi>, <hi rend="italic">ought to</hi>, or <hi rend="italic">used to</hi> + infinitive:
<q rend="display"> you're not going_VVG to_TO0 get killed  [KCE.6550]<lb/> you ought_VM0 to_TO0 let them know. [KCT.6115] </q>
 </item></list>
 <!-- end verb list -->
 
 
 <!-- <p>See further - Disambiguation Guide
 <q rend="display"><lb/>Section 3 <ref target="#m3adj-part"> Adjective vs. Participle</ref> (AJ0 vs. VVG and AJ0 vs. VVN)
 <lb/>Section 4 <ref target="#m4apostrophes"><hi rend="italic">'s</hi> </ref> 
 
 
 -->
  </div>
 
<div xml:id="m2adj"><head>Adjectives</head>

<p>Adjectives are given one of the wordclass tags <code>AJ0</code>,
<code>AJC</code>, or <code>AJS</code>.</p>


<p>The general tag for adjectives (<code>AJ0</code>) subsumes:
 
 <list type="gloss">
 <label>Predicative and attributive uses</label>
<item><q rend="display">  The ground was dry_AJ0 and dusty_AJ0 [GWA.118]<lb/>The dust from the dry_AJ0 ground [GWA.121] 
</q>
 </item>
 <label>Quasi-comparatives and quasi-superlatives</label>
 <item>
 Adjectives which have a heightening or downtoning effect rather like that of comparatives and superlatives, 
 but which do not behave syntactically like comparatives or superlatives, are treated as ordinary adjectives.
 Examples include <hi rend="italic">utter</hi>, <hi rend="italic">upper</hi> and
 <hi rend="italic">uppermost</hi>:
<q rend="display"> Events in Eastern Europe were evidently uppermost_AJ0 in Mr
Li's mind. [A95.366] <lb/>  Family contacts were very important in
uniting the upper_AJ0 classes [FB6.1495] </q></item>

 <label>Adjectives used catenatively</label>
<item>For example, <hi rend="italic">able</hi> and 
 <hi rend="italic">unable</hi>:
<q rend="display"> Will you be able_AJ0 to manage? (catenative)<lb/> Your son is very able_AJ0 (non-catenative) </q>
 </item>
 </list>
</p>
 
 <p>Comparative adjectives receive the tag <code>AJC</code>;
 superlatives take <code>AJS</code>:
<q rend="display">
 A faster_AJC car.<lb/> The best_AJS in its class.
 </q></p>

<p>Ambiguities frequently arise between adjectives and other wordclasses, in 
 particular adverbs, nouns and participles.</p>
 <!-- <p>See further - Disambiguation Guide <q rend="display"><lb/>
 Section 3 <ref target="#m3adj-part">ADJECTIVE vs. PARTICIPLE</ref> (AJ0 vs. VVG, AJ0 vs. VVN) <lb/>
 Section 3 <ref target="#m3adj-nn">ADJECTIVE vs. NOUN </ref> (AJ0 vs. NN1) <lb/>
 Section 3 <ref target="#m3adj-adv">ADJECTIVE vs. ADVERB </ref> (AJ0 vs. AV0, AJC vs. AV0) <lb/>
 Section 4 <ref target="#m4well"><hi rend="italic">well</hi></ref>, <ref target="#m4right"><hi rend="italic">right</hi></ref> </q></p>
 --> </div>
 
 </div> 

 <div xml:id="m2adv"><head>Adverbs</head>

 <p>Adverbs are given one of the tags
<code>AV0, AVQ</code>, or <code>AVP</code></p>

<p><code>AV0</code> is the default tag for adverbs. It incorporates a very mixed bag, including:

<list type="gloss">
 <label>adverbs of time, manner, place etc. </label>
 <item>Eg <hi rend="italic">slowly</hi>; <hi rend="italic">here</hi>; <hi rend="italic">soon</hi></item>
 
 <label>degree adverbs</label>
 <item>Eg <hi rend="italic">very</hi> and <hi rend="italic">rather</hi> in
<q rend="display"> very_AV0 tall_AJ0
 <lb/>rather_AV0 painfully_AV0</q></item>
 
 <label>sentence adverbs</label>
 <item>for example:
<q rend="display">However_AV0, … <lb/> <hi>In addition_AV0</hi></q></item>
 
  <label>postnominal adverbs</label><item>for example:
<q rend="display"> aged between 2 and 11 years inclusive_AV0  [AMD.31] <lb/> the buildings thereon_AV0  [J16.813]<lb/> during 1986-91 inclusive_AV0 [FT0.1400]<lb/> Diamonds galore_AV0 [FPH.900] </q></item>
 <label> discourse markers</label>
<item>such as <ref target="#m4well"><hi rend="italic">well</hi></ref>, 
 <ref target="#m4right"><hi rend="italic">right</hi></ref>, <ref target="#m4like"><hi rend="italic">like</hi></ref>:
 <q rend="display">you know like_AV0, it's worthwhile opening a cinema at 4 o'clock... [F7A.358] </q></item>
 </list>
</p>
 <p> Note that adverbs, unlike adjectives, are not tagged as positive, comparative, or superlative. 
 This is because of the relative rarity of comparative and superlative
 adverbs.</p>

 <p>Interrogative and relative wh-adverbs (<hi rend="italic">when, where, how, why, wherever</hi>) 
 are tagged <code>AVQ</code> whether the word occurs in interrogative
 or relative use.
<q rend="display"> 
 "When_AVQ do your courses start?" [A0F.3117]<lb/>  "...if you let me know when_AVQ the police are called in." [BMU.2291]<lb/>  Yet why_AVQ is that so? [CR7.3089]
 </q></p>

 <p>Ordinal-type adverbs (including <hi rend="italic">first</hi>, <hi rend="italic">fourth</hi>,
 etc.) are treated separately with the 
  <ref
   target="#m2ord"><code>ORD</code></ref> tag</p>
 <p>Prepositional Adverbs (also known as "Adverbial Particle") are
 treated as prepositions and tagged <code>AVP</code>: see 
 <ref target="#m2prep">Prepositions</ref></p>
 
 <!-- <p>See further - Disambiguation Guide <q rend="display"><lb/>
 Section 3 <ref target="#m3adj-adv">ADVERB vs. ADJECTIVE </ref>(AV0 vs. AJ0, AV0 vs. AJC ) <lb/>
 Section 3 <ref target="#m3rrr-dar">DETERMINER-PRONOUN vs. ADVERB</ref><lb/>
 Section 3 <ref target="#m3prep-avp">ADVERB vs. PREPOSITION </ref><lb/>
 Section 4 <ref target="#m4about"><hi rend="italic">about</hi></ref>, <ref target="#m4as"><hi rend="italic">as</hi></ref>, <ref target="#m4but"><hi rend="italic">but</hi></ref>, <ref target="#m4like"><hi rend="italic">like</hi></ref>,
 <ref target="#m4little"><hi rend="italic">little</hi></ref>, <ref target="#m4much"><hi rend="italic">much</hi></ref>, <ref target="#m4no"><hi rend="italic">no</hi></ref>, <ref target="#m4right"><hi rend="italic">right</hi></ref>,
 <ref target="#m4so"><hi rend="italic">so</hi></ref>, <ref target="#m4well"><hi rend="italic">well</hi></ref>, <ref target="#m4when"><hi rend="italic">when</hi></ref>
 </q></p> -->
 
 </div>
 
 <div xml:id="m2art">

 <head>Articles, determiners &amp; pronouns</head>

 <p>Articles, definite or indefinite, are tagged
 <code>AT0</code>. Pronouns which act as determiners of various kinds
 (all, which, your etc.) are given tags <code>DPS</code>,
 <code>DT0</code>, or <code>DTQ</code>, and distinguished from
pronouns which do not have a determiner function. These are marked
using one of the tags <code>PNP</code>, <code>PNI</code>,
<code>PNQ</code>, or <code>PNX</code> depending on their function.</p>

<list type="gloss"> 
 <label>Articles</label>
<item>All articles are tagged <code>AT0</code>. An article is  defined
here as a determiner word which typically begins a noun phrase, but
which cannot occur as the head of a noun phrase. 
 Examples include <hi rend="italic">a/an</hi>, <hi rend="italic">the</hi>, <hi rend="italic">no</hi> and
 <hi rend="italic">every</hi>:
<q rend="display">  Have a_AT0 break<lb/> Every_AT0 year<lb/>There's no_AT0
time</q>
</item>
<label>Determiners</label>
<item>Recognising that there is a high degree of formal and functional overlap between determiners and pronouns, we have conflated under the D-- heading
 words that are capable of either function. We distinguish three classes of determiner pronouns:
<list type="gloss">
<label>Determiner-Pronoun</label>
<item>Words such as <hi rend="italic">few</hi>, <hi rend="italic">both</hi>, <hi rend="italic">another</hi> are
tagged <code>DT0</code>:
<q rend="display"> free secondary education for all_DT0 [ECB.1610]<lb/> Few_DT0 diseases are incurable  [GV1.1129]<lb/> for the benefit of the few_DT0  [HHX.10183]</q></item>
<label>Interrogative determiner-pronoun</label> 
 <item>The  wh- (interrogative) determiner-pronoun is tagged <code>DTQ</code>. <hi rend="italic">Which</hi> and <hi rend="italic">what </hi> are always tagged <code>DTQ</code>:
 <q rend="display"> Which_DTQ country do you live in? [A7N.979]<lb/> And she
 didn't say which_DTQ? [KCF.351 ]<lb/> What_DTQ time is it? [A0N.406]
  </q></item>
<label>Prenominal possessive determiner pronoun</label>
<item><p>Forms such as <hi rend="italic">my</hi>, <hi rend="italic">your</hi>, etc are always tagged
<code>DPS</code>, for example:
<q rend="display"> my_DPS hat</q></p>
 <p> Compare this with the nominal use:
<q rend="display"> That is your way. This is mine_PNP [ASD.726-7]</q>
 </p></item>
</list> 
<!-- <p>[ <ref url="detpnn.htm">View list of Determiner-Pronoun tagged words and compounds.</ref> ] </p>-->
</item>

<label>Pronouns</label>

<item> <p>Tags beginning <code>P--</code> indicate pronouns which do not share the determiner function, for example 
 <hi rend="italic">I</hi>, <hi rend="italic">it</hi> , <hi rend="italic">anyone</hi>. 
 Pronouns are differentiated according to whether they are: 
 <list><item>
 personal (<code>PNP</code>), eg <hi rend="italic">I</hi>, <hi rend="italic">him</hi>, <hi rend="italic">they</hi>, <hi rend="italic">us</hi>. Note also: <hi rend="italic">it</hi> is included here.
 </item>
<item>  reflexive personal (<code>PNX</code>), eg <hi rend="italic">herself</hi>,
<hi rend="italic">themselves</hi></item>
<item> indefinite pronouns (<code>PNI</code>), <hi rend="italic">anyone</hi>, <hi rend="italic">everything</hi>, 
 <hi rend="italic">nobody</hi>  </item>
 <item>interrogative (<code>PNQ</code>), eg <hi rend="italic">who</hi>, <hi rend="italic">whoever</hi>
 </item></list>
 </p>
<!-- 
 <p>[ <ref url="pronoun.htm">View list of Pronoun-only words and compounds</ref> ] </p>-->
</item>
 

 <label>Relative pronouns</label>
 <item>
 <p><hi rend="italic">Which</hi> as a relative (or interrogative) pronoun is grouped with the
 other determiner-pronouns, and tagged <code>DTQ</code>:
 <q rend="display"> Give 4 details which_DTQ should appear on an order form [HBP.417] </q></p>
 
 <p>Meanwhile, <hi rend="italic">that</hi> as a relative clause complementizer is treated with 
 <hi rend="italic">that</hi> as a <ref target="#compclause">complement clause complementizer</ref>, and tagged <code>CJT</code>:
<q rend="display"> I got some currants that_CJT are left over [KST.3733]
<lb/> this girl that_CJT Claire knows [KC7.1101]<lb/> He dismissed reports that_CJT his party was divided over tactics [A28.11]<lb/> We both knew that_CJT enough was enough. [FEX.268]  </q></p>
 <p>Note, however, that <hi rend="italic">that</hi> takes the tag <code>DT0</code> when it functions as a demonstrative pronoun or determiner:
<q rend="display">Look at that_DT0 bear! [KP8.1547]<lb/> I guess I was sad about that_DT0.[BMM.239] </q></p>

 </item>
 
 <!-- <p> For D - - tagged words, the main source of ambiguity is
      between determiners and adverbs. See Disambiguation Guide<q rend="display"><lb/>
 Section 3: <ref target="#m3rrr-dar">DT0 vs. AV0</ref> (illustrated by <hi rend="italic">more</hi> and <hi rend="italic">less</hi>) and <lb/>
 Section 4: <ref target="#m4much"><hi rend="italic">much</hi></ref>;
 <ref target="#m4no"><hi rend="italic">no</hi></ref>; <ref target="#m4that"><hi rend="italic">that</hi></ref></q></p> -->

</list></div>
 
 <div xml:id="m2prep">
 
<head>Prepositions and prepositional adverbs</head>
 
<!--<p><hi rend="italic">Basic tags: </hi>
 <q rend="display"><lb/> PRP PRF AVP
 <lb/><hi rend="italic">Ambiguity tags: </hi>
 <lb/>PRP-AVP = Prep more probable; AVP-PRP = Prep less probable</q></p>-->
 <!-- start prep list -->
 
<list type="gloss">
<label>Prepositions</label>
 <item>Most prepositions are tagged <code>PRP</code>, including a
 large number of multiword items. Examples include:
 <q rend="display">at_PRP the Pompidou Centre in_PRP Paris [A04.325]<lb/> I
 use humour as_PRP a protection [FBL.356]<lb/> Heard about_PRP this
 have you? [KE6.9556]<lb/> <hi>According to_PRP</hi> ancient tradition,
 ...[A04.784]<lb/> Many disputes are dealt with by bodies <hi>other
 than_PRP</hi> courts. [F9B.4]<lb/>  Nice walls and a big sky to look
 at_PRP. [A25.122] </q>
 </item>
<label>Of</label> 
 <item>The preposition <hi rend="italic">of</hi> is assigned a special tag <code>PRF</code> 
 because of its frequency and its almost exclusively postnominal function. Examples:
 <q rend="display">a couple of_PRF cans of_PRF Coke[ AJN.283]<lb/> DNA
 consists of_PRF a string of_PRF four kinds of_PRF bases [AE7.107]
 </q> Note that numerous <ref
   target="#multiwords">multiwords</ref> contain <hi rend="italic">of</hi>, 
 eg <hi rend="italic">in front of</hi>, <hi rend="italic">in light of</hi>, <hi rend="italic">by means of</hi>, etc.
<!-- [ <ref url="prep.htm">View list of Preposition-tagged words and compounds</ref> ] --></item>

<label xml:id="prepAdv">Prepositional adverbs/particles</label>
 
 <item>Preposition-type words which have no complement are tagged <code>AVP</code>. 
 Typical uses of <code>AVP</code> are in phrasal verb constructions, or when it functions as a 
 place adjunct:
 <q rend="display"> We gave up_AVP after two hours. [KSV.1029]<lb/> there were a lot of horses around_AVP. [HR7.3101] </q>
 <!--
 <p>The following is a list of possible AVP words: 
 <hi rend="italic"> 
 'bout, about, along, around, back, by, down, in, off, 
 on, out, over, round, through, thru, to, under, up</hi></p>
 
 
 <p>Of the above list, all except <hi rend="italic">back</hi> allow also a prepositional reading. 
 Thus t=-->There are many instances of ambiguity between <code>PRP</code> and <code>AVP</code>. 
 </item></list>
<!--See further - Disambiguation Guide:

      Section 3 <ref target="#m3prep-avp">Preposition
      vs. Prepositional Adverb vs. Locative Adverb </ref> (PRP vs. AVP
      vs. AV0)<q rend="display"><lb/>
 Section 4 <ref target="#m4but"><hi rend="italic">but</hi></ref>, <ref target="#m4about"><hi rend="italic">about</hi></ref>
 --> 
</div>
 <!-- prep-->
 <div xml:id="m2conj"> 
 
 <head>Conjunctions</head>
<!--
 <p><hi rend="italic">Basic tags: </hi>CJC CJS CJT
 <eg><lb/><hi rend="italic">Ambiguity tags: </hi>CJS-PRP PRP-CJS</q></p>
 -->
 <!-- start conj list -->

<list type="gloss"> 
 <label xml:id="cjc">Co-ordinating conjunction</label>
<item>Co-ordinators such as <hi rend="italic">and</hi>, <hi rend="italic">or</hi>, <hi rend="italic">but</hi>,
<hi rend="italic">nor</hi> etc are tagged  <code>CJC</code>:
 <q rend="display"> Fish and_CJC chips<lb/> James laughed and_CJC spilled wine. [A0N.136]<lb/> She was paralysed but_CJC she could still feel the pain. [FLY.529] </q></item>
 
 <label xml:id="CJS">Subordinating conjunction</label>
 <item>All subordinating conjunctions are all tagged <code>CJS</code>
 and introduce one of:

 <list type="gloss">
 <!-- start cjslist -->
 <label>an adverbial clause (of time, reason, condition etc.)</label>
 <item><q rend="display">  "When_CJS you 've done it , you should go
 home,"[CRE.949]<lb/> 
I still stayed there after_CJS I heard the shooting [HW8.3263]<lb/>  As_CJS you may know Scorton will again enter the Best Kept Village competition in 1992 [HPK.768]<lb/>  Do send me an interim copy as_CJS soon as you can [HD3.69]<lb/>  If_CJS it's wet just take your time. [KCL.554]</q></item>
 
 <label>a comparative clause</label>
<item>introduced by <hi rend="italic">than</hi> or
 <hi rend="italic">as</hi>, and occurring with or without ellipsis: 
<q rend="display"> It was worse than_CJS she could have imagined.[CH0.1315]<lb/>
  ...apparently we eat more chocolate than_CJS any other country.[G3U.1000] <lb/> "it's as good as_CJS it's going to get."[K9K.199] <lb/> make the transporter as light as_CJS possible. [CA1.1113] </q></item>
 
 <label>a nominal wh-clause</label>
<item> containing <hi rend="italic">whether</hi> or <hi rend="italic">if</hi>
<q rend="display"> Can you tell me whether_CJS ivies do damage
trees. [C9C.720] </q>
</item></list></item>
 <!-- end cjslist -->
 
 <label xml:id="compclause">Complementary clause</label>
 <item>The conjunction <hi rend="italic">that</hi> at the start of a clause introducing reported speech and thought, and also 
at the start of a relative clause is tagged <code>CJT</code>:
 <q rend="display">  Historians knew that_CJT this was nonsense.[G3C.363]<lb/>China announced that_CJT it was ending martial law in the Tibetan capital Lhasa. [KRU.95]<lb/> The problem that_CJT he was having was that_CJT she was his legal wife 's sister [HE3.210]   </q>
<!-- <p>[ <ref url="conj.htm">View list of Conjunction words and compounds</ref> ] </p>-->

 </item></list>
 <!-- end conj list -->
 
 <!-- <p>See further - Disambiguation Guide <q rend="display"><lb/>
 Section 4 <ref target="#m4as"><hi rend="italic">as</hi></ref>, 
 <ref target="#m4so">
 <hi rend="italic">so</hi></ref>, 
 <ref target="#m4that">that</ref></q></p> -->
 </div> <!--conj-->
 
 
 
 
 <div xml:id="m2num">
 <head>Numerals</head>
 <p>Cardinal numbers and similar items are tagged
 <code>CRD</code>. Ordinal numbers and similar items are tagged <code>ORD</code>.
 </p>
 <list type="gloss">
 <label>Numbers and fractions</label>
<item>All cardinal numbers, numeral nouns, fractions and so on take the tag <code>CRD</code>, 
 whether they are written as words or numerals, and whether functioning nominally or prenominally. 
 Examples: <q rend="display">5_CRD out of 10_CRD[CGM.525]<lb/>
one_CRD striking feature of the years 1929-31_CRD [A6G.134]<lb/>
his first_ORD innings, when he scored forty-two_CRD, with seven_CRD
fours_CRD [KJT.128]<lb/>
Hundreds_CRD of people audition each year  [K1S.2239]<lb/>
 About a dozen_CRD there.  [HEU.131]<lb/>
 </q></item>
 <label xml:id="m2ord">Ordinal numbers and similar</label>
 <item>Ordinal numbers are assigned <code>ORD</code> in all syntactic positions, including adverbial positions, 
 as in <q rend="display">  We only came fourth_ORD in the county championship last_ORD year[EDT.1629] </q>
Note that <code>ORD</code> is also assigned to less overtly numeric words like <hi rend="italic">next</hi> and <hi rend="italic">last</hi>, even in clear adverbial, adjectival or nominal contexts. This is because <hi rend="italic">next</hi> and <hi rend="italic">last</hi> function like ordinals both syntactically and semantically. </item>
 <label xml:id="currency">Currency and measurement expressions</label>
 <item>Measurement expressions, consisting of numbers and a unit of measurement of some kind 
 (together as one word), are assigned a noun tag, usually <code>NN0</code> (neutral for number) or <code>NN2</code> (plural): 
 <q rend="display">6kg_NN0 <lb/>£600_NN0 <lb/>12.5%_NN0 </q>
 </item>
<label>formulae</label>
<item> Other sequences of numeric and alphabetic characters are assigned <code>UNC</code> 
 (unclassified) tags: <q rend="display"> Figure 2b_UNC [FTC.250]<lb/>Serial no. S835508_UNC  [C9H.2282]<lb/>A4_UNC sheet of paper [CN4.296]<lb/>Mark drove home along the M1_UNC [AC2.2210] </q></item>
 </list>
 <!-- end num list -->
 <!--
 <p>The main ambiguity in this category is between <ref target="#m4one"><hi rend="italic">one</hi></ref>
 functioning as a cardinal number (<code>CRD</code>) and as a pronoun (<code>PNI</code>). </p>-->
 </div> <!-- numerals-->

 <div xml:id="m2misc">
 
 <head>Miscellaneous other tags</head>

<!-- <p>The following tags are included here:
  <ref target="#m2misc_ex0">EX0</ref> | <ref target="#m2misc_itj">ITJ</ref> |
  <ref target="#m2misc_pos">POS</ref> | <ref target="#m2misc_to0">TO0</ref> | 
  <ref target="#m2misc_xx0">XX0</ref> | <ref target="#m2misc_zz0">ZZ0</ref> | 
   <ref target="#m2misc_unc">UNC</ref> 
 </p>-->
 <list type="gloss">

 <label xml:id="m2misc_ex0">Existential  <hi rend="italic">there</hi></label>

 <item>The tag <code>EX0</code> is used for <hi
 rend="italic">there</hi> when it <!--does not carry any real meaning: it-->
 merely states that something exists or existed. It occurs at the
 beginning of a clause and is usually followed by the verb <hi
 rend="italic">be</hi> and an indefinite noun phrase; for example <q
 rend="display"> There_EX0 was a long pause and then a smile
 [A4H.416]<lb/> Waiter! Waiter! There_EX0's an awful film on my soup!
 [CHR.657-9]<lb/> There_EX0 appears to be little alternative
 [ECE.2139]<lb/>
 </q>
 Compare this with <hi rend="italic">there</hi> when it has a clear locative meaning ('in/to that place'):
<q rend="display">  Don't stand there_AV0 grinning like a stuck pig [C85.1553] </q>
 </item>
 <label xml:id="m2misc_itj">Interjection</label>
 <item>The tag <code>ITJ</code> is used for any interjection:
<q rend="display">  Hello_ITJ, Nell.<lb/> Oi_ITJ - come here!<lb/> Yes_ITJ , please_AV0 do
  <lb/> No_ITJ not_XX0 yet_AV0 </q>
( For the distinction between ITJ and the unclassified tag, UNC, see <ptr target="#m3itj-unc"/>)
 </item>

 <label xml:id="m2misc_pos">Genitive morpheme</label>
<item>The tag <code>POS</code> is used for the
genitive morpheme <hi rend="italic">'s</hi> (singular) or <hi rend="italic">'</hi> 
  (plural after an <hi rend="italic">s</hi>): 
<q rend="display">teacher_NN1 's_POS pet <lb/>teachers_NN2 '_POS pet  </q>
Note the lack of space between the noun and the following <code>POS</code>, as <hi rend="italic">'s</hi> is 
 tokenized in the same way whether it represents a genitive or a contracted verb. See further 
 on tagging of <hi rend="italic">'s</hi> in <ptr target="#m4apostrophes"/></item>
 <label xml:id="m2misc_to0">Infinitive marker</label>
<item>The tag <code>TO0</code> is used for 
the infinitive marker. This includes elliptical uses.
 
<q rend="display">"Do you want to_TO0 talk about it?" [EFG.1935]<lb/>In the summer holidays I can , I can get up early if I want to_TO0 . [KPG.4153]<lb/>   </q>
Note the morphological variation of <hi rend="italic">to</hi> in the following colloquial forms: 
<q rend="display"> We got_VVN <emph>ta</emph>_TO0 go<lb/>
  We wan_VVB<emph>na</emph>_TO0 stay.</q></item>

 <label xml:id="m2misc_unc">Unclassified words</label>
<item>The tag <code>UNC</code>
is used for unclassified (or unclassifiable) words. It is applied in contexts where no other wordclass tag 
 seems appropriate, including 
  <list> <!-- start second ulist -->
 <item><emph>"Noise words" and pause fillers</emph> in spoken utterances; imitations of animal or machine sounds: 

 <q rend="display">blah_UNC blah_UNC blah_UNC    <lb/>er_UNC I think so </q>
 </item>
 <item>
 <emph>Certain fused forms</emph> (in written or spoken data) for which no other tag would be appropriate:
<q rend="display">Methinks_UNC <lb/>That ai_UNC n't_XX0 right.<lb/>0.5 cm
increments/30_UNC seconds [HWT.282]<lb/>Fits with most
lap/diagonal_UNC seat belts. [BNX.392]<lb/></q></item>

<item><emph>Truncated words in speech</emph>. Partial words that are not completed by a
speaker, whether through hesitation or an interruption,  are also
usually marked with the XML tags <gi>trunc</gi>; for example 
the partial word <hi rend="italic">bathr</hi> in the following:
 
<q rend="display">The bathr_UNC data. er you can't beat a white bathroom suite anyway. [KCF.771]  </q>
</item>
 <item><emph>Partial repetitions of multiwords</emph> in spoken data.
  <p>Occasionally in spoken data, when a <ref
   target="#multiwords">multiword sequence</ref> is used, it appears to be repeated, but only partially so. 
 In the following example, the orthographic word <hi rend="italic">sort</hi> is used twice:
 
<q rend="display">  we're going to sort sort of summarize...  [G5X.106]</q>
We treat the first <hi rend="italic">sort</hi> as an incomplete multiword, and tag it <code>UNC</code> (rather like truncated words, above). The complete multiword <hi rend="italic">sort of</hi> is tagged AV0, as normally.
 
<q rend="display">  we're going to sort_UNC <hi>sort of_AV0</hi> summarize... </q>

 <!--multi --></p></item></list> See <ptr target="#m5"/> for
      further examples; for the distinction between <code>UNC</code>
      and <code>ITJ</code> see <ptr target="#m3itj-unc"/>.  
 </item>

 <label xml:id="m2misc_xx0">Negative particle</label>
 <item> <code>XX0</code> is the tag for the negative particle <hi rend="italic">not</hi>, and also for its contracted or fused form,
<q rend="display"> Brown did_VDDn't _XX0 see it that way. [A6W.338]<lb/>no, that is not_XX0 correct. [JK0.257]  
 </q>
 </item>
 <label xml:id="m2misc_zz0">Letter</label>
 <item> <code>ZZ0</code> is used for a free-standing letter of the
 alphabet such as <hi rend="italic">A, X, x, p, r </hi>. If however, the letter
 clearly represents a separate word, or an abbreviation of a separate
 word, we have tried to assign the appropriate POS-tag for the full
 form of that word, rather than <code>ZZ0</code>.For example, 
 
 <list>
 <item> <hi rend="italic">I</hi> as personal pronoun is <code>PNP</code> rather than ZZ0. </item>
 <item><hi rend="italic">a</hi> as indefinite article is tagged <code>AT0</code> </item>
 <item><hi rend="italic">F</hi> as in <hi rend="italic">John F. Kennedy</hi> is tagged <code>NP0</code> </item>
 <item><hi rend="italic">v</hi> meaning 'versus' is tagged <code>PRP</code> in
<q rend="display">Italy  v_PRP New Zealand ... Hungary v_PRP Thailand [A1N.507].</q>
  Although the same should apply to <hi rend="italic">v.</hi> the
  full-stop has sometimes incorrectly produced a 
 new sentence break. (See eg  CHS.1076, EB2.19, EDL.313)
 </item>
 <item>In spoken texts, words which are spelt out by the speaker are transcribed letter by 
 letter, and each letter is tagged <code>ZZ0</code>. 
<q rend="display">  I_ZZ0 B_ZZ0 M_ZZ0 compatible [JYM.6]<lb/>children who go to the E_ZZ0 N_ZZ0 T_ZZ0 clinic [KB8.3807]<lb/> </q>
 </item></list>
<!--  <p>See also <ptr  target="#m5"/>.
  </p>
-->
 </item>
 </list> <!-- end misc list -->
 </div><!--Intro Word class -->
 
 <div xml:id="m3">
 <head>Disambiguation Guide</head>
 
 <p>The following is a guide to resolution of the most common tagging
 ambiguities. It states the principles by which we have drawn the line
 between the "correct" and the "incorrect" assignment of a tag in
 particular contexts (as applied in the <ref
 target="#errorRates">report on tagging error rates</ref>.) Note that
 in the next two sections, we also cite examples where the POS-tagging
 in the corpus is less reliable and does not match that given for the
 citation. In such cases we append the actual tag in the corpus to the
 file reference with an asterisk. Eg. under Adjective vs Adverb (next
 section), the preferred tag for <hi rend="italic">long</hi> is <code>AV0</code>, but the actual
 tag is ambiguous <code>AV0-AJ0</code>: <q rend="display"> You're not supposed to keep
 medicine that long_AV0. [H8Y.1976 *AV0-AJ0] </q></p>

 <p>Note also that in this section we use a number of invented
 examples (in addition to corpus citations) to clarify the distinction
 between categories.
 </p>

 <div xml:id="disambigTagpair">

 <head>Disambiguation by Tag Pair</head>
 
 
 <div xml:id="m3adj-adv">
 <head>Adjective vs. adverb</head>
 
 <p>
 After a verb or an object, there is sometimes a difficult choice
 between <code>AJ0</code> and <code>AV0</code>, or between <code>AJC</code> and <code>AV0</code>. e.g.:<q rend="display"> 
 We arrived tired_AJ0, but safe_AJ0 [CCP.529] </q></p>
 
 <p> Here, both <hi rend="italic">tired </hi>and <hi rend="italic">safe</hi> are AJ0. The main test is to see whether one can express the relation between these words
 and their logical subjects using the verb <hi rend="italic">be: They arrived tired but safe</hi> implies 'They were tired but safe'. The
 word tagged <code>AJ0</code> refers to a property of a noun, rather than to a
 property of an event or situation. Contrast:
<q rend="display"> After a little he remembered it and sang out loud_AV0.[A0N.1144]-->  </q></p>
 <p>
 This sentence does not imply that he <emph>was</emph> loud,
 but is more or less equivalent to <hi rend="italic">He sang out loudly</hi>. It means that his <emph>singing</emph> was loud.
 </p>
 <p>
 It follows that when, in colloquial English, a word which we normally
 expect to be an adjective is used as an adverb, we should tag it <code>AV0</code>:
 <q rend="display"> You did great_AV0 though. [HH0.3248 *AV0-AJ0] </q>
 </p>
 <p> Here is another pair of examples, where the <code>AJ0/AV0</code> word follows
 an object:
<q rend="display">  everyone below 25 grew their hair too long_AJ0.  [ARP.590 *AV0-AJ0]<lb/> (i.e. 'their hair was too long'.) <lb/>
  Try not to keep her too long_AV0. [FAB.3620 *AV0-AJ0] <lb/> (i.e. NOT 'she will be too long.') 
 <!-- old examples -->
 <!-- <p><hi rend="italic">I thought the game too long_AJ0. </hi>(i.e. 'the game was too long'.) -->
 <!-- <p> <hi rend="italic">The dried fish goes bad_AJ0 if you keep it too long_AV0.</hi> -->
 <!-- <p> <hi rend="italic">You're not supposed to keep medicine that long_AV0.[H8Y.1976 *AV0-AJ0] -->
 </q></p>
 <p> Also note the similar distinction between <code>AJC</code> and <code>AV0</code>:<q rend="display">
 They'll have to make the taxes higher_AJC.  ('the taxes will be higher') <lb/>
  We can make this piece higher_AJC if you want to. [BNG.2268]<lb/>  
  You'll have to aim higher_AV0. (NOT 'you will be higher') <lb/>
  You should aim higher_AV0 [ACN.984 *AJC] </q></p>
 
 <p>Similar considerations arise for the choice between <code>AJS</code> and <code>AV0</code>:
<q rend="display"> I thought it best_AJS to call. [AT4.3239] <lb/>
I liked the cartoons best_AV0 [CAM.194]</q></p>
 </div>

 <div xml:id="m3adj-nn">
 <head>Adjective vs. noun</head>

 <p>There are many words in English which can be tagged either
 adjective (<code>AJ0</code>) or noun (<code>NN1</code>). Colour words like <hi rend="italic">black, white
 </hi>and <hi rend="italic">red</hi> are fairly consistent in allowing the two tags,
 and may be used to illustrate the difference. In attributive
 (premodifying) or predicative (complementing) positions without
 further modification these words are normally adjectives: 
<q rend="display">a  white_AJ0 screen, The screen is white_AJ0. </q>
When the word is the  head of a noun phrase, on the other hand, it is a noun:
 <q rend="display">Red_NN1 is my favourite colour. <lb/>They painted the wall
 a brilliant white_NN1.</q>
</p>
 <p> Sometimes a word cannot be used predicatively as an adjective,
 but can occur attributively in a way which suggests adjectival
 use. For example, <hi rend="italic">past</hi> and <hi rend="italic">present</hi> are
 adjectives in <q rend="display">
 All past_AJ0 and present_AJ0 employees of the branch are invited. [K99.216] </q></p>
 <p> We do not find <hi rend="italic">present</hi> or similar words being used as predicative
 adjectives, however: <q rend="display"> 
 *These needs are past, present, and future.
 </q></p>
 <p> (Note that <hi rend="italic">present</hi> can be used as a predicative adjective
 meaning the opposite of <hi rend="italic">absent</hi>; but this meaning is not comparable
 to the temporal meanings of <hi rend="italic">past, present</hi> and <hi rend="italic">future</hi>
 above.)</p>
 <p>
 Contrast K99.216 above with cases where <hi rend="italic">past, present</hi> etc.
 are heads of noun phrases, e.g. following the definite article,
 and are clearly nouns:
<q rend="display"> You're living in the past_NN1. [HGS.1045] <lb/>I don't even want to think about the future_NN1. [JY4.2864] </q></p>
 <p>
 The only reason for treating <hi rend="italic">past</hi> and <hi rend="italic">present</hi> in
 the example above as adjectives is that they have an institutionalized
 meaning as modifiers, which is rather different from the meaning
 they have as nouns. Further examples of this type are words such
 as <hi rend="italic">model</hi> in <hi rend="italic">model behaviour, giant</hi> in <hi rend="italic">a giant
 caterpillar</hi> and <hi rend="italic">vintage</hi> in <hi rend="italic">vintage cars</hi>. 
 </p>
 <p> Words ending in <hi rend="italic">-ing</hi> are a particular problem: when they
 premodify a noun, they can be tagged either <code>NN1</code> (noun) or <code>AJ0</code> (adjective).
 Contrast:
<q rend="display">     new spending_NN1 plans [CEN.5922]<lb/> a working_AJ0 mother [ED4.153]  <lb/>
   his reading_NN1 ability [CFV.1897]  <lb/>in the coming_AJ0 weeks [HKU.1333] 
 </q></p>
 <p> The guideline is as follows.
 If <hi rend="italic">X-ing + Noun</hi> is equivalent in meaning to <hi rend="italic">Noun
 who/which X-es</hi> (or <hi rend="italic">X-ed</hi> or  <hi rend="italic">BE + X-ing</hi>), then <hi rend="italic">X-ing</hi> is an adjective (<code>AJ0</code>).
 That is, a word ending <hi rend="italic">-ing</hi> is an adjective when it is the
 notional subject of the noun it premodifies. For example:
<q rend="display"> 
 two smiling_AJ0 children [HTT.743]  ('two children who are smiling')   </q></p>
 <p>
 In other cases, <hi rend="italic">X-ing</hi> is generally a noun (<code>NN1</code>). In such cases, it is often possible to paraphrase <hi rend="italic">X-ing + Noun</hi> 
 by a more explicit phrase in which <hi rend="italic">X-ing</hi> is clearly a noun:
 <q rend="display"> new spending_NN1 plans ('new plans for spending')<lb/> his reading_NN1 ability ('his ability in reading')  </q></p>
 <p>
 Further examples:<q rend="display"> 
 a mating_AJ0 animal [GU8.2142]<lb/> the mating_NN1 game [ECG.336 *AJ0-NN1] <lb/> a falling_AJ0 rate of unemployment [KR2.2129] <lb/>slimming_NN1 tablets. [KCA.941 *NN1-VVG]  </q></p>
 </div>

 <div xml:id="m3rrr-dar">
 <head>Determiner-pronoun vs. adverb</head>
  <p><hi rend="italic">More</hi> and <hi rend="italic">less</hi> can be assigned to either of the tags
 <code>DT0</code> or <code>AV0</code>. The difference between them is that <code>DT0</code> is for noun-phrase-like
 (and determiner-like) uses of the word in question, whereas <code>AV0</code>
 is for adverbial uses. The two can be hard to distinguish, particularly
 after a verb:
 <q rend="display"> (a) You should relax more_AV0. <lb/> (b) You should spend more_DT0.
 
 </q></p>
 <p> Since <hi rend="italic">relax</hi> is an intransitive verb in (a), <hi rend="italic">more</hi>
 cannot be a noun phrase following it. Instead, <hi rend="italic">more</hi> can
 be paraphrased roughly as 'to a greater extent' or 'to a greater
 degree'. On the other hand, <hi rend="italic">spend</hi> in (b) is a transitive
 verb, and so <hi rend="italic">more</hi> is a determiner-pronoun form following
 it. As confirmation of this, note that sentence (b) could be turned
 into a passive with <hi rend="italic">more</hi> as subject: <hi rend="italic">More should be
 spent...</hi>. There are unfortunately some verbs for which the
 distinction is less clear than in the above examples, e.g.:<q rend="display">
  You should eat more. <lb/>You should read more. <lb/>You should smoke less.
 
 </q></p>
 
 <p>
 In these cases, the verb may be used transitively or intransitively
 with almost identical meanings, so that the syntactic structures
 of the immediate and/or surrounding context are the only clues
 as to which is the case:
 <q rend="display">Do you smoke? (Intransitive)<lb/>How many do you smoke in a week? (Transitive)
  </q></p>
 <p>
 Contrast (c) and (d) below:
<q rend="display">  (c) <hi rend="italic">At the moment we have 23 fixtures per season. Personally, I would rather play more_DT0.</hi> <lb/> (d) <hi rend="italic">You should work less and play more_AV0.</hi>  </q></p>
 <p>
 (In (d) the adverb <hi rend="italic">more</hi> has roughly the meaning of 'more
 often'.)</p>
 <p>
 Note. The automatic disambiguation of determiners and adverbs is not reliable, because transitivity has not been encoded in the tagger. Sentences like (c) and (d), where <hi rend="italic">more</hi> follows the verb at end of a sentence, are invariably tagged <code>AV0</code>.
 </p>
 </div> <!-- det pron -->
 <div xml:id="m3adj-part">
 
 <head>Adjective vs. participle </head>
 <p>
 Another area of borderline cases is the tagging of words as adjectives
 (<code>AJ0</code>) or as participles (<code>VVG</code> or
 <code>VVN</code>).</p>

<p>One test is to see whether a degree adverb like <hi rend="italic">very</hi> can be inserted in front of the
 word: e.g. in <hi rend="italic">We were very surprised</hi>, <hi rend="italic">surprised</hi> is an <code>AJ0</code>.
</p>
<p> Another test, having the opposite effect, is to see
 whether there is an agent <hi rend="italic">by</hi>-phrase following the word in
 <hi rend="italic">-ed</hi> or <hi rend="italic">-en</hi>. If so it is a <code>VVN</code>: <q rend="display">We were
 surprised_VVN by pirates.</q> Even where it is not present, the
 possibility of adding the <hi rend="italic">by-</hi>phrase, without changing the
 meaning of the word, is evidence in favour of <code>VVN</code>. (However, this
 criterion can clash with the preceding one — since it occasionally
 happens that an <hi rend="italic">-ed</hi> word is both preceded by an adverb like
 <hi rend="italic">very</hi> and followed by a <hi rend="italic">by-</hi>phrase: E.g. <hi rend="italic">I was so
 irritated by his behaviour that I put the phone down.</hi> When these
 do occur, we give preference to <code>AJ0</code>.)
</p> 
<p>A third test is negative: to see whether the word in question
 can be placed before a noun. e.g.: 
<q rend="display"> 
  The effect is lasting_AJ0 (compare a lasting_AJ0 effect).<lb/>
  The door is locked_AJ0 (compare the locked_AJ0 door.)<lb/> </q>
 This shows that <hi rend="italic">lasting</hi> or <hi rend="italic">locked</hi> can easily be (but need not be) an <code>AJ0</code>. If the word could not be placed (with
 the same meaning) before the noun, this would be evidence that the word is a participle.</p> 

<p>Even though an <hi rend="italic">-ing</hi> word is normally a <code>VVG</code> after
 the verb <hi rend="italic">be</hi>, it is generally treated as an <code>AJ0</code> before a noun:
<q rend="display">  The man was dying_VVG. [HTM.1494 *VVG-AJ0]<lb/>
  the dying_AJ0 man. [FSF.1787] </q>
</p>
<p> However, when the <hi rend="italic">-ing</hi> or <hi rend="italic">-ed</hi> forms part of
 a premodifying phrase, the <code>VVG</code> or <code>VVN</code> tag is preferred:
<q rend="display">  an interest_NN1 earning_VVG account<lb/> a hypothesis_NN1 driven_VVN approach  
</q>
</p> <p>
 In these examples the <code>NN1+VVG/VVN</code> sequence has the character of a premodifying adjective compound. We can therefore imagine the
 two words bracketed together forming an adjective: <hi rend="italic">an interest-earning_AJ0 account</hi>. But within the adjective, the <code>VVG</code> and <code>VVN</code> tags retain their verbal character, with the initial noun acting as object of the verb (cf. <hi rend="italic">the account earns interest</hi>).
 </p><p>
 The same applies when the premodifying compound phase is noun-like:
<q rend="display">  a shanty_NN1 singing_VVG competition[K4W.2952]  </q>
 </p> 
<p> If the verb <hi rend="italic">be</hi> can be replaced by another verb such
 as <hi rend="italic">seem</hi> or <hi rend="italic">become</hi>, without changing the meaning
 of the following <code>AJ0 / VVN</code> word, this is a strong indication that
 the construction is not properly a passive, and that the word
 is an <code>AJ0</code>:<q rend="display">  <hi rend="italic">The building was infested_AJ0 with cockroaches</hi> <lb/> (cf.: <hi rend="italic">The building seemed/became infested with cockroaches</hi>)  
 </q><!-- unfortunately all examples of infested with cockroaches in
 BNC are tagged as VVN!  (LB) -->
</p>
<p> A further distinction which can be used to test with 'event' verbs is that the AJ0 refers to a 'resultant state', whereas the
 VVN refers to an event:
<q rend="display">  Bill was married_AJ0. (i.e. he was not single) <lb/>
  Bill was married_VVN to Sarah on the 15th May. (i.e. the actual event)  </q>

 This is a manifestation of the general semantic character of adjectives
 (which typically refer to states or qualities) and verbs (which
 typically refer to events or actions).</p>
 <p>
 However, this criterion is not definitive, as <code>VVG</code> and <code>VVN</code> can also sometimes refer to states, when the meaning of the verb is stative: 
<q rend="display"> She is not disturbed_VVN by that sort of threat.<lb/> The tourists were standing_VVG around a map of the city.</q></p>
 
<p> Finally, here is a test which clearly identifies an <hi rend="italic">-ing</hi> form as a verb.
 A verb takes following complements such as a noun phrase, an adjective or an adverbial. These cannot follow the same word as adjective. E.g.:
<q rend="display"> Are you expecting_VVG someone?[G01.2610]<lb/> 
  The arithmetic is looking_VVG good. [K1M.3611] <lb/> 
  Turning_VVG suddenly, she ran for the safety of the car [CK8.297] 
 </q></p> 
  <p> Contrast:
<q rend="display">  His manner was insulting_AJ0.  </q>
 where <hi rend="italic">insulting</hi> could not normally be followed by an object:
<q rend="display">  * insulting us. </q>
 </p>
 <!-- end adjpart list --> 
</div> <!-- adj - particle -->
 <div xml:id="m3prep-avp">
 
 <head>Preposition vs. prepositional adverb vs. general adverb</head>
 <p>
 This kind of ambiguity occurs frequently, particularly in spoken texts. Compare:
<q rend="display"> (a) She ran down_PRP the hill.
<lb/>(b) She ran down_AVP her best friends. </q></p>
 <p>
 In (a), <hi rend="italic">down</hi> is a preposition, because: <list>
 <item> An adverb could be inserted before it:
<q rend="display"> She ran quickly down the hill.<lb/>(But not: *She ran viciously down her best friends.) </q>
 </item>
 <item>It can be moved (somewhat awkwardly) to the front of a <hi rend="italic">wh</hi>-word:
<q rend="display"> This is the hill down_PRP which he ran.<lb/> Down_PRP which slopes do you like ski-ing? </q>
 </item>
 </list>
</p>
 <p>
 In (b), <hi rend="italic">down</hi> is an adverbial particle because:
 <list>
  <item>It can be placed before or after the noun phrase acting as
 object of the verb:<q rend="display"><lb/>
 She ran her best friends down_AVP.<lb/> (But not: *She ran the hill down.)
 </q></item>
 
 <item> If the noun phrase is replaced by a pronoun, the pronoun has
 to be placed in front of the particle:
 <q rend="display">She ran them down_AVP. (= her best friends)<lb/>(But not: *She ran down them.)<lb/>
 </q>
 Similarly: <q rend="display">The dentist took all my teeth out_AVP. (The dentist took them out)
</q> 
<!-- <p>
 Contrast: <hi rend="italic">She went through_PRP the gate. (She went  through it).</hi>
 </p>-->
</item></list>
 </p>
 <p>
 Notice that the syntactic distinction between (for example) <hi rend="italic">down</hi> as an adverbial particle and <hi rend="italic">down</hi>  as a preposition
 is independent of the semantic distinction between locative and
 non-locative interpretations of <hi rend="italic">down</hi>.</p>
 <p>
 When the verb is simply followed by <hi rend="italic">down</hi> or <hi rend="italic">out</hi>,
 etc., without a following noun phrase, it is normally an <code>AVP</code>:
<q rend="display">  Income tax is coming down_AVP.<lb/> 
   The decorations are put up_AVP on Christmas Eve. </q></p>
 <p>
 However, it is important to recognize 'stranded' prepositions,
 which have been deprived of the company of their noun phrase,
 the prepositional complement, because it has been fronted or omitted
 through ellipsis (e.g. in relative clauses, with passives, in
 questions, etc.):
<q rend="display"> This is the hill (which) she ran down_PRP.<lb/>(Cf. This is the hill down which she ran.)
  <lb/>The poor were looked down on_PRP by the rich.<lb/>(Here <hi rend="italic">on</hi> is the stranded preposition)
 <lb/>Which car did she arrive in_PRP? </q></p>
 <p>
 The same tests apply to words which are tagged either as prepositions or as general adverbs (AV0), such as <hi rend="italic">across, past</hi> and <hi rend="italic">behind</hi>.
 </p>
 <p>
  Note, additionally, the use of <ref
   target="#m4about">
 <hi rend="italic">about</hi></ref> as a degree adverb.</p>
 </div> <!--prep -->
 
 <div xml:id="m3itj-unc">
 
 <head>Interjection vs. unclassified</head>
 
 <p> The borderline between interjections or exclamatory particles (tagged
 <code>ITJ</code>) and unclassified 'noise' words (tagged
 <code>UNC</code>) is drawn as follows:</p>
 <p>
 <code>ITJ</code> is used for 'institutionalized' interjections or discourse particles such as  <hi rend="italic">good-bye, oh, no, oops, hallelujah, whoa, wow </hi>; however
 <ref target="#m4well">Well</ref>, 
 <ref target="#m4right">right</ref> and <ref target="#m4like">like</ref> 
 functioning as discourse markers are tagged <code>AV0</code>.</p>
 <p> <code>UNC</code> is used in contexts where no other wordclass tag seems appropriate:
 <list>
 <item>'noise' words and pause fillers in spoken utterances; this
 includes imitations of animal or machine sounds:
 <q rend="display"> blah_UNC blah_UNC blah_UNC<lb/> 
  er_UNC I think so.<lb/> Erm_UNC nope_ITJ. 
 </q> </item>
 <item>certain fused forms which cannot easily be broken down into
 separate word classes:
 <q rend="display"> methinks_UNC.<lb/> ai_UNC n't_XX0</q>
 </item>
<item>constituent <gi>w</gi> elements within multiword expressions
for which no unique C5 code can be found</item>
 </list></p>
 <p>The contraction <hi rend="italic">ain't</hi> is a special case: its first half
 is tagged <code>UNC</code> because it abbreviates so many different verb forms
 (<hi rend="italic">am not, is not, are not, has not, have not</hi>) that no single
 tag can be applied to it (unless one were to invent a special
 tag for that purpose).</p>
 </div><!-- interject -->
 
 
 </div> <!-- disambig tag pair -->
 
 <div xml:id="m4">
 
 <head>Disambiguation by Word</head>
 <p>
 In this section we discuss some common words which belong to more than one word class, and are among the most problematic for disambiguation. As in section 3, if the tag stated in the example differs from the actual tag in the corpus, we append the latter to the file reference number in the next line. Eg <code>*AV0</code> in 
<q rend="display">  Tears well_VVB up in my eyes. [BN3.5 *AV0]
 </q>
 </p><!--The words covered are:
 <ref target="#m4apostrophes">apostrophe 'S</ref>  
 <ref target="#m4about">ABOUT</ref>  
 <ref target="#m4as">AS</ref>  
 <ref target="#m4but">BUT</ref>  
 <ref target="#m4home">HOME</ref>  
 <ref target="#m4like">LIKE</ref>  
 <ref target="#m4little">LITTLE</ref>  
 <ref target="#m4much">MUCH</ref>  
 <ref target="#m4more">MORE</ref>  
 <ref target="#m4no">NO</ref>  
 <ref target="#m4one">ONE </ref>  
 <ref target="#m4right">RIGHT</ref>  
 <ref target="#m4so">SO</ref>  
 <ref target="#m4that">THAT</ref>  
 <ref target="#m4then">THEN</ref>  
 <ref target="#m4to">TO</ref>  
 <ref target="#m4well">WELL</ref>  
 <ref target="#m4when">WHEN</ref>  
 <ref target="#m4worth">WORTH</ref> 
</p>-->
  <div xml:id="m4apostrophes">
 <head>Apostrophe S</head>
 <!--<p>
 Choice of tags: VBZ VHZ VDZ POS 
 <lb/>[<hi rend="italic">in fused words:</hi> VM0 ZZ0 CRD ]<lb/>
 </p>-->
 <p> In the BNC the two-character sequence <hi rend="italic">'s</hi> is generally tagged as a 
 separate wordform, following 
 without a space the immediately preceding word. 
 
 <list type="gloss"> <!-- start 's list -->
 <label>Contracted forms</label>
 <item>
 When it represents a shortened form of <hi rend="italic">is</hi>, <hi rend="italic">has</hi> or (rarely) <hi rend="italic">does</hi>, it has the appropriate verb tag. 
 Occasionally, for example with auxiliaries followed by past participles, there are difficulties determining what the full form of the verb should be.
 Examples:
 
 <q rend="display">
 That_DT0's_VBZ perfect is that one... (= That is...) [KCX.1254]<lb/>
  She_NP0 's_VHZ got tickets. (= She has...) [KPV.6479]<lb/>
  well, what_DTQ 's_VDZ he do?, is he a plumber?  (= What does...) [KD6.310]
 </q>
 </item>
 <label>Genitives</label>
 <item>
 
 Britain_NP0's_POS small businesses [HMH.67]<lb/>
 After today_AV0's_POS announcement [K6F.39]
 
 </item>
 <label>'s plural</label>
 <item>When <hi rend="italic">'s</hi> acts as a marker of the -<hi rend="italic">s</hi> plural, or as part
 of the verb form <hi rend="italic">let's</hi>, it is part of a single word, and
 is not assigned its own tag. E.g.:
 <q rend="display">
 
 success in the three R_ZZ0's [EVY.59]<lb/>
 in the 1980_CRD's [HJ1.22024]<lb/>
 Let_VM0's go_VVI. [A61.1443]
 </q>
 </item></list></p>
 <p>
 Note that <hi rend="italic">let's</hi> is not considered a contraction of <hi rend="italic">let
 us</hi>, but is treated as a single 'verbal particle', tagged <code>VM0</code>,
 on the grounds that it is closely analogous to modal auxiliaries.
 </p> 
 <!-- end 's list -->
 </div> <!-- 's -->
 
 <div xml:id="m4about">
 
 <head>ABOUT</head>
<!-- <p> Choice of tags: PRP, AV0 and AVP-->
 <list type="gloss">
 <label>Degree adverb:</label>
 <item>
 When <hi rend="italic">about</hi> has an approximating meaning, typically premodifying
 a quantifying expression, it is tagged <code>AV0</code> (not
 <code>PRP</code>):
<q rend="display">  ...it was about_AV0 three weeks ago [FAJ.1714]<lb/>
   about_AV0 half the size of a grain of rice [AJ4.33]<lb/>
 </q>
 Note also the multiword <hi rend="italic">just about</hi>, as in: 
<q rend="display">We're just about_AV0 ready.</q>
</item>
 <label>Preposition vs. particle:</label>
 <item>See further at <ptr target="#m3prep-avp"/><!--PRP vs. AVP</ref>-->
 <p>
 Examples:<q rend="display">
 
 my mother was reading a novel about_PRP gypsies... . [ARJ.2068]<lb/>
 How did this transformation come about_AVP?  [A11.786]
 </q></p></item>
 </list>
 </div>
 
 <div xml:id="m4as">
 <head>AS</head>
 <!--<p>
 Choice of tags: <hi rend="italic">PRP, AV0 and CJS (also multiword tags)</hi>
 -->
 <list type="gloss"> <!-- start ASlist -->
 <label>Comparative constructions:</label>
 <item>
 <hi rend="italic">As</hi> is a degree adverb (AV0) when it occurs before an adjective,
 adverb or determiner (and sometimes other words) in phrases of
 the type <hi rend="italic">as X as Y,</hi> or simply <hi rend="italic">as X</hi> (where the comparative
 clause or phrase <hi rend="italic">as Y</hi>) is omitted but understood:
<q rend="display">  I go to see them as_AV0 often as I can .  [AC7.1189]<lb/>
 and they employ ninety people, twice as_AV0 many as last year.  [K1C.3540]<lb/>
And every bit as_AV0 good .[EEW.1132 *CJS]
  </q>
 In the first and second examples above, the second <hi rend="italic">as</hi> introduces
 a comparative construction which expresses 'equal comparison',
 as contrasted with the unequal comparison of <hi rend="italic">more X than Y</hi>.
 When <hi rend="italic">as</hi> is a word introducing such a comparative construction,
 it is tagged <code>CJS</code>:
<q rend="display">  Capitalism is not as_AV0 good as_CJS it claims. [CFT.2042]<lb/>
 Linked together, they can crunch numbers as_AV0 fast as_CJS any mainframe.[CRB.271]<lb/>
 She will deposit as_AV0 many as_CJS a dozen eggs there. [F9F.424]<lb/>
 </q>
 Notice that <hi rend="italic">as</hi> in this comparative use is tagged CJS whether
 or not it introduces a clause. Often it introduces a noun phrase.
 In the following example, it introduces an adjective:<lb/>
 <q rend="display">  always reply as_AV0 quickly as_CJS possible. [C9R.989]
 </q>
</item>
 <label>Introducing other clauses:</label>
 <item>
 The tag CJS is also used when introducing other subordinate clauses,
 such as adverbial clauses of time or reason:
<q rend="display">
 New York called just as_CJS I was leaving.  [APU.1543]<lb/>
 As_CJS you've gone to so much trouble , it would seem discourteous to refuse [KY9.2107]
 </q>
 </item>
 <label>Preposition:</label>
 <item> The tag <code>PRP</code> is used for <hi rend="italic">as</hi> functioning clearly as a preposition:
<q rend="display">  Consider it as_PRP a kind of insurance [AD0.1641]<lb/>
 As_PRP head of information, Christina will lead a team of four TEC staff... [BM4.2830]
 </q>
  Usually the meaning is related to the equative meaning of the
 verb <hi rend="italic">be</hi>. However, the guideline restricts <code>PRP</code> to cases
 where <hi rend="italic">as</hi> is followed by the normal noun phrase or nominal,
 as is normal for prepositions. Where the <hi rend="italic">as</hi> is followed
 by an adjective or a past participle clause, it is tagged <code>CJS</code>,
 even though it may retain the equative type of meaning:
 <q rend="display"> We regard these results as_CJS encouraging. [B1G.184]<lb/>
 I very much hope that you will in fact support the motion as_CJS originally intended. [KGX.93]
 </q>
 </item>
 <label>Multiwords:</label>
 <item>
 <hi rend="italic">As</hi> is part of many multiwords which get tagged with a
 single tag: e.g. <hi rend="italic">as soon as</hi>, <hi rend="italic">such as, in so far as,
 as long as, as well as</hi>. The sequence <hi rend="italic">as well as,</hi> for
 example, is tagged as a preposition (<code>PRP</code>) in such examples as <lb/>
<q rend="display"> Sometimes <emph>as well as</emph>_PRP going this way we actually need to go in this was too. [G5N.31] </q>
  Note that this is different from the multiword adverb <hi rend="italic">as well</hi> (meaning
 <hi rend="italic">also</hi>); it is also different from the sequence of <hi rend="italic">as
 well as</hi> as three separate words, e.g. in:
<q rend="display"> She's as_AV0 well_AJ0 as_CJS can be expected. [F9X.2095]</q></item>
 
 </list> <!-- end ASlist -->

 </div> <!-- end as -->
 <div xml:id="m4but">
 
 
 <head>BUT</head>
<!-- <p>Choice of tags: CJC, CJS, PRP, AV0<q rend="display"><lb/>-->
<p> The coordinating conjunction <code>CJC</code> is overwhelmingly the most common
 use of <hi rend="italic">but</hi>. The following other cases can also be detected:
 <list type="gloss"> <!-- start BUTlist -->
 <label>Adverb:</label>
 <item>
 <hi rend="italic">But</hi> is an adverb when its meaning is similar to 'only':
<q rend="display">  She can spare you but_AV0 a few minutes [CCD.82 *CJC]
  There is but_AV0 one penalty. [ALS.185 *CJC] </q>
 </item>
 <label>Subordinating conjunction or preposition:</label>
 <item>
 <hi rend="italic">But</hi> is either a conjunction (<code>CJS</code>) or a preposition (<code>PRP</code>)
 if it has the meaning of 'except (for)', 'other than' or 'apart
 from'. <code>CJS</code> is used when it introduces a clause, and <code>PRP</code> is used
 when it introduces a phrase:
<q rend="display">...mediocre albums that do nothing but_CJS take up shelf space [C9M.1014]
 <lb/>I couldn't help but_CJS notice. [JY0.5323 *CJC]
 <lb/>I always feel they are open meetings in everything but_PRP name.  [HJ3.5520]<lb/>
 No one had guessed she was anything but_PRP a boy. [C85.517]
 </q>
 </item>
 <label>Coordinating conjunction:</label>
 <item>
 Otherwise <hi rend="italic">but</hi> is a coordinating conjunction, tagged <code>CJC</code>,
 linking units of the same kind (e.g. clauses or adjective/adverb
 phrases). Its function is to express contrastive or 'adversative'
 meaning:
<q rend="display">  God and minds do exist , but_CJC materially so . [ABM.1265]<lb/>
  And that's it for another week but_CJC don't forget the late news at eleven thirty. [J1M.2520]<lb/>
Hares ( but_CJC not rabbits ) are particularly vulnerable... [B72.892]
 </q>
 </item>
 <label>Multiwords</label>
 <item>Note also multiwords such as <hi rend="italic">but for</hi> (<code>PRP</code>):

<q rend="display">The fare increases would have been bigger <emph>but for</emph>_PRP the governments last minute intervention. [K6D.124]
 </q></item>
 </list> </p>
 </div> <!-- end BUTlist -->
 
 <div xml:id="m4home">
 <head>HOME</head>
<!-- <p>
 Choice of tags: <hi rend="italic">AV0 and NN1</hi></p>-->
 <p>As a locative adverb, <hi rend="italic">home</hi> has no determiner or article
 preceding:
<q rend="display"> 
 We stayed home_AV0. [FAP.313]<lb/>
This is my home_NN1. [AMB.1805]
 
 </q></p></div>
 
 <div xml:id="m4like">
 <head>LIKE</head>
<!-- <p>
 Choice of tags: <hi rend="italic">PRP AV0 CJS VVB VVI NN1 AJ0<lb/></hi>
 -->
 <list type="gloss"> <!-- start LIKElist -->
 <label>Discoursal function:</label>
 <item>
 In speech, when <hi rend="italic">like</hi> has a discoursal function as a 'hedge',
 we tag it <code>AV0</code>:
<q rend="display"> 
 well she says like_AV0, I won't be a minute  [KCY.1518]<lb/>
 I'm driving along, you know like_AV0 <gi>trunc</gi> wha<gi>/trunc</gi> when you're
 in the car by yourself and everything's turning over in your head [KBU.1096]
 </q>
 </item>
 <label>Other functions:</label>
 <item>
 <hi rend="italic">Like</hi> very frequently occurs as a preposition or as a verb.
 The noun and adjective uses are fairly rare:<lb/>
<q rend="display"> 
 ...but I like_VVB Monday best. [FU4.1089]<lb/>
 He didn't look like_PRP a goodie. [H0M.1353]<lb/>
 ... fuel, weapons, ground crew and the like_NN1. [JNN.105 *AJ0-NN1]<lb/>
 Churchill and Eden were not of like_AJ0 minds... [ACH.1297]
 </q></item>
 </list> 
</div><!-- end LIKElist -->
 <div xml:id="m4little">
 
 <head>LITTLE</head>
<!-- <p>
 Choice of tags: <hi rend="italic">AJ0, DT0, AV0,</hi> (also multiwords)<q rend="display"><lb/>
 -->
 <list type="gloss"> <!-- start LITTLElist -->
 <label>Adjective:</label>
 <item>
 The meaning of <hi rend="italic">little</hi> (<code>AJ0</code>) is the opposite of <hi rend="italic">big</hi>:
 <lb/>
<q rend="display"> 
 Bless their dear little_AJ0 faces. [HRB.722]<lb/>
 Little_AJ0 green shoots of recovery are stirring. [CEL.968]
 </q>
 </item>
 <label>Determiner-pronoun:</label>
 <item>
 The meaning of <hi rend="italic">little</hi> (<code>DT0</code>) is 'not much': <lb/>
<q rend="display"> 
 I have little_DT0 to say. [G1Y.1133]<lb/>
 ...there was little_DT0 food left. [FSJ.720]<lb/>
 </q>
 </item>
 <label>Adverb:</label>
 <item>
 As an adverb (<code>AV0</code>) <hi rend="italic">little</hi> also has the meaning 'not much':
<q rend="display"> 
 I care very little_AV0 about petty-minded, selfish "rules". [B0P.211]
 </q>
 </item>
 <label>A little</label>
 <item>
 Note that <hi rend="italic">a little</hi> can also be a multiword adverb (<code>AV0</code>):<lb/>
<q rend="display"> 
 They are all <emph>a little</emph>_AV0 drunk. [G0F.2117]
 </q>
 
 However, the quantifier <hi rend="italic">a little</hi> meaning 'a small amount' is not tagged as a multiword
<note place="foot">In BNC version 1, the quantifier <hi rend="italic">a little</hi> 
 meaning 'a small amount' was sometimes (but not reliably) tagged as a
 multiword <code>DT0</code></note> but as <code>AT0 + DT0</code>
<q rend="display">  You couldn't let me have a_AT0 little_DT0 milk? [GUM.1656]
 </q>
 
 [See <ptr target="#m3rrr-dar"/> ]<lb/>
 </item></list> 

 </div><!-- end LITTLElist -->
 
 <div xml:id="m4much">
 <head>MUCH</head>
<!-- <p>
 <hi rend="italic">Choice of tags:</hi> DT0 AV0<q rend="display"><lb/>
 -->
 <list type="gloss"> <!-- start MUCHlist -->
 <label>Determiner-pronoun:</label>
 <item>
<q rend="display">Much_DT0 of this work has to be done on the spot. [C8R.24]<lb/>
I've spent too much_DT0 money. [KPV.62659]
 </q>
 </item>
 <label>Adverb:</label>
 <item> <q rend="display">
Thanks very much_AV0. [A73.5]<lb/>
I didn't sleep much_AV0 last night [ALH.1495]
 </q></item>
 </list>
<p> See also <ptr target="#m3rrr-dar"/></p>
  </div> <!-- end MUCHlist -->
 
 
 <div xml:id="m4more"><anchor xml:id="m4less"/>
 
 <head>MORE and LESS</head>
 <!--<p>
 <hi rend="italic">Choice of tags:</hi> DT0 AV0 AV0<q rend="display"><lb/>
 -->
 <p> See <ptr target="#m3rrr-dar"/> for a fuller
 discussion. Further examples:

<q rend="display"> 
 You deserve more_DT0 than a medal. [K97.3705]<lb/>
 More_DT0 haste, less_DT0 speed. [J10.4543]<lb/>
 ...this will make him more_AV0 tired than usual [A75.282]<lb/>
 But I couldn't agree more_AV0  [BMD.3] </q></p>
 <p><hi rend="italic">More than</hi> as a multiword premodifier counts as an <code>AV0</code>:
<q rend="display">  <emph>more than</emph>_AV0 one in a million [K5N.46] </q></p>
 
 </div><!-- end MORElist -->
 
 <div xml:id="m4no">
 
 <head>NO</head>
<!-- <p>
 <hi rend="italic">Choice of tags:</hi> AT0 NN1 AV0 ITJ<q rend="display"><lb/>
 -->
 <list type="gloss"> <!-- start NOlist -->
 <label>Article</label>
 <item> <q rend="display">
 No_AT0 problem_NN1. [H4H.227]
 </q></item>
 
 <label>Noun</label>
 <item>
 As a noun, <hi rend="italic">no</hi> is usually an abbreviation for <hi rend="italic">number:</hi>
<q rend="display"> 
 quoting Ref_NN1 No_NN1 BCE90_UNC [CJU.673]
 </q>
 </item>
 <label>Adverb</label>
 <item> <q rend="display">
 but the matter was taken no_AV0 further_AV0. [ARF.183 <hi rend="italic">no</hi>: *AT0] <lb/>
  To put it no_AV0 more_AV0 strongly_AV0, it has not been proved beyond doubt that.... [EW7.125] 
</q> </item>
 <label>Interjection:</label>
 <item>
 <hi rend="italic">No</hi> is tagged as an interjection (<code>ITJ</code>) where it functions
 as the opposite of <hi rend="italic">Yes.<lb/></hi>
 <q rend="display"> 
 "...See how easy my job can be?" <lb/>"Frankly, no_ITJ". [HR4.2329]
 </q></item>
 </list> 

 </div><!-- end NOlist -->
 
 
 <div xml:id="m4one">
 
 
 <head>ONE</head>
<!-- <p>
 <hi rend="italic">Choice of tags:</hi> PNI, CRD<q rend="display"><lb/>
 -->
 <list type="gloss"> <!-- start ONElist -->
 <label>Numeral:</label>
 <item>
 The clearest cases of <code>CRD</code> are in a quantifying noun phrase, typically allowing the substitution of another numerical expression (e.g. <hi rend="italic">one chip</hi>
 contrasts with <hi rend="italic">two chips</hi>) or of the digit 1 (<hi rend="italic">1 chip</hi>):
<q rend="display"> 
 Can I have one_CRD chip, please? [KDB.1416]<lb/>So are there criticisms? Just one_CRD. [CG2.1489]<lb/>... one_CRD in five sufferers never tells their partners. [CF5.8 *PNI]<lb/> Orford Ness is one_CRD of Britain's most unusual coastal features. [CF8.86] </q>
  In such noun phrases, <hi rend="italic">one</hi> functions like a determiner-pronoun such as <hi rend="italic">some.</hi>
 </item>
 <label>Indefinite Pronoun:</label>
 <item> The clearest cases of <code>PNI</code> are:
 <list>
 <item>
 As a substitute form, standing for an understood noun or noun
 phrase:
<q rend="display"> 
 The channel was not a broad one_PNI [AEA.1457]
 </q>
 In this use, <hi rend="italic">one</hi> has a plural form <hi rend="italic">ones.</hi>
 </item>
 <item>
 As a generic personal pronoun, meaning 'people in general':
<q rend="display">  And I think one_PNI might go on to argue that far from saving labour it creates it. [J17.1915]
 </q>
 </item></list></item>
 </list> 
 <p>Note that the reliability of the ambiguity tag <code>PNI-CRD</code> (in which the pronoun is rated more likely) 
 is somewhat low. See <ptr target="#errorRates"/></p>
 </div><!-- end ONElist -->
 <div xml:id="m4right">
 <head>RIGHT</head>
 <!--
 <p>
 <hi rend="italic">Choice of tags:</hi> AV0 VVB VVI NN1<q rend="display"><lb/>
 -->
<p> As both an adverb (<code>AV0</code>) and an adjective (<code>AJ0</code>) <hi rend="italic">right</hi> means
 the opposite of 'wrong' and also the opposite of 'left'. As a
 noun, it generally means 'entitlements': e.g. <hi rend="italic">I have a 
 right_NN1 to know</hi>. The uses of <hi rend="italic">right</hi> as a verb are
 very rare.</p>
 <p>
 Less obvious points:
 <list type="gloss"> <!-- start RIGHTlist -->
 <label>Discoursal function:</label>
 <item>
 As a discourse marker, <hi rend="italic">right</hi> is tagged <code>AV0</code>:
<q rend="display"> 
 Right_AV0, how you doing there? [KBL.4671]<lb/>
  Right_AV0, er, members, any questions ? [F7V.138]
 </q></item>
 <label>Degree adverb (intensifier):</label>
 <item>
 In dialectal usage, <hi rend="italic">right</hi> can be an intensifier, and is tagged <code>AV0</code>:
<q rend="display"> 
 it's a ... it's a right_AV0 soft carpet. [KB2.1242-4] </q></item>
 </list> </p>
 </div><!-- end RIGHTlist -->
 
 <div xml:id="m4so">
 
 <head>SO</head>
<!-- <p>
 <hi rend="italic">Choice of tags:</hi> AV0 AV0 CJS<q rend="display"><lb/>
 -->
 <list> <!-- start SOlist -->
 <item>In most cases <hi rend="italic">so</hi> is tagged as an adverb (<code>AV0</code>):
<q rend="display"> 
 So_AV0 this is where you work... [H8M.2964]<lb/>
 Right, so_AV0 what's fifty three per cent as a decimal?  [JP4.357]<lb/>
They waited but nothing happened so_AV0 they made a fuss. [FU1.2484] </q>
 </item>
 <item>As a pro-form meaning 'thus' or standing for a clause or predicate,
 <hi rend="italic">so</hi> is tagged <code>AV0</code>:
<q rend="display"> So_AV0 say I and so_AV0 say the folk. [G11.228]<lb/>"Yes, I think so_AV0." [CCM.151] </q>
 </item>
 <item>As a <emph>degree adverb</emph> or intensifier, <hi rend="italic">so</hi> is tagged <code>AV0</code>:
<q rend="display">  tough and long lasting - that's why they're so_AV0 popular. [BN4.929]<lb/>There would not be so_AV0 many lonely people in our land [B1Y.1262]</q>
 </item>
 <item>Introducing purpose clauses, <hi rend="italic">so</hi> is tagged <code>CJS</code> (subordinating
 conjunction):
<q rend="display">  Drink your tea so_CJS they can have your cup. [KB2.1767]
 </q>
 </item>
 <item>Note that <hi rend="italic">so</hi> is frequently part of a multiword: <hi rend="italic">so
 that, so far, so as to, (in) so far as,</hi> etc. 
 See <ref target="#defrobs">the list of multiwords</ref></item>
 
 </list> 
 </div> <!-- end SOlist -->
 <div xml:id="m4that">
 
 <head>THAT</head>
<!-- <p>
 <hi rend="italic">Choice of tags</hi>: DT0 CJT AV0<q rend="display"><lb/>-->
 <list > <!-- start THATlist -->
 <item>As a demonstrative (pronoun or determiner), <hi rend="italic">that</hi> is tagged <code>DT0</code>
 <q rend="display"> 
 That_DT0's_VBZ my coat yeah. [KBS.1309]<lb/>he's getting hooked on the taste of vaseline, that_DT0 dog. [KCL.197]
 </q>
 </item> <item>As a clause-initiating conjunction, <hi rend="italic">that</hi> is
 tagged <code>CJT</code>. 
 This applies to <hi rend="italic">that</hi> as a complementizer:
<q rend="display"> 
 Many experts claim that_CJT it is good for your growing baby, too. [G2T.1091]
 </q>
  and also to <hi rend="italic">that</hi> as a relativizer (introducing a relative
 clause):
<q rend="display"> 
 A ship that_CJT never enters harbour. [BPA.1326]
 </q>
This is different from the more traditional analysis which treats
 <hi rend="italic">that</hi> introducing a relative clause as a relative pronoun.
 </item>
 <item>As a degree adverb (intensifier):
<q rend="display">
 It wasn't all that_AV0 bad. [KPP.321]
 </q></item>

 <item><hi rend="italic">That</hi> occurs commonly in multiwords such as <hi rend="italic">so
 that, in that, in order that</hi>.</item>
  </list> 

 </div><!-- end THATlist -->
 
 <div xml:id="m4then">
 
 <head>THEN</head>
<!-- <p>
 <hi rend="italic">Choice of tags:</hi> AV0 AJ0<q rend="display"><lb/>
 </q></p>-->
 <p>
 In all functions except <emph>clear adjectival usage</emph> (<code>AJ0</code>, usually following <hi rend="italic">the</hi>), <hi rend="italic">then</hi>
 receives the tag <code>AV0</code>:<q rend="display">  And then_AV0 she spoke. [H8T.2675]<lb/>"Come on, then_AV0." [K8V.1722]<lb/>Mr Willi Brandt, the then_AJ0 Mayor of West Berlin. [A87.84]<lb/>...the then_AJ0 state governor , who wasn't then_AV0 Bill Clinton [A87.84] </q></p>
 </div>

 <div xml:id="m4to">
 
 <head>TO</head>
<!-- <p>
 <hi rend="italic">Choice of tags:</hi> TO0 PRP AVP<q rend="display"><lb/>-->
 <list type="gloss"> <!-- start TOlist -->
 <label>Infinitive marker </label>
 <item>
When used with an infinitive, <hi rend="italic">to</hi> is always tagged
<code>TO0</code>. Note elliptical uses of the pre-infinitival
<hi rend="italic">to,</hi> especially in informal spoken texts:<q rend="display"> 
 In the summer holidays, I can, I can get up early if I want to_TO0. [KPG.4153]
 </q>
  Note also the common colloquial spelling of <hi rend="italic">want to, got to,
</hi> and <hi rend="italic">going to</hi> as fused words:
<q rend="display">   <hi rend="italic">wanna = wan_VVB na_TO0 <lb/>gotta = got_VVN ta_TO0 <lb/>gonna = gon_VVG na_TO0<lb/></hi> </q>
 </item>
 <label>Preposition</label>
 <item>When used as a preposition, <hi rend="italic">to</hi> is always tagged
<code>PRP</code>. Prepositions are normally followed by a noun phrase or nominal
 clause. Where the preposition is 'stranded' (i.e. where the noun
 phrase associated with the preposition has been moved or ellided )
 it can be confused with an adverbial particle:<lb/>
<q rend="display">
 That 's the school that Terry goes to_PRP. [KB8.2442]<lb/>...what you're entitled to_PRP by law is money back [FUT.360]<lb/>"Where to_PRP?""The_PRP moon." [FNW.240-1]</q>
 </item>
 <label>Adverbial particle</label>
 <item>The adverbial particle <hi rend="italic">to</hi> is rare but does occur, for example
 in <hi rend="italic">come to</hi> meaning 'regain consciousness'.</item>
 </list><!-- no occurrences in BNC XML -->
 </div> <!-- end TOlist -->

 <div xml:id="m4well">
 
 <head>WELL</head>
<!--
 <hi rend="italic">Choice of tags:</hi> AV0 VVB VVI AJ0 NN1<q rend="display"><lb/>-->
 <list type="gloss"> <!-- start WELLlist -->
 <label>Adverb</label>
 <item>By far the most common function for <hi rend="italic">well</hi> is as an <emph>adverb</emph>:
<q rend="display">She's playing well_AV0</q></item>

 <label>Discoursal function:</label>
 <item> When <hi rend="italic">well</hi> has the function of a discourse marker, it is
 treated as an adverb (<code>AV0</code>):
<q rend="display">  Oh well_AV0! That'll be the finish! [FX6.196-7]<lb/> I bet he doesn't get up till about, well_AV0, it's eleven now. [KBL.3808]</q>
 </item>
 <label>Degree adverb:</label>
 <item>
 <hi rend="italic">Well</hi> is tagged <code>AV0</code>, too, where it has an intensifying function: e.g.
<q rend="display"> It was dark outside and well_AV0 past your bedtime. [ASS.898]</q></item>
 
 <label>Adjective</label>
 <item>
 <hi rend="italic">Well</hi> is tagged as an adjective where it means 'in good
 health': <q rend="display"> You don't look well_AJ0. [HPR.107]</q>
 </item>
 <label>Verb</label>
 <item>As a verb, <hi rend="italic">well</hi> is very rare, but  occurs in the phrasal
 verb <hi rend="italic">well up</hi>. NB. This use has not been accurately tagged in the corpus:
<q rend="display"> Tears well_VVB up in my eyes. [BN3.5 *AV0]</q>
</item>
 </list>
 </div><!-- end WELLlist -->
 <div xml:id="m4when">
 
 <head>WHEN</head>
<!-- <p>
 <hi rend="italic">Choice of tags:</hi> AVQ CJS<lb/>
 -->
<p> <hi rend="italic">When</hi> can introduce three types of clauses: an adverbial
 clause, a nominal clause, or a relative clause. Where it introduces
 an adverbial clause, it is tagged <code>CJS</code>. Otherwise it is
 tagged <code>AVQ</code>.  The <code>AVQ</code> tag is also used for
 <hi rend="italic">when</hi> introducing a question.  Examples:
 
 <list type="gloss"> <!-- start WHENlist --> 
  <label>Adverbial clause:</label>
 <item> <q rend="display">
 When_CJS I got back to my flat, I decided to ring Toby. [CS4.1265]<lb/>
 the crowd left quietly when_CJS the police arrived. [APP.1017]
 (when = at the time at which)<lb/>
 If you smoke when_CJS you're pregnant...  [A0J.1598] (when = whenever)
 </q>
  Note that <hi rend="italic">when</hi> is also a subordinating conjunction in <emph>abbreviated</emph>
 adverbial clauses which lack a subject and finite verb, such as
 <hi rend="italic">when in doubt, when ready, when completed</hi>.</item>
 
 <label>Nominal clause</label>
 <item><q rend="display"> 
 I can't remember when_AVQ we last had a frost. [KBF.11728]<lb/>
 "Do you remember when_AVQ we used to go with Daddy in the boat on Saturdays?"  [A6N.2022]<lb/>
 You never know when_AVQ the next big story will break.  [HJ6.100]</q>
 Before an infinitive, <hi rend="italic">when</hi> is also tagged AVQ: 
<q rend="display"> Otto knew when_AVQ to change the subject. [FAT.1603] </q>
 Also when the rest of the infinitive clause is understood: 
<q rend="display">Tell me when_AVQ. </q></item>
 <label>Relative clause</label>
 <item><q rend="display"> in the year when_AVQ I was born (when = in which)
<lb/>the moment when_AVQ he arrived (when = at which)
 </q>
Note that <hi rend="italic">when</hi> can often be omitted in relative clauses:
 <hi rend="italic">the moment he arrived</hi>.<lb/>
</item>
 <label>Direct questions</label>
 <item><q rend="display"> When_AVQ did you find out? </q></item>
 </list> </p>
 </div><!-- end WHENlist -->
 
 <div xml:id="m4where">
 <head>WHERE</head>
<!-- <p>
 <hi rend="italic">Choice of tags:</hi> AVQ CJS<q rend="display"><lb/>
 -->
<p> <hi rend="italic">Where</hi> is like <hi rend="italic">when</hi>
in that it can be a <hi rend="italic">wh-</hi> adverb
(<code>AVQ</code>) or a subordinating conjunction
(<code>CJS</code>). However, with <hi rend="italic">where</hi> the
<code>CJS</code> tag is much less likely.  Examples:

 <list type="gloss"> <!-- start WHERElist -->
 
 <label>In adverbial clauses </label>
 <item><q rend="display"> ...to hit him where_CJS it hurts. [CEN.2816] </q></item>
 <label>In other contexts</label> 
 <item><list>
 <item>Nominal clause:
<q rend="display"> 
 I don't know where_AVQ she picked them up. [G1D.1163]
 </q></item>
 <item>Relative clauses
<q rend="display"> 
 It was the house where_AVQ the poor woodcutter lived with Hansel and Gretel </q></item>
 <item>Direct questions:
<q rend="display"> Where_AVQ are you going? [KB9.2650] </q></item></list> </item> </list> 

</p> </div> <!-- end WHERElist -->
 
 <div xml:id="m4worth">
 
 <head>WORTH</head>
 <!--<p>
 <hi rend="italic">Choice of tags:</hi> PRP NN1<q rend="display"><lb/>
 -->
 <list type="gloss"> <!-- start WORTHlist -->
 <label>Preposition</label>
 <item><hi rend="italic">worth</hi> is tagged <code>PRP</code> where it could answer a question
such as 'How much is X worth?' or 'What is X worth?'
<q rend="display">
these pictures are worth_PRP a small fortune. [FNT.1060]
 <lb/>That makes him worth_PRP about $60m. [CT3.479]
 <lb/>'Darling, it's not worth_PRP getting upset. [HH9.2308]
 </q>
 <hi rend="italic">worth</hi> also occurs as a 'stranded preposition' in questions
 used to elicit such responses, and in some other common constructions:
 <q rend="display">
 how much d'ya think it's worth_PRP? [KCX.1344]<lb/>
 share prices say nothing about what a company is worth_PRP. [A9U.305 *NN1]<lb/>
 Please go ahead and push Grapevine for all you are worth_PRP. [AP1.575]
 </q>
</item>
 <label>Noun</label>
 <item><hi rend="italic">worth</hi> is tagged <code>NN1</code> when it is an obvious
 noun (meaning 'value'). Typically this occurs following expressions
 of quantity, whether or not the quantity is expressed by a possessive
 or genitive (e.g. <hi rend="italic">its, 's</hi>).
 <q rend="display"> Baker showed his worth_NN1 for Ipswich in the 20th minute [CF9.102]<lb/>
 hundreds of pounds' worth_NN1 of damage. [A0H.15]<lb/>
 £2,500 WORTH_NN1 OF PRIZES [ECJ.1147]<lb/>
 </q></item>
 </list> 
 </div><!-- end WORTHlist -->
 
  
 </div><!-- disambig word -->
 </div> <!-- disambig guide -->
 
 
 <div xml:id="m5">
 <head>Features of spoken corpus tagging</head>
 
 <p>The spoken and written texts of the BNC have been tagged in the same way, except that the following 
 phenomena occur almost entirely in the spoken part of the corpus.
 
 <list type="gloss"> <!-- start SPOKENlist -->
 <label>Individual letters</label>
 <item>Words spelt out by a speaker as individual letters have been transcribed letter by letter, 
 each being tagged <ref target="#m2misc_zz0"><code>ZZ0</code></ref>.
 <q rend="display">children who go to the E_ZZ0 N_ZZ0 T_ZZ0 clinic [KB8.3805]<lb/>
 ...ten ninety minute tapes! T_ZZ0 D_ZZ0 K_ZZ0 tapes! [KPG.3534-5]
 </q>
 
 <p>In the written corpus these items would nearly always be written
 and tagged as whole words (<hi rend="italic">ENT</hi> or <hi rend="italic">TDK</hi> in the above
 example).
 </p></item>
 <label>Truncated words</label>
 
 <item>Words that are left incomplete by the speaker are enclosed
 within an XML 
 <gi>trunc</gi> element and tagged <code>UNC</code>. Examples include <hi rend="italic">bathr</hi> and 
 <hi rend="italic">su</hi> in the following
 <q rend="display"> 
 <hi rend="italic">The <gi>trunc</gi> bathr_UNC <gi>/trunc</gi> er you can't
 beat a white bathroom suite anyway.</hi> [KCF.721]<lb/>
  Aye, they only came in the <gi>trunc</gi> su_UNC <gi>/trunc</gi> they only came up here in the summer. [GYS.127] 
 </q>
 </item>
 <label>Partial repetition of multiwords</label>
 <item> 
 Occasionally in spoken data it happens that only a portion of a 
multiword sequence is repeated. In this example, the word <hi rend="italic">sort</hi> is used twice; in both cases 
 it appears to function not as a separate word but as part of the multiword adverb 
 <hi rend="italic">sort of</hi>.
<q rend="display">  we're going to sort sort of summarize...  [G5X.106] </q>
 
 We treat the first <hi rend="italic">sort</hi> as an incomplete multiword, and tag it <code>UNC</code>
 (rather like truncated words, above). The complete multiword <hi rend="italic">sort of</hi> is tagged <code>AV0</code>, as normally. 
 <q rend="display"> we're going to sort_UNC <emph>sort of</emph>_AV0 summarize... </q>
  Further examples of incomplete multiwords are the <hi rend="italic">as long</hi> in <hi rend="italic">as long as</hi> (conjunction), <hi rend="italic">of</hi> in <hi rend="italic">because of</hi> (preposition) and the <hi rend="italic">in</hi> in <hi rend="italic">in general</hi> (adverb) below
 <q rend="display"> As_UNC long_UNC As_CJS long as everyone recognizes that for an area of that size... [J9T.258]<lb/>
 because_PRP of the &lt;pause&gt; of_UNC the drought. When we were away it didn't get watered in. [KCH.982]<lb/>
  I know that in_UNC in_UNC in_AV0 general, in in in erm, imperial measure, it is &lt;trunc&gt; f &lt;/trunc&gt; five feet eight inches [JK1.480] 
 </q>
 
The second example shows that when words are repeated, the incomplete
portion of a multiword is not necessarily immediately adjacent to the
fully formed multiword. In the last example, the three instances of
<hi rend="italic">in</hi> before <hi rend="italic">erm, imperial measure</hi> have not been
analysed as part of the multiword <hi rend="italic">in general</hi>; they are
instead tagged as ordinary words (in this case, ambiguous between
preposition and prepositional adverb: PRP-AVP). There are a few cases
where the tagger has probably been over-zealous in spotting repeated
portions of multiwords: <q rend="display">  What happens now_UNC, now_CJS that
you are winched down? [HEF.9] </q> Here, the first instance of
<hi rend="italic">now</hi> would probably have better been interpreted as a single
word adverb (='at this time'), not part of the multiword conjunction
<hi rend="italic">now that</hi><note place="foot">In our experience, human analysts
too sometimes have difficulty resolving ambiguities such as these,
especially when using the plain orthographic transcriptions of the
BNC, and with no direct access to the original sound
recordings.</note>.  </item>
 
 <label><hi rend="italic">Er</hi> and <hi rend="italic">erm</hi> inside multiwords</label>
 
 <item>Generally (in both written and spoken texts) the pause fillers <hi rend="italic">er</hi> 
 and <hi rend="italic">erm</hi> take the tag <code>UNC</code>. This applies also
 when they appear within  a multiword 
 sequence, as in <hi rend="italic">every er so often</hi>. The code assigned to the surrounding
 <gi>mw</gi> element is identical to that which would have been
 assigned if the filler were not present.
 <q rend="display"> And your homework was handed in <emph>every er so often</emph>_AV0, you know [G64.152]<lb/>
  <lb/>something had gone wrong with the <gi>pause</gi> gas pipes <emph>because erm of</emph>_PRP <gi>pause</gi> flooding. [KB8.5356]<lb/>
 <lb/>these kind of books were, er, generally er, at , <emph>at er best</emph>_AV0 ignored [HUN] </q>
 
 Note that in the last example the word <hi rend="italic">at</hi> preceding the multiword 
 <hi rend="italic">at er best</hi> is treated as a partial repetition of that multiword, and 
 therefore tagged <code>UNC</code>.</item>
 </list> 
</p>
 </div><!-- end SPOKENlist -->
  <!-- spoken -->
 </div> <!-- guidelines -->
 <div xml:id="errorRates">
 <head> POS-tagging Error Rates</head>
 <p>This section  reports on the accuracy of the results of the improved tagging programs.</p>
 <div><head>Levels of estimation</head>
 <p>Based on the findings from the 50,000-word test sample, the estimated ambiguity and error rates for the BNC are shown below in three different degrees of detail.:
<list>
<item> First, as a general assessment of accuracy, the estimated
rates are given for the whole corpus. (See <ptr target="#table-1"/> below.)</item>
<item> Secondly, separate estimates of ambiguity rates and error rates are given for each of the 57 word tags in the corpus. This will enable users of the corpus to assign appropriate degrees of reliability to each tag. Some tags are always correct; other tags are quite often erroneous. For example, the tag VDD stands for a single form of the verb do: the form did. Since the spelling did is unambiguous, the chances of ambiguity or error, in the use of the tag VDD, are virtually nil. On the other hand, the tag VVB (base finite form of a lexical verb) is not only quite frequent, but also highly prone to ambiguity and error. 15 per cent of the occurrences of VVB are errors - a much higher error rate than any other tag. (See <ptr target="#table-2"/> below.)
</item>
<item> Thirdly, separate estimates of ambiguity rates and error
rates are given for ‘wrong-tag--right-tag’ pairings XXX, YYY,
consisting of (i) the actually-occurring erroneous tag XXX, and (ii)
the correct tag YYY which should have occurred in its place. However,
because the number of possible tag-pairs is large (572), and most of
these tag-pairs have few or no errors, only the more common pairings
of erroneous tag and correct tag are separately listed, with their
estimated probability of occurrence. This list of tag-pairings will
help users further, in enabling them to estimate not merely the
reliability of a tag, but, if that tag is incorrect, the likelihood
that the correct tag would have been some other particular tag. In
this way, the frequency of grammatical word classes, or individual
words in those classes, can be estimated more accurately for the whole
BNC. (See <ptr target="#table-3"/> below.)  </item></list> </p> </div>

 <div><head>Presentation of Ambiguity Rates and Error Rates (fine-grained mode of calculation)</head>

 <p>In this section, we examine ambiguities and errors using a
 ‘fine-grained’ mode of calculation, treating each error as of equal
 importance to any other error. In <ptr target="#coarse"/> we look at
 the same data in terms of a ‘coarse-grained’ mode of calculation,
 ignoring errors and ambiguities involving subcategories of the same
 part of speech.</p>

 <div><head>Overall estimated ambiguity and error rates: based on the 50,000 word sample</head>

 <p>As the following table shows, the ambiguity rate varies
 considerably between written and spoken texts. (However, note that
 the calculation for speech is based on a small sample of 5,000
 words.)</p>
 
<table rend="center" xml:id="table-1"><head>Estimated ambiguity and error rates for the whole corpus (fine-grained calculation)</head>
 
 <row role="label">
 <cell>
 Sample tag count</cell>
 <cell>
 Ambiguity rate (%)</cell>
 <cell>
 Error rate (%)</cell>
 </row>
 <row><cell>
 Written texts</cell>
 <cell>
 45,000</cell>
 <cell>
 3.83%</cell>
 <cell>
 1.14%</cell>
 </row>
 <row><cell>
 Spoken texts</cell>
 <cell>
 5,000</cell>
 <cell>
 3.00%</cell>
 <cell>
 1.17%</cell>
 </row>
 <row><cell>
 All texts</cell>
 <cell>
 50,000</cell>
 <cell>
 3.75%</cell>
 <cell>
 1.15%</cell>
 </row>
 </table>
 <p> It will be noted that written texts on the whole have a higher ambiguity rate, whereas spoken texts have a slightly greater error rate.
 </p><p>

 The success of an automatic tagger is sometimes represented in terms
 of the information-retrieval measures of precision and recall, rather
 than ambiguity rate and error rate as in <ptr target="#table-1"/>. Precision is the
 extent to which incorrect tags are successfully discarded from the
 output. Recall is the extent to which all correct tags are
 successfully retained in the output of the tagger, allowing, however,
 for more than one reading to occur for one word (i.e. ambiguous
 tagging is permitted). According to these measures, the success of
 the tagging is as follows:
 </p>

 <table rend="center" >
 <row role="label"><cell></cell>
 <cell>
 Precision</cell>
 <cell>
 Recall</cell>
 </row>
 <row><cell>
 Written texts </cell>
 <cell>
 96.17%</cell>
 <cell>
 98.86%</cell>
 </row>
 <row><cell>
 Spoken texts</cell>
 <cell>
 97.00%</cell>
 <cell>
 98.83%</cell>
 </row>
 <row><cell>
 All texts</cell>
 <cell>
 96.25%</cell>
 <cell>
 98.85%</cell>
 </row>
 </table>
 
 <p>However, from now on we will continue to use ‘ambiguity rate’ and ‘error rate’, which appear to us more transparent.</p>
 </div>
 <div><head>Estimated ambiguity and error rates for each tag (fine-grained mode of calculation)</head>
 <p>The estimates for individual tags are again based on the 50,000 sample, and the ambiguity rate for each tag is based on the number of ambiguity tags which begin with a given tag. The table also specifies the estimated likelihood that a given tag, in the first position of the ambiguity tag, is the correct tag.</p>
 <p>In <ptr target="#table-2"/>, column (b) shows the overall
 frequency of particular tags (not including ambiguity tags). Column
 (c) gives the overall occurrence of ambiguity tags, as well as of
 particular ambiguity tags, beginning with a given tag. (Ambiguity
 tags marked * are less ‘serious’ in that they apply to two
 subcategories of the same part of speech, such as past tense and past
 participle of the verb - see 4.1 below.) Column (d) shows which tags
 are more or less likely to be found as the first part of an ambiguity
 tag. For example, both <code>NP0</code> and <code>VVG</code> have an
 especially high incidence of ambiguity tags. Column (e) tells us,
 given that we have observed an ambiguity tag, what is the likelihood
 of the first tag’s being correct? Overall, there is more than a 3-1
 chance that the first tag will be correct; but there are some
 exceptions, where the chances of the first tag’s being correct are
 much lower: for example, <code>PNI</code> (indefinite pronoun). Note
 that (f) and (g) exclude errors where the first tag of an ambiguity
 tag is wrong; contrast <ptr target="#table-5"/>, and <ptr
 target="#table-6"/> column (c), below.</p>
 <table rend="center" xml:id="table-2"> <head>Estimated ambiguity rates and error
 rates by tag<!--) (fine-grained calculation)--></head>
<row role="label"><cell>
(a) Tag</cell>
<cell>
(b) SingleTag count (out of 50,000 words)</cell>
<cell>
(c) Ambiguity Tag count (out of 50,000 words)
</cell>
<cell>
(d) Ambiguity rate (%)(c / b + c)</cell>
<cell>
(e) 1st tag of ambiguity tag correct (% of all ambiguity tags)</cell>
<cell>
(f) Error count</cell>
<cell>
(g) Error rate (%)(f / b)</cell>
</row>
<row><cell role="label">AJ0</cell>
<cell>
3412</cell>
<cell>
all 338 </cell>
<cell>
 9.01%</cell>
<cell>
282 (83.43%)</cell>
<cell>
46</cell>
<cell>
1.35%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(AJ0-AVO 48)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(AJ0-NN1 209)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(AJ0-VVD 21)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(AJ0-VVG 28)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(AJ0-VVN 32)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">AJC</cell>
<cell>
 142</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 4</cell>
<cell>
2.82%</cell>
</row>
<row><cell role="label">AJS</cell>
<cell>
 26</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 2</cell>
<cell>
7.69%</cell>
</row>
<row><cell role="label">AT0</cell>
<cell>
4351</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 2</cell>
<cell>
0.05%</cell>
</row>
<row><cell role="label">AV0</cell>
<cell>
2450</cell>
<cell>
all 45</cell>
<cell>
 1.80%</cell>
<cell>
37 (82.22%)</cell>
<cell>
57</cell>
<cell>
2.33%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(AV0-AJ0 45)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">AVP</cell>
<cell>
 379</cell>
<cell>
all 44</cell>
<cell>
10.40%</cell>
<cell>
34 (77.27%)</cell>
<cell>
 6</cell>
<cell>
1.58%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(AVP-PRP 44)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">AVQ</cell>
<cell>
 157</cell>
<cell>
all 10</cell>
<cell>
 5.99%</cell>
<cell>
10 (100.00%)</cell>
<cell>
 9</cell>
<cell>
5.73%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(AVQ-CJS 10)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">CJC</cell>
<cell>
1915</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 3</cell>
<cell>
0.16%</cell>
</row>
<row><cell role="label">CJS</cell>
<cell>
 692</cell>
<cell>
all 39</cell>
<cell>
 5.34%</cell>
<cell>
30 (76.92%)</cell>
<cell>
18</cell>
<cell>
2.60%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(CJS-AVQ 26)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(CJS-PRP 13)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">CJT</cell>
<cell>
 236 </cell>
<cell>
(all) 28</cell>
<cell>
10.61%</cell>
<cell></cell>
<cell>
 3</cell>
<cell>
1.27%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(CJT-DT0 28 ) </cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">CRD</cell>
<cell>
 940</cell>
<cell>
all 1</cell>
<cell>
 0.11%</cell>
<cell>
 0 (0.00%)</cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(CRD-PNI 1)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">DPS</cell>
<cell>
 787</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">DT0</cell>
<cell>
1180</cell>
<cell>
all 20</cell>
<cell>
 1.67%</cell>
<cell>
16 (80.00%)</cell>
<cell>
19</cell>
<cell>
1.61%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(DT0-CJT 20)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">DTQ</cell>
<cell>
 370</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">EX0</cell>
<cell>
 131</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 1</cell>
<cell>
0.76%</cell>
</row>
<row><cell role="label">ITJ</cell>
<cell>
 214</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 2</cell>
<cell>
0.93%</cell>
</row>
<row><cell role="label">NN0</cell>
<cell>
 270</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
10</cell>
<cell>
3.70%</cell>
</row>
<row><cell role="label">NN1</cell>
<cell>
7198</cell>
<cell>
all 514</cell>
<cell>
 6.66%</cell>
<cell>
395 (76.84%)</cell>
<cell>
86</cell>
<cell>
1.19%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(NN1-AJ0 130)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(NN1-NP0 92)*</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(NN1-VVB 243)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(NN1-VVG 49)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">NN2</cell>
<cell>
2718</cell>
<cell>
all 55</cell>
<cell>
 1.98%</cell>
<cell>
48 (87.27%)</cell>
<cell>
30</cell>
<cell>
1.10%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(NN2-VVZ 55)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">NP0</cell>
<cell>
1385</cell>
<cell>
all 264</cell>
<cell>
16.01%</cell>
<cell>
224 (84.84%)</cell>
<cell>
31</cell>
<cell>
2.24%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(NP0-NN1 264)*</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">ORD</cell>
<cell>
 136</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">PNI</cell>
<cell>
 159</cell>
<cell>
all 8</cell>
<cell>
 4.79%</cell>
<cell>
 3 (37.50%)</cell>
<cell>
 5</cell>
<cell>
3.14%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(PNI-CRD 8)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">PNP</cell>
<cell>
2646 </cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">PNQ</cell>
<cell>
 112</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">PNX</cell>
<cell>
 84</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">POS</cell>
<cell>
 217</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 5</cell>
<cell>
2.30%</cell>
</row>
<row><cell role="label">PRF</cell>
<cell>
1615 </cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">PRP</cell>
<cell>
4051</cell>
<cell>
all 166</cell>
<cell>
 3.94%</cell>
<cell>
154 (92.77%)</cell>
<cell>
24</cell>
<cell>
0.59%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(PRP-AVP 132)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(PRP-CJS 34)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">TO0</cell>
<cell>
 819</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 6</cell>
<cell>
0.73%</cell>
</row>
<row><cell role="label">UNC</cell>
<cell>
 158</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 4</cell>
<cell>
2.53%</cell>
</row>
<row><cell role="label">VBB</cell>
<cell>
 328</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 1</cell>
<cell>
0.30%</cell>
</row>
<row><cell role="label">VBD</cell>
<cell>
 663</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VBG</cell>
<cell>
 37</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VBI</cell>
<cell>
 374</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VBN</cell>
<cell>
 133</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VBZ</cell>
<cell>
 640</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 4</cell>
<cell>
0.63%</cell>
</row>
<row><cell role="label">VDB</cell>
<cell>
 87</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VDD</cell>
<cell>
 71</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VDG</cell>
<cell>
 10</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VDI</cell>
<cell>
 36</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VDN</cell>
<cell>
 20</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VDZ</cell>
<cell>
 22</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VHB</cell>
<cell>
 150</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 1</cell>
<cell>
0.67%</cell>
</row>
<row><cell role="label">VHD</cell>
<cell>
 258</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VHG</cell>
<cell>
 16</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VHI</cell>
<cell>
 119</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VHN</cell>
<cell>
 9</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">VHZ</cell>
<cell>
 116</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 1</cell>
<cell>
0.86%</cell>
</row>
<row><cell role="label">VM0</cell>
<cell>
 782</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 3</cell>
<cell>
0.38%</cell>
</row>
<row><cell role="label">VVB</cell>
<cell>
 560</cell>
<cell>
all 84</cell>
<cell>
13.04%</cell>
<cell>
56 (66.67%)</cell>
<cell>
84</cell>
<cell>
15.00%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(VVB-NN1 84)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">VVD</cell>
<cell>
 970</cell>
<cell>
all 90</cell>
<cell>
 8.49%</cell>
<cell>
62 (58.89%)</cell>
<cell>
50</cell>
<cell>
 5.15%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(VVD-AJ0 11)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(VVD-VVN 79)*</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">VVG</cell>
<cell>
 597</cell>
<cell>
all 132</cell>
<cell>
18.11%</cell>
<cell>
112 (84.84%)</cell>
<cell>
 9</cell>
<cell>
1.51%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(VVG-AJ0 83)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(VVG-NN1 49)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">VVI</cell>
<cell>
1211</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 7</cell>
<cell>
0.58%</cell>
</row>
<row><cell role="label">VVN</cell>
<cell>
1086</cell>
<cell>
all 158</cell>
<cell>
12.70%</cell>
<cell>
113 (71.52%)</cell>
<cell>
27</cell>
<cell>
2.49%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(VVN-AJ0 50)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(VVN-VVD 108)*</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">VVZ</cell>
<cell>
 295</cell>
<cell>
all 26</cell>
<cell>
 8.10%</cell>
<cell>
14 (53.85%)</cell>
<cell>
11</cell>
<cell>
3.73%</cell>
</row>
<row><cell></cell>
<cell></cell>
<cell>
(VVZ-NN2 26)</cell>
<cell></cell>
<cell></cell>
<cell></cell>
<cell></cell>
</row>
<row><cell role="label">XX0</cell>
<cell>
 363</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 0</cell>
<cell>
0.00%</cell>
</row>
<row><cell role="label">ZZ0</cell>
<cell>
 75</cell>
<cell></cell>
<cell>
 0.0%</cell>
<cell></cell>
<cell>
 3</cell>
<cell>
4.00%</cell>
</row>
</table>
 </div>
 <div><head>Estimated error rates specifying the incorrect tag and the correct tag (fine-grained calculation)</head>
 <p>The next table, <ptr target="#table-3"/>, gives the frequency, as
 a percentage, of error-prone tag-pairs where XXX is the incorrect tag
 and YYY is the correct tag which should have occurred in its
 place. In the third column, the number of the specified error-type is
 listed, as a frequency count from the sample of 50,000 words. In the
 fourth column, this is expressed as a percentage of all the tagging
 errors of word category XXX (in <ptr target="#table-2"/> column
 (f)). The fifth column answers the question: if tag XXX occurs, what
 is the likelihood that it is an error for tag YYY? Where the number
 of occurrences of a given error-type is less than 5 (i.e. 1 in 10,000
 words), they are ignored. Hence, <ptr target="#table-3"/> is not exhaustive: only the more likely error-types are listed. In the second column, we add, where useful, the individual words which trigger these errors.</p>
 <table rend="center" xml:id="table-3"><head>Estimated frequency of selected tag-pairs<!--, where XXX is the incorrect tag, and YYY is the correct one--></head>
<row role="label"><cell>
(1) Incorrect tag XXX</cell>
<cell >
(2) Corrected tag YYY</cell>
<cell >
(3) No. of occurrences of this error type</cell>
<cell >
(4) % of all incorrect uses of tag(XXX)
<!--(col 3 / Table 2 col(f))--></cell>
<cell >
(5) % of all tags XXX
<!--(col 3 / Table 2 col(b))--></cell>
</row>
<row><cell >
AJ0</cell>
<cell >
AVO</cell>
<cell >
12</cell>
<cell >
26.1%</cell>
<cell >
0.4%</cell>
</row>
<row><cell ></cell>
<cell >
NN1</cell>
<cell >
12</cell>
<cell >
26.1%</cell>
<cell >
0.4%</cell>
</row>
<row><cell ></cell>
<cell >
NP0</cell>
<cell >
 5</cell>
<cell >
10.9%</cell>
<cell >
0.1%</cell>
</row>
<row><cell ></cell>
<cell >
VVN</cell>
<cell >
 8</cell>
<cell >
17.4%</cell>
<cell >
0.2%</cell>
</row>
<row><cell >
AV0</cell>
<cell >
AJ0</cell>
<cell >
 6</cell>
<cell >
10.5%</cell>
<cell >
0.2%</cell>
</row>
<row><cell ></cell>
<cell >
AJC</cell>
<cell >
 8</cell>
<cell >
14.0%</cell>
<cell >
0.3%</cell>
</row>
<row><cell ></cell>
<cell >
DT0 </cell>
<cell >
24</cell>
<cell >
42.1%</cell>
<cell >
1.0%</cell>
</row>
<row><cell ></cell>
<cell >
EX (there)</cell>
<cell >
 5</cell>
<cell >
 8.8%</cell>
<cell >
0.2%</cell>
</row>
<row><cell ></cell>
<cell >
PRP</cell>
<cell >
 5</cell>
<cell >
 8.8%</cell>
<cell >
0.2%</cell>
</row>
<row><cell >
AVQ</cell>
<cell >
CJS (when, where)</cell>
<cell >
 6</cell>
<cell >
66.7%</cell>
<cell >
3.8%</cell>
</row>
<row><cell >
CJS</cell>
<cell >
PRP </cell>
<cell >
10</cell>
<cell >
55.6%</cell>
<cell >
1.4%</cell>
</row>
<row><cell >
DTO</cell>
<cell >
AV0 </cell>
<cell >
15</cell>
<cell >
78.9%</cell>
<cell >
1.3%</cell>
</row>
<row><cell >
NN1</cell>
<cell >
AJ0</cell>
<cell >
13</cell>
<cell >
15.1%</cell>
<cell >
0.2%</cell>
</row>
<row><cell ></cell>
<cell >
NN0*</cell>
<cell >
 8</cell>
<cell >
 9.3%</cell>
<cell >
0.1%</cell>
</row>
<row><cell ></cell>
<cell >
NP0*</cell>
<cell >
22</cell>
<cell >
25.6%</cell>
<cell >
0.3%</cell>
</row>
<row><cell ></cell>
<cell >
UNC</cell>
<cell >
 9</cell>
<cell >
10.5%</cell>
<cell >
0.2%</cell>
</row>
<row><cell ></cell>
<cell >
VVI</cell>
<cell >
13</cell>
<cell >
15.1%</cell>
<cell >
0.2%</cell>
</row>
<row><cell >
NN2</cell>
<cell >
NP0*</cell>
<cell >
14</cell>
<cell >
46.7%</cell>
<cell >
0.5%</cell>
</row>
<row><cell >
NP0</cell>
<cell >
NN1*</cell>
<cell >
10</cell>
<cell >
32.3%</cell>
<cell >
0.7%</cell>
</row>
<row><cell ></cell>
<cell >
NN0*</cell>
<cell >
 5</cell>
<cell >
16.1%</cell>
<cell >
0.4%</cell>
</row>
<row><cell >
PRP</cell>
<cell >
AV0</cell>
<cell >
 7</cell>
<cell >
29.2%</cell>
<cell >
0.2%</cell>
</row>
<row><cell ></cell>
<cell >
AVP</cell>
<cell >
 5</cell>
<cell >
20.8%</cell>
<cell >
0.1%</cell>
</row>
<row><cell >
TO0</cell>
<cell >
PRP (to)</cell>
<cell >
 6</cell>
<cell >
100.0%</cell>
<cell >
0.7%</cell>
</row>
<row><cell >
VVB</cell>
<cell >
AJ0</cell>
<cell >
 7</cell>
<cell >
 8.3%</cell>
<cell >
1.3%</cell>
</row>
<row><cell ></cell>
<cell >
NN1</cell>
<cell >
 7</cell>
<cell >
 8.3%</cell>
<cell >
1.3%</cell>
</row>
<row><cell ></cell>
<cell >
VVI*</cell>
<cell >
55</cell>
<cell >
65.5%</cell>
<cell >
9.8%</cell>
</row>
<row><cell >
VVD</cell>
<cell >
AJ0</cell>
<cell >
 6</cell>
<cell >
12.0%</cell>
<cell >
0.6%</cell>
</row>
<row><cell ></cell>
<cell >
VVN*</cell>
<cell >
44 </cell>
<cell >
88.0%</cell>
<cell >
4.5%</cell>
</row>
<row><cell >
VVG</cell>
<cell >
NN1</cell>
<cell >
 9</cell>
<cell >
100.0%</cell>
<cell >
1.5%</cell>
</row>
<row><cell >
VVI</cell>
<cell >
NN1</cell>
<cell >
 5</cell>
<cell >
71.4%</cell>
<cell >
0.4%</cell>
</row>
<row><cell >
VVN</cell>
<cell >
AJ0</cell>
<cell >
 7</cell>
<cell >
25.9%</cell>
<cell >
0.6%</cell>
</row>
<row><cell ></cell>
<cell >
VVD*</cell>
<cell >
17</cell>
<cell >
63.0%</cell>
<cell >
1.6%</cell>
</row>
<row><cell >
VVZ</cell>
<cell >
NN2</cell>
<cell >
 8</cell>
<cell >
72.7%</cell>
<cell >
2.7%</cell>
</row>
</table>
 <p>Similar to before, the asterisk * indicates a ‘less serious’ error, in which the erroneous and correct tags belong to the same major category or part of speech. As the table shows, the most frequent specific error types are within the verb category: VVB ? VVI (55, or 9.8% of all VVB tags) and VVD ? VVN (44, or 4.5% of all VVD tags).</p>
 </div>
 </div>
 <div><head>A further mode of calculation: ignoring subcategories of the same part of speech</head>
 <div xml:id="coarse"><head>Presentation of Ambiguity and Error Rates (coarse-grained calculation)</head>
 <p>Yet a further way of looking at the ambiguities and errors in the corpus is to make a coarse-grained calculation in counting these phenomena. In a fine-grained measurement, which is the one assumed up to now, each tag is considered to define its own word class which is different from all other word classes. Using the coarse-grained calculation, on the other hand, we consider words to belong to different word classes (parts of speech) only when the major category is different. If we consider the pair NN1 (singular and common noun) and NP0 (proper noun), the coarse-grained calculation says that the ambiguity tag NN1-NP0 or NP0-NN1 does not show tagging uncertainty, since both the proposed tags agree in categorizing the word as the same part of speech (a noun). So this does not add to the ambiguity rate. Similarly, the coarse-grained point of view on error is that, if a word is tagged as NN1 when it should be NP0, or vice versa, then this is not error, because both tags are within the noun category. To summarize: in the fine-grained calculation, minor differences of wordclass count towards the ambiguity and error rates; in the coarse-grained calculation, they do not.
 </p>

 <p>In this section, the same calculations are made as in section 3,
 except that errors and ambiguities which are confined within a major
 category (noun, verb, etc.) are ignored. In practice, most of the
 errors and ambiguities of this kind come from the difficulty the
 tagger finds in recognizing the difference between NN1 (singular
 common noun) and NP0 (proper noun), between VVD (past tense lexical
 verb) and VVN (past participle lexical verb), and between VVB (finite
 present tense base form, lexical verb) and VVI (infinitive lexical
 verb). Thus the ambiguity tags NN1-NP0, VVD-VVN and their mirror
 images do not occur in the relevant table (<ptr target="#table-5"/>) below. However,
 since there are no ambiguity tags for VVB and VVI, the problem of
 distinguishing these two shows up only in the error calculation. 
 </p>
<p>The
 three tables in this section correspond with the three tables in the
 preceding section.</p>
<!--

 <list><item> Table 4: Estimated ambiguity and error rates for the whole corpus (coarse-grained calculation)
 </item><item>Table 5: Estimated error rates for the whole corpus after ambiguities have been automatically eliminated (assuming the first part of each ambiguity tag to be correct)
 </item><item>Table 6: Estimated error rates (by tag) after the second tags of ambiguity tags have been automatically eliminated
 </item><item>Table 7: Estimated frequency of selected tag-pairs, where XXX is the incorrect tag, and YYY is the correct one (after the second tags of ambiguity tags have been eliminated automatically) </item></list>
 </p>
 -->
 
 <table rend="center" xml:id="table-4"><head><!--Table 4. -->Estimated ambiguity and error rates for the whole corpus<!-- (coarse-grained calculation)--></head>
<row role="label"><cell></cell>
<cell>
Sample tag count</cell>
<cell>
Ambiguity rate (%)</cell>
<cell>
Error rate (%)</cell>
</row>
<row><cell role="label">Written texts</cell>
<cell>
45,000</cell>
<cell>
2.78%</cell>
<cell>
0.69%</cell>
</row>
<row><cell role="label">Spoken texts</cell>
<cell>
 5,000</cell>
<cell>
2.67%</cell>
<cell>
0.87%</cell>
</row>
<row><cell role="label">All texts</cell>
<cell>
50,000</cell>
<cell>
2.77%</cell>
<cell>
0.71%</cell>
</row>
</table>
 <p>It will be noted from <ptr target="#table-4"/> that this method of
 calculation reduces the overall ambiguity rate by c.1 per cent, and
 the overall error rate by c.0.5 per cent. We will not present
 coarse-grained tables corresponding to <ptr target="#table-2"/> and
 <ptr target="#table-3"/> above: these
 tables would be unchanged from the fine-grained calculation, except
 that the rows marked with an asterisk (*) would be deleted, and the
 other calculations changed as necessary.</p>
 
</div>
 <div><head>Different modes of calculation: eliminating ambiguities</head> 

 <p>Given that the elimination of errors was beyond our capability
 within the time frame and budget we had available, the corpus in its
 present form, containing ambiguity tags as well as a small proportion
 of errors, is designed for what we believe will be the most common
 type of user, who will find it easier to tolerate ambiguity than
 error. However, other users may prefer a corpus which does not
 contain ambiguities, even though its error rate is higher. For this
 latter type of user, the present corpus is easy to interpret as a
 corpus free of ambiguities, simply by deleting or ignoring the second
 tag of any ambiguity tag, and accepting the first tag as the only
 one. In what follows, we therefore allow two modes of calculation: in
 addition to the "safer" mode, in which ambiguities are allowed and
 consequently errors are relatively low, we allow a "riskier" mode in
 which ambiguities are abolished, and errors are more frequent. In
 fact, if ambiguity tags are eliminated, the overall error rate rises
 to almost 2 per cent.</p>

 <table rend="center" xml:id="table-5"><head><!--Table 5: -->Estimated error rates for the whole corpus<!-- after ambiguities have been automatically eliminated (assuming the first part of each ambiguity tag to be correct)--></head>
<row role="label"><cell ></cell>
<cell >
Sample tag count</cell>
<cell >
Error rate (%)</cell>
</row>
<row><cell >
Written texts</cell>
<cell >
45,000</cell>
<cell >
2.01%</cell>
</row>
<row><cell >
Spoken texts</cell>
<cell >
 5,000</cell>
<cell >
1.92%</cell>
</row>
<row><cell >
All texts</cell>
<cell >
50,000</cell>
<cell >
2.00%</cell>
</row>
</table>

 <p>The following table gives an error count (c) for each tag:
 i.e. the number of errors in the 50,000 word sample where that tag
 was the erroneous tag. [Cf. the "safer" error count in <ptr target="#table-3"/>,
 column (f).] In addition, each tag has a correction count (d):
 i.e. the number of erroneous tags for which that tag was the correct
 tag. If we subtract the Error count (c) from the Tag count (b), and
 add the Correction count (d) to the result, we arrive at the "Real
 tag count" (e) representing the number of occurrences of that tag in
 the corrected sample corpus. Not included in the table is the small
 number of ‘multiword’ errors which resulted in two tags being
 replaced by one (error count), or one tag being replaced by two
 (correction count), due to the incorrect non-use or use of multiword
 tags. The last column divides the error count by the tag count to
 provide the error rate (as a percentage).</p>
 
 
 <table rend="center" xml:id="table-6"><head>Estimated error rates (by tag)<!-- after the second tags of ambiguity tags have been automatically eliminated--></head>
<row role="label"><cell>
(a)
Tag</cell>
<cell>
(b)
Tag count</cell>
<cell>
(c)
Error count</cell>
<cell >
(d)
Correction count</cell>
<cell>
(e)
Real tag count 
(b - c + d )</cell>
<cell >
(f)
Error rate (%) 
(c / b)x 100</cell>
</row>
<row><cell role="label">AJ0</cell>
<cell>
3750</cell>
<cell>
102</cell>
<cell >
(132)</cell>
<cell>
3780</cell>
<cell >
2.72%</cell>
</row>
<row><cell role="label">AJC</cell>
<cell>
 142</cell>
<cell>
 4</cell>
<cell >
 (12)</cell>
<cell>
 150</cell>
<cell >
2.82%</cell>
</row>
<row><cell role="label">AJS</cell>
<cell>
 26</cell>
<cell>
 2</cell>
<cell >
 (0)</cell>
<cell>
 24</cell>
<cell >
7.69%</cell>
</row>
<row><cell role="label">AT0</cell>
<cell>
4351</cell>
<cell>
 2</cell>
<cell >
 (3)</cell>
<cell>
4352</cell>
<cell >
0.05%</cell>
</row>
<row><cell role="label">AV0</cell>
<cell>
2495</cell>
<cell>
 65</cell>
<cell >
 (67)</cell>
<cell>
2497</cell>
<cell >
2.61%</cell>
</row>
<row><cell role="label">AVP</cell>
<cell>
 423</cell>
<cell>
 16</cell>
<cell >
 (17)</cell>
<cell>
 424</cell>
<cell >
3.78%</cell>
</row>
<row><cell role="label">AVQ</cell>
<cell>
 167</cell>
<cell>
 9</cell>
<cell >
 (6)</cell>
<cell>
 164</cell>
<cell >
5.39%</cell>
</row>
<row><cell role="label">CJC</cell>
<cell>
1915</cell>
<cell>
 3</cell>
<cell >
 (1)</cell>
<cell>
1913</cell>
<cell >
0.16%</cell>
</row>
<row><cell role="label">CJS</cell>
<cell>
 731</cell>
<cell>
 27</cell>
<cell >
 (5)</cell>
<cell>
 709</cell>
<cell >
3.69%</cell>
</row>
<row><cell role="label">CJT</cell>
<cell>
 264</cell>
<cell>
 3</cell>
<cell >
 (15)</cell>
<cell>
 276</cell>
<cell >
1.14%</cell>
</row>
<row><cell role="label">CRD</cell>
<cell>
 940</cell>
<cell>
 1</cell>
<cell >
 (11)</cell>
<cell>
 950</cell>
<cell >
0.11%</cell>
</row>
<row><cell role="label">DPS</cell>
<cell>
 787</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 787</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">DT0</cell>
<cell>
1200</cell>
<cell>
 23</cell>
<cell >
 (29)</cell>
<cell>
1206</cell>
<cell >
1.92%</cell>
</row>
<row><cell role="label">DTQ</cell>
<cell>
 370</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 370</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">EX0</cell>
<cell>
 131</cell>
<cell>
 1</cell>
<cell >
 (5)</cell>
<cell>
 135</cell>
<cell >
0.76%</cell>
</row>
<row><cell role="label">ITJ</cell>
<cell>
 214</cell>
<cell>
 2</cell>
<cell >
 (2)</cell>
<cell>
 214</cell>
<cell >
0.93%</cell>
</row>
<row><cell role="label">NN0</cell>
<cell>
 270</cell>
<cell>
 10</cell>
<cell >
 (16)</cell>
<cell>
 276</cell>
<cell >
0.37%</cell>
</row>
<row><cell role="label">NN1</cell>
<cell>
7712</cell>
<cell>
205</cell>
<cell >
(152)</cell>
<cell>
7659</cell>
<cell >
2.66%</cell>
</row>
<row><cell role="label">NN2</cell>
<cell>
2773</cell>
<cell>
 37</cell>
<cell >
 (29)</cell>
<cell>
2765</cell>
<cell >
1.33%</cell>
</row>
<row><cell role="label">ORD</cell>
<cell>
 136</cell>
<cell>
 0</cell>
<cell >
 (2)</cell>
<cell>
 138</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">NP0</cell>
<cell>
1649</cell>
<cell>
 71</cell>
<cell >
(102)</cell>
<cell>
1680</cell>
<cell >
4.31%</cell>
</row>
<row><cell role="label">PNI</cell>
<cell>
 167</cell>
<cell>
 10</cell>
<cell >
 (1)</cell>
<cell>
 158</cell>
<cell >
5.99%</cell>
</row>
<row><cell role="label">PNP</cell>
<cell>
2646</cell>
<cell>
 0</cell>
<cell >
 (1)</cell>
<cell>
2647</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">PNQ</cell>
<cell>
 112</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 112</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">PNX</cell>
<cell>
 84</cell>
<cell>
 0</cell>
<cell >
 (1)</cell>
<cell>
 85</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">POS</cell>
<cell>
 217</cell>
<cell>
 5</cell>
<cell >
 (6)</cell>
<cell>
 218</cell>
<cell >
2.30%</cell>
</row>
<row><cell role="label">PRF</cell>
<cell>
1615</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
1615</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">PRP</cell>
<cell>
4217</cell>
<cell>
 36</cell>
<cell >
 (45)</cell>
<cell>
4226</cell>
<cell >
0.85%</cell>
</row>
<row><cell role="label">TO0</cell>
<cell>
 819</cell>
<cell>
 6</cell>
<cell >
 (1)</cell>
<cell>
 814</cell>
<cell >
0.73%</cell>
</row>
<row><cell role="label">UNC</cell>
<cell>
 158</cell>
<cell>
 4</cell>
<cell >
 (29)</cell>
<cell>
 183</cell>
<cell >
2.53%</cell>
</row>
<row><cell role="label">VBB</cell>
<cell>
 328</cell>
<cell>
 1</cell>
<cell >
 (0)</cell>
<cell>
 327</cell>
<cell >
0.30%</cell>
</row>
<row><cell role="label">VBD</cell>
<cell>
 663</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 663</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VBG</cell>
<cell>
 37</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 37</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VBI</cell>
<cell>
 374</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 374</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VBN</cell>
<cell>
 133</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 133</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VBZ</cell>
<cell>
 640</cell>
<cell>
 4</cell>
<cell >
 (5)</cell>
<cell>
 641</cell>
<cell >
0.63%</cell>
</row>
<row><cell role="label">VDB</cell>
<cell>
 87</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 87</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VDD</cell>
<cell>
 71</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 71</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VDG</cell>
<cell>
 10</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 10</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VDI</cell>
<cell>
 36</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 36</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VDN</cell>
<cell>
 20</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 20</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VDZ</cell>
<cell>
 22</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 22</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VHB</cell>
<cell>
 150</cell>
<cell>
 1</cell>
<cell >
 (0)</cell>
<cell>
 151</cell>
<cell >
0.67%</cell>
</row>
<row><cell role="label">VHD</cell>
<cell>
 258</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 258</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VHG</cell>
<cell>
 16</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 16</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VHI</cell>
<cell>
 119</cell>
<cell>
 0</cell>
<cell >
 (1)</cell>
<cell>
 120</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VHN</cell>
<cell>
 9</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 9</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">VHZ</cell>
<cell>
 116</cell>
<cell>
 1</cell>
<cell >
 (0)</cell>
<cell>
 115</cell>
<cell >
0.86%</cell>
</row>
<row><cell role="label">VM0</cell>
<cell>
 782</cell>
<cell>
 3</cell>
<cell >
 (0)</cell>
<cell>
 779</cell>
<cell >
0.38%</cell>
</row>
<row><cell role="label">VVB</cell>
<cell>
 644</cell>
<cell>
112</cell>
<cell >
 (13)</cell>
<cell>
 545</cell>
<cell >
17.39%</cell>
</row>
<row><cell role="label">VVD</cell>
<cell>
1060</cell>
<cell>
 78</cell>
<cell >
 (60)</cell>
<cell>
1042</cell>
<cell >
7.36%</cell>
</row>
<row><cell role="label">VVG</cell>
<cell>
 729</cell>
<cell>
 29</cell>
<cell >
 (29)</cell>
<cell>
 729</cell>
<cell >
3.98%</cell>
</row>
<row><cell role="label">VVI</cell>
<cell>
1211</cell>
<cell>
 7</cell>
<cell >
 (73)</cell>
<cell>
1277</cell>
<cell >
0.57%</cell>
</row>
<row><cell role="label">VVN</cell>
<cell>
1244</cell>
<cell>
 72</cell>
<cell >
 (87)</cell>
<cell>
1259</cell>
<cell >
5.79%</cell>
</row>
<row><cell role="label">VVZ</cell>
<cell>
 321</cell>
<cell>
 23</cell>
<cell >
 (12)</cell>
<cell>
 310</cell>
<cell >
7.17%</cell>
</row>
<row><cell role="label">XX0</cell>
<cell>
 363</cell>
<cell>
 0</cell>
<cell >
 (0)</cell>
<cell>
 363</cell>
<cell >
0.00%</cell>
</row>
<row><cell role="label">ZZ0</cell>
<cell>
 75</cell>
<cell>
 3</cell>
<cell >
 (4)</cell>
<cell>
 76</cell>
<cell >
4.00%</cell>
</row>
</table>
 
 
 <p>It is clear from this table that the amount of error in the
 tagging of the corpus varies greatly from one tag to another. The
 most error prone-tag, by a large margin, is <code>VVB</code>, with
 more than 17 per cent error, while many of the tags are associated
 with no errors at all, and well over half the tags have less than a 1
 per cent error.
 
 The final table gives figures for the third level of detail, where we
 itemise individual tag pairs XXX, YYY, where XXX is the incorrect
 tag, and YYY is the correct one which should have appeared but did
 not. Only those pairings which account for 5 or more errors are
 listed. This table differs from <ptr target="#table-3"/> in that here
 the second tags of ambiguity tags are not taken into account
 ("riskier mode"). It will be seen that the errors which occur tend to
 fall into a relatively small number of major categories.</p>
<p>The percentages in columns 4 and 5 of this table are calculated
with respect to the figures given in <ptr target="#table-2"/>. 
 <table rend="center" xml:id="table-7"><head>Estimated frequency of selected tag-pairs</head>

<!--, where XXX is the incorrect tag, and YYY is the correct one (after the second tags of ambiguity tags have been eliminated automatically) based on the sample of 50,000 words</head>-->
<row role="label"><cell >
Incorrect tag XXX</cell>
<cell >
Correct tag YYY</cell>
<cell >
No. of occurrences of this error type</cell>
<cell >
% of all incorrect uses of tag XXX</cell>
<!--(col 3 / Table 2 col(f))</cell>-->
<cell >
% of all tags XXX</cell>
<!--(col 3 / Table 2 col(b))</cell>-->
</row>
<row><cell >
AJ0 </cell>
<cell >
AV0</cell>
<cell >
22</cell>
<cell >
21.57%</cell>
<cell >
0.59%</cell>
</row>
<row><cell ></cell>
<cell >
NN1</cell>
<cell >
41</cell>
<cell >
40.19%</cell>
<cell >
1.09%</cell>
</row>
<row><cell ></cell>
<cell >
NP0</cell>
<cell >
 5</cell>
<cell >
 4.90%</cell>
<cell >
0.13%</cell>
</row>
<row><cell ></cell>
<cell >
VVG</cell>
<cell >
14</cell>
<cell >
13.73%</cell>
<cell >
0.37%</cell>
</row>
<row><cell ></cell>
<cell >
VVN</cell>
<cell >
14</cell>
<cell >
13.73%</cell>
<cell >
0.37%</cell>
</row>
<row><cell >
AV0</cell>
<cell >
AJ0</cell>
<cell >
 9</cell>
<cell >
13.85% </cell>
<cell >
0.36%</cell>
</row>
<row><cell ></cell>
<cell >
AJC</cell>
<cell >
 8</cell>
<cell >
12.31%</cell>
<cell >
0.32%</cell>
</row>
<row><cell ></cell>
<cell >
DT0</cell>
<cell >
26</cell>
<cell >
40.00%</cell>
<cell >
1.04%</cell>
</row>
<row><cell ></cell>
<cell >
EX0 (there)</cell>
<cell >
 5</cell>
<cell >
 7.69%</cell>
<cell >
0.20%</cell>
</row>
<row><cell ></cell>
<cell >
PRP</cell>
<cell >
 6</cell>
<cell >
 9.23%</cell>
<cell >
0.24%</cell>
</row>
<row><cell >
AVP</cell>
<cell >
CJT</cell>
<cell >
 6</cell>
<cell >
94.12%</cell>
<cell >
1.42%</cell>
</row>
<row><cell >
AVQ</cell>
<cell >
CJS (when, where)</cell>
<cell >
 6</cell>
<cell >
66.67%</cell>
<cell >
3.59%</cell>
</row>
<row><cell >
CJS</cell>
<cell >
PRP </cell>
<cell >
15</cell>
<cell >
55.56%</cell>
<cell >
2.05%</cell>
</row>
<row><cell >
DTO</cell>
<cell >
AV0 (much, more, etc)</cell>
<cell >
15</cell>
<cell >
65.22%</cell>
<cell >
1.25%</cell>
</row>
<row><cell >
NN1</cell>
<cell >
AJ0</cell>
<cell >
63</cell>
<cell >
30.73%</cell>
<cell >
0.82%</cell>
</row>
<row><cell ></cell>
<cell >
NN0</cell>
<cell >
 8</cell>
<cell >
 3.90%</cell>
<cell >
0.10%</cell>
</row>
<row><cell ></cell>
<cell >
NP0</cell>
<cell >
74</cell>
<cell >
36.10% </cell>
<cell >
0.96%</cell>
</row>
<row><cell ></cell>
<cell >
UNC</cell>
<cell >
 9</cell>
<cell >
 4.39%</cell>
<cell >
0.12%</cell>
</row>
<row><cell ></cell>
<cell >
VVB</cell>
<cell >
 9</cell>
<cell >
 4.39%</cell>
<cell >
0.12%</cell>
</row>
<row><cell ></cell>
<cell >
VVG</cell>
<cell >
13</cell>
<cell >
 6.34%</cell>
<cell >
0.17%</cell>
</row>
<row><cell ></cell>
<cell >
VVI</cell>
<cell >
13</cell>
<cell >
 6.34%</cell>
<cell >
0.17%</cell>
</row>
<row><cell >
NN2</cell>
<cell >
NP0</cell>
<cell >
14</cell>
<cell >
37.84%</cell>
<cell >
0.50%</cell>
</row>
<row><cell ></cell>
<cell >
UNC</cell>
<cell >
 9</cell>
<cell >
24.32%</cell>
<cell >
0.32%</cell>
</row>
<row><cell ></cell>
<cell >
VVZ</cell>
<cell >
10</cell>
<cell >
27.02%</cell>
<cell >
0.36%</cell>
</row>
<row><cell >
NN0</cell>
<cell >
UNC</cell>
<cell >
 7</cell>
<cell >
70.00%</cell>
<cell >
2.59%</cell>
</row>
<row><cell >
NP0</cell>
<cell >
NN1</cell>
<cell >
50</cell>
<cell >
70.42%</cell>
<cell >
3.03%</cell>
</row>
<row><cell ></cell>
<cell >
NN2</cell>
<cell >
 5</cell>
<cell >
 7.04%</cell>
<cell >
0.30%</cell>
</row>
<row><cell >
PNI </cell>
<cell >
CRD (one)</cell>
<cell >
 9</cell>
<cell >
90.00% </cell>
<cell >
5.39%</cell>
</row>
<row><cell >
PRP</cell>
<cell >
AV0</cell>
<cell >
 8</cell>
<cell >
22.22%</cell>
<cell >
0.19%</cell>
</row>
<row><cell >
TO0</cell>
<cell >
PRP (to)</cell>
<cell >
 6</cell>
<cell >
100.00%</cell>
<cell >
0.73%</cell>
</row>
<row><cell >
VVB</cell>
<cell >
AJ0</cell>
<cell >
 7</cell>
<cell >
 6.25%</cell>
<cell >
1.09%</cell>
</row>
<row><cell ></cell>
<cell >
NN1</cell>
<cell >
35</cell>
<cell >
31.25%</cell>
<cell >
5.43%</cell>
</row>
<row><cell ></cell>
<cell >
VVI</cell>
<cell >
55</cell>
<cell >
49.11%</cell>
<cell >
8.54%</cell>
</row>
<row><cell ></cell>
<cell >
VVN</cell>
<cell >
 5</cell>
<cell >
 4.46%</cell>
<cell >
0.85%</cell>
</row>
<row><cell >
VVD</cell>
<cell >
AJ0</cell>
<cell >
14</cell>
<cell >
17.95%</cell>
<cell >
1.32%</cell>
</row>
<row><cell ></cell>
<cell >
VVN</cell>
<cell >
64</cell>
<cell >
82.05%</cell>
<cell >
6.04%</cell>
</row>
<row><cell >
VVG</cell>
<cell >
AJ0</cell>
<cell >
11</cell>
<cell >
37.93%</cell>
<cell >
1.51%</cell>
</row>
<row><cell ></cell>
<cell >
NN1</cell>
<cell >
18</cell>
<cell >
62.07%</cell>
<cell >
2.47%</cell>
</row>
<row><cell >
VVI</cell>
<cell >
NN1</cell>
<cell >
 5</cell>
<cell >
71.43%</cell>
<cell >
0.41%</cell>
</row>
<row><cell >
VVZ</cell>
<cell >
NN2</cell>
<cell >
20</cell>
<cell >
86.96%</cell>
<cell >
6.23%</cell>
</row>
</table>
</p>
 <p>Some of the error types above are associated with one or two particular words, and where these occur they are listed. For example, the AV0 - EX0 type of error occurs invariably with the one word there.</p>

 <p>Finally, we list here the text samples used to constitute the
manually-conducted 50,000-word error analysis.  Each sample consisted
of 2,000 words taken from the BNC texts listed below, except that two
samples, one of written and one of spoken English, consisted of 1,000
words only. These samples are marked "*" in the list below. The reason
for using half-length samples in two cases was to maintain the
proportion of written and spoken data as 90% - 10%, so as to keep the
proportions of the sample the same as the proportions in the BNC as a
whole. The BNC text files are cited by the three-character code used
in the BNC Users Reference Guide.
 <list type="gloss">
<label>Written imaginative writing</label>
<item> G0S, ADY, H7P, GW0, FSF </item>
<label>Written informative writing</label>
<item><list type="gloss">
<label>Natural Science</label><item>JXN</item>
<label>Applied Science</label><item>HWV, CEG</item>
<label>Social Science</label><item>CLH, EE8, *A6Y</item>
<label>World Affairs</label><item>A4J, CMT, EE2, EB7</item>
<label>Commerce and finance</label><item>HGP, B27</item>
<label>Arts</label><item>C9U, G1N</item>
<label>Belief and thought</label><item>CA9</item>
<label>Leisure</label><item>EX0, ADR, CE4</item>
</list> </item>
<label>Spoken demographic</label><item> KBG</item>
<label>Spoken context-governed</label><item> D8Y, *FXH</item></list>
</p></div>
 </div> 

  <div xml:id="prog"><head>POS-Tagging Workflow</head>
   
    <p>The overall process of creating the wordclass annotation may be
    summarized as follows:

<list>
<!--This document describes the overall process of POS-tagging texts
     for version 2 of the British National Corpus.  Listed below are
     the main stages involved: stages A-D are handled by the CLAWS4
     tagger; stage E, <ref target="#tt">Template Tagger</ref> is a
     corrective phase for CLAWS; the main part of F, <ref
     target="#pm">Ambiguity Tagging</ref>, describes the conversion of
     some less reliable tags into dual tags containing more than one
     part of speech.  <list><head>Wordclass Tagging schema for BNC
     XML</head>-->
    <item>
     <ref target="#tokenization2">A. Tokenization</ref>
      </item>
     <item><ref target="#initassignment">B. Initial tag assignment</ref></item>
     <item><ref target="#disambiguation">C. Tag selection (disambiguation)</ref></item>
     <item><ref target="#idiomtag">D. Idiom-Tagging</ref></item>
     <item><ref target="#tt">E. Template Tagger</ref></item>
      <item><ref target="#postproc">F. Postprocessing: including Ambiguity tagging</ref></item>
     </list>
    </p>     
 <p>The first four phases were carried out automatically, using
 CLAWS4, an automatic tagger which developed out of the CLAWS1
 automatic tagger (authors: Roger Garside and <ref target="#refs">Ian
 Marshall 1983</ref>) used to tag the LOB Corpus. The advanced version
 CLAWS4 is principally the work of Roger Garside, although many other
 researchers at Lancaster have contributed to its performance in one
 way or another. Further information about CLAWS4 can be obtained from
 <ref target="#refs">Leech, Garside and Bryant 1994</ref> and <ref
 target="#refs">Garside and Smith 1997</ref>.  CLAWS4 is a
 <emph>hybrid</emph> tagger, employing a mixture of probabilistic and
 non-probabilistic techniques. The fifth and sixth phases used other
 systems,described in the appropriate section below.
         </p>
     <div xml:id="tokenization2">
      <head>A. Tokenization</head>
      
      <p>The first major step in automatic tagging is to divide up the
      text or corpus to be tagged into individual (1) word tokens and
      (2) orthographic sentences. These are the segments usually
      demarcated by (1) spaces and (2) sentence boundaries
      (i.e. sentence final punctuation followed by a capital
      letter). This procedure is not so straightforward as it might
      seem, particularly because of the ambiguity of full stops (which
      can be abbreviation marks as well as sentence-demarcators) and
      of capital letters (which can signal a naming expression, as
      well as the beginning of a sentence). Faults in tokenization
      occasionally occur, but rarely cause tagging errors.</p>
     
      <p>In tokenization, an orthographic word boundary (normally a
      space, with or without accompanying punctuation) is the default
      test for identifying the beginning and end of word-tokens. (See,
      however, the next paragraph and <ptr target="#idiomtag"/>
      below.)  Hyphens are counted as word-internal, so that a
      hyphenated word such as <hi rend="italic">key-ring</hi> is given just one tag
      (<code>NN1</code>). Because of the different ways of writing
      compound words, the same compound may occur in three forms: as a
      single word written ‘solid’ (<hi rend="italic">markup</hi>), as a hyphenated
      word (<hi rend="italic">mark-up</hi>) or as a sequence of two words (<hi rend="italic">mark
      up</hi>). In the first two cases, CLAWS4 will give the compound
      a single tag, whereas in the third case, it will receive two
      tags: one for <hi rend="italic">mark</hi> and the other for <hi rend="italic">up</hi>.</p>
      
      <p>A set of special cases dealt with by tokenization is the set
      of enclitic verb and negative contractions such as <hi rend="italic">'s, 're,
      'll</hi> and <hi rend="italic">'nt</hi>, which are orthographically attached
      to the preceding word. These will be given a tag of their own,
      so that (for example) the orthographic forms <hi rend="italic">It's</hi>,
      <hi rend="italic">they're,</hi> and <hi rend="italic">can't</hi> are given two tags in
      sequence: pronoun + verb, verb + negative, etc. There are also
      some 'merged' forms such as <hi rend="italic">won't</hi> and <hi rend="italic">dunno</hi>,
      which are decomposed into more than one word for tagging
      purposes. For example, <hi rend="italic">dunno</hi> actually ends up with the
      three tags for <hi rend="italic">do + n't + know</hi> (for a list of these
      contracted forms, see <ptr target="#defrobs"/>). </p>
     </div>
     
     <div xml:id="initassignment">
      <head>B. Initial assignment of tags</head>
      
      <p>The second stage of CLAWS POS-tagging is to assign to each word token one or more tags. Many word tokens are unambiguous, and so will be assigned just one tag: e.g. <hi rend="italic">various</hi> AJ0 (adjective). Other word tokens are ambiguous, taking from two to seven potential tags. For example, the token <hi rend="italic">paint</hi> can be tagged NN1, VVB, VVI, i.e. as a noun or as a verb; the token <hi rend="italic">broadcast</hi> can be tagged as VVB, VVI, VVD, VVN (verb which is either present tense, infinitive, past tense, or past participle). In addition, it can be a noun (NN1) or an adjective (<code>AJ0</code>), as in <hi rend="italic">a broadcast concert</hi>.</p>
      
      <p>To find the list of potential tags associated with a word, CLAWS first looks up the word in a  lexicon of c.50,000 word entries. This lexicon look-up accounts for a large proportion of the word tokens in a text. However, many rarer words or names will not be found in the lexicon, and are tagged by other test procedures. Some of the other procedures are:
       
       
       <list>
        <item>Look for the ending of a word: e.g. words in <hi rend="italic">-ness</hi> will normally be nouns.</item>
        <item>Look for an initial capital letter (especially when the word is not sentence-initial). Rare names which are not in the lexicon and do not match other procedures will normally be recognized as proper nouns on the basis of the initial capital.</item>
        <item>Look for a final -(<hi rend="italic">e</hi>)<hi rend="italic">s</hi>. This is stripped off, to see if the word otherwise matches a noun or verb; if it does, the word in -<hi rend="italic">s</hi> is tagged as a plural noun or a singular present-tense verb.</item>
        <item>Numbers and formulae (e.g. <hi rend="italic">271, *K9,  +</hi>) are tagged by special rules.</item>
        <item>If all else fails, a word is tagged ambiguously as either a noun, an adjective or a lexical verb.</item>
       </list>
       </p>
       <p>When a word is associated with more than one tag, information is given by the lexicon look-up or other procedures on the relative probability of each tag. For example, the word <hi rend="italic">for</hi> can be a preposition or a conjunction, but is much more likely to be a preposition. This information is provided by the lexicon, either in numerical form, or where numerical data available are insufficient, by a simple distinction between 'unmarked', 'rare' and 'very rare' tags.</p>
       
       <p>Some adjustment of probability is made according to the position of the word in the sentence. If a word begins with a capital, the likelihood of various tags depends partly on whether the word occurs at the beginning of a sentence. For instance, the word <hi rend="italic">Brown</hi> at the beginning of a sentence is less likely to be a proper noun than an adjective or a common noun (normally written <hi rend="italic">brown</hi>). Hence the likelihood of a proper noun tag being assigned is reduced at the beginning of a sentence. </p>
     </div>
     
     <div xml:id="disambiguation">
      <head>C. Tag selection (or disambiguation)</head>
      
      <p>The next stage, logically, is to choose the most probable tag
      from any ambiguous set of tags associated with a word token by
      tag assignment (but see <ptr target="#idiomtag"/> below). This is another
      probabilistic procedure, this time making use of the context in
      which a word occurs. A method known as <hi rend="italic">Viterbi
      alignment</hi> uses the probabilistic estimates available, both
      in terms of the tag-word associations and the sequential tag-tag
      likelihoods, to calculate the most likely path through the
      sequence of tag ambiguities. (The model employed is largely
      equivalent to a hidden Markov model.) After tag selection, a
      single 'winning tag' is selected for each word token in a
      text. (The less likely tags are not obliterated: they follow the
      winning tag in descending probability order.) However, the
      winning tag is not necessarily the right answer. If the CLAWS
      tagging stopped at this point, only c.95-96% of the word-tokens
      would be correctly tagged. This is the main reason for including
      an additional stage (or rather a set of stages) termed
      'idiom-tagging'.</p>
     </div>
     
     <div xml:id="idiomtag">
      <head>D. Idiom-Tagging</head>
      
      <p>Idiom-tagging is a stage of CLAWS4's operation in which
      sequences of words and tags are matched against a
      <term>template</term>. Depending on the match, the tags may be
      disambiguated or corrected. In practice, there are two main
      reasons for idiom-tagging:
      
      <list>
       <item>The correct tag can only be selected if CLAWS looks at a word+tag sequence as a whole. In tag selection, this was not done, since the program merely used 'bigrams' consisting of two tags in sequence. In other words, idiom-tagging is more powerful than the <hi rend="italic">Viterbi</hi> disambiguation  algorithm because it is able to operate on a 'window' of several word tokens at once.</item>
       <item>There are many cases in English where a sequence of orthographic words is best assigned a single tag. Such cases include <hi rend="italic">because of</hi>  (a preposition), <hi rend="italic">so long as</hi> (a conjunction), and <hi rend="italic">of course</hi> (an adverb). These so-called multiwords are the opposite of the contracted forms such as <hi rend="italic">don't</hi> and <hi rend="italic">there's</hi>, where one orthographic word is assigned more than one tag. Thus idiom-tagging here plays the role of adjusting tokenization to larger units.</item></list>
       </p>
      
      <p>Idiom-tagging is a matching procedure which operates on lists of rules which might loosely be termed <q>idioms</q>. Among these are:
       
       <list>
        <item>a list of multiwords (just described) such as <hi rend="italic">because of</hi>, <hi rend="italic">so long as</hi> and <hi rend="italic">of course</hi>.</item>
        <item>a list of place name expressions (e.g. <hi rend="italic">Mount X</hi> , where <hi rend="italic">X</hi> is some word beginning with a capital).</item>
        <item>a list of personal name expressions (e.g. <hi rend="italic">Dr. (X) Y</hi>, where <hi rend="italic">X</hi> and <hi rend="italic">Y</hi> are words beginning with a cap.; the word <hi rend="italic">X</hi> may or may not appear in the matching word sequence).</item>
        <item>a list of foreign or classical language expressions used in English (e.g. <hi rend="italic">de jure</hi>, <hi rend="italic">hoi polloi</hi>)</item>
        <item>a list of grammatical sequences where there are typically 'slots' in the sequence which may or may not be filled: e.g. Modal  + (adverb/negative) + (adverb/negative) + Infinitive. This matches a sequence such as <hi rend="italic">would not necessarily like</hi>. The recognition that the word token <hi rend="italic">like</hi> here is an infinitive verb (rather than, say, a present-tense verb or a preposition) could not be trusted if the tagger was not equipped with an idiom-tagging component, but had to rely simply on tag-pair probabilities.
        </item>
       </list></p>
      
      <p>The idiom-tagging component of CLAWS is quite powerful in
      matching 'template' expressions in which there are wild-card
      symbols, Boolean operators and gaps of up to
      <hi rend="italic">n</hi> words. They are much more variable than <q>idioms</q> in
      the ordinary sense, and resemble finite-state networks.</p>
      
      <p>Another important point about idiom-tagging is that it is
      split up into two main phases which operate at different points
      in the tagging system. One part of the idiom-tagging takes place
      at the end of Stage C., in effect retrospectively correcting
      some of the errors which would otherwise occur in CLAWS
      output. Another part, however, actually takes place
      <emph>between</emph> Stages B. and C.  This means it can utilise
      ambiguous input and also produce ambiguous output, perhaps
      adjusting the likelihood of one tag relative to another. As an
      example, consider the case of <hi rend="italic">so long as</hi>, which can be
      a single grammatical item - a conditional conjunction meaning
      'provided that'. The difficulty is that <hi rend="italic">so long as</hi> can
      also be a sequence of three separate grammatical items: degree
      adverb + adjective/adverb + conjunction/preposition. In this
      case, the tagging ambiguity belongs to a whole word sequence
      rather than a single word, and the output of the idiom-tagging
      has to be passed on to the probabilistic tag selection
      stage. Hence, although we have called idiom-tagging <q>Stage D</q>,
      it is actually split between two stages, one preceding C. and
      one following C.</p>
      
      
      <p>When the text emerges from Stages C. and D., each word has an associated set of one or more tags associated with it, and each tag itself is associated with a probability represented as a percentage. An example is:
<q rend="display">   
        <hi rend="italic">entering</hi> VVG 86% NN1 14%  AJ0  0%</q>
       
       Clearly VVG (<hi rend="italic">-ing</hi> participle of the verb <hi rend="italic">enter</hi>) is judged by CLAWS4 to be the most likely tag in this case.</p>
      
     </div>

     <div xml:id="tt">
      <head>E. After CLAWS: the Template Tagger</head>
      
      <p>The error rate with CLAWS4 averages around 3%.<note place="foot">That is, the error rate based on CLAWS's first choice tag only.</note> For the BNC Tagging Enhancement project, we decided to concentrate our efforts on the rule-based part of the system, where most of the inroads in error reduction had been made. This involved (a) developing software with more powerful pattern-matching capabilities than the CLAWS Idiomlist, and (b) carrying out a more systematic analysis of errors, to identify appropriate error-correcting rules.</p>
      
      <p>The next program, known as Template Tagger, supplements
      rather than supplants CLAWS.  It takes a CLAWS output file as
      its input, and "patches"<note place="foot">We borrow the term
      "patching" from <ref target="#refs">Brill (1992)</ref>, although
      for his tagging program the patches are discovered by an
      automatic procedure.</note> any erroneous tags it finds by using
      hand-written template rules.  Figure 1 above shows where
      Template Tagger fits in the overall tagging scheme. Effectively,
      it is an elaborate 'search and replace' tool, capable of
      matching longer-distance and more variable dependencies than is
      possible with the Idiomlist:
       
       <list> 
        <item>it can refer to information at the level of the word, or tag, or by user-defined categories grouping lexical, grammatical, semantic or other related features</item>
        
        <item>it can handle a wide and variable context window, incorporating
         <list>
          <item>repetition of the value in (a) a specified number of times, or indefinitely up to the left or right sentence boundary (or other delimiter) from any given word or tag;  and</item>
          <item>different levels of optionality: necessarily present, optional, and necessarily excluded.</item>
         </list></item></list>
      </p>
      <p>These features can best be understood by an example. In BNC1 there were quite a number of errors disambiguating prepositions from subordinating conjunctions, in connection with words like <hi rend="italic">after</hi>, <hi rend="italic">before</hi>, <hi rend="italic">since</hi> and so on. The following rule corrects many such cases from subordinating conjunction (CJS) to prepositions (PRP) tags.  It applies a basic grammatical principle that subordinating conjunctions mark the start of clauses and generally require a finite verb somewhere later in the sentence.
       
               &#9;#AFTER [CJS^PRP] PRP, ([!#FINITE_VB/VVN])16, #PUNC1
      </p>

      <p>The two commas divide the rule into three units, each
      containing a word or tag or word+tag combination.  Square
      brackets contain tag patterns, and a tag following square
      brackets is the replacement tag (ie the action part of the
      rule). #AFTER refers to a list of words like <hi rend="italic">after,
      before</hi> and <hi rend="italic">since</hi>, that have similar grammatical
      properties. These words are defined in a separate file; not all
      conjunction-preposition words are listed - <hi rend="italic">as</hi>, for
      instance, can be used elliptically, without the requirement for
      a following verb. (See Tagging Guidelines under <ref
      target="#m4as"><hi rend="italic">as</hi></ref>). The definition for #FINITE_VB
      contains a list of possible POS-tags (rather than word values),
      eg VVZ/VV0/VM0.  Finally #PUNC1 is a 'hard' punctuation boundary
      (one of . : ; ? and ! ). The patching rule can be interpreted
      as:
       'If a sequence of the following kind occurs:
        a word like <hi rend="italic">after</hi>, <hi rend="italic">before</hi> or <hi rend="italic">since</hi>,
	which CLAWS has identified as most likely being a
	subordinating conjunction, and less likely a preposition;        
        an interval of  up to 16 words, none of which has been tagged
	as a finite verb or past participle <note place="foot">The repetition value of up to 16 words was reached at by trial and error;  an occurrence of a finite verb beyond that range was rarely in the same clause as the #AFTER-type word.</note>
 (NB   [! … ] negates the tag pattern.);
        a 'hard' punctuation boundary     
        then change the conjunction tag to preposition.'
      </p>
      
      <p>The rule doesn't always work accurately, and doesn't cater for all preposition-conjunction errors. (i) It relies to a large extent on CLAWS having correctly identified finite verb tags in the right context of the preposition-conjunction; sometimes, however, a past participle is confused with a past tense form. (We therefore added VVN, ie past participle, as a possible alternative to #FINITE_VB in the second part of the pattern. The downside of this was that Template Tagger ignored some conjunction-preposition errors containing genuine use of VVN in the right context). (ii) The scope of the rule doesn't cover long sentences where more than 16 non-finite-verb words occur after the conjunction-preposition. A separate rule had to be written to handle such cases. (iii) Adverb uses of <hi rend="italic">after</hi>, <hi rend="italic">before</hi> and <hi rend="italic">since</hi> etc. need to be fixed by additional rules.</p>
      <div xml:id="targeting">
       <head>Targetting and writing the Template rules</head>
       
       <p>The Templates are targetted at the most error-prone
       categories introduced (or rather, left unresolved) by CLAWS. As
       with the preposition-conjunction example just shown, many
       disambiguation errors congregate around pairs of tags, for
       example adjective and adverb, or noun and verb. Sometimes a
       triple is involved, eg a past tense verb (<code>VVD</code>),
       past participle (<code>VVN</code>) and adjective
       (<code>AJ0</code>) in the case of <hi rend="italic">surprised</hi>. </p>
       
       <p>A small team of researchers sought out patterns in the errors by concordancing  a training corpus that contained two parallel versions of the tagging: the automatic version produced by CLAWS and a hand-corrected version, which served as a benchmark.  A concordance query of the form "tag A | tag B", would retrieve lines where the former version assigned an incorrect tag A and the latter a correct tag B. An example is shown below, in which A  is a subordinating conjunction and B a preposition.
       </p> 
        
<eg><![CDATA[
         the company which have occurred | since CJS [PRP] | the balance sheet date . 
         nd-green shirt with epaulettes . | Before CJS [PRP] | the show , the uniforms were approved by 
         rt towards the library catalogue | since CJS [PRP] | the advent of online systems . The overall
         ales . There have been no events | since CJS [PRP] | the balance sheet date which materially af
         n in demand , adding 13p to 173p | since CJS [PRP] | the end of October . Printing group Linx h
         Hugh Candidus of Peterborough . | After CJS [PRP] | the appointment of Henry of Poitou , a sel
         boys would be in the Ravenna mud | until CJS [PRP] | the spring . Our landlady obviously liked 
         ution in treatment brought about | since CJS [PRP] | the arrival of penicillin and antibiotics ]]></eg>
       <p>By working interactively with the parallel concordance,
       sorting on the tags of the immediate context, testing for
       significant collocates to the left and right, and generally
       applying his/her linguistic knowledge, the researcher can often
       detect sufficient commonality between the tagging errors to
       formulate a patching rule (or a set of rules) such as that
       shown above. It took several iterations of training and testing
       to refine the rules to a point where they could be applied by
       Template Tagger to the full corpus.<note place="foot">
Training and testing were mostly carried out on the BNC Sampler corpus of 2 million words. For less frequent phenomena we needed to use sections from the full BNC.  None of the texts used for the <ref target="#errorRates">tagging error report</ref> is included in the Sampler. </note></p>
       
       <p>It should be said that some categories of error were easier to write rules for than others. Finding productive rules for noun-verb correction was especially difficult, because of the many types of ambiguity between nouns, verb and other categories, and the widely differing contexts in which they appear. The errors and ambiguity tags associated with NN1-VVB and NN2-VVZ in BNC2 in the <ref target="#errorRates">error report</ref> testify to this problem. Here a more sophisticated lexicon, detailing the selectional restrictions of individual verbs and nouns (and  other categories) would have undoubtedly been useful. </p>
      </div>
      <div xml:id="ordereing"><head>Ordering the rules</head>
       
       <p>In some instances the ordering of rules was important. When two rules in the same ruleset compete, the longer match applies. Clashes arise in the case of the multiply ambiguous word <hi rend="italic">as</hi>, for instance. Besides the clear grammatical choices between a preposition and a complementiser introducing an adverbial clause, there are many "interfering" idiomatic uses (<hi rend="italic">as well as</hi>, <hi rend="italic">as regards</hi> etc) and elliptical uses ( <hi rend="italic">The TGV goes as fast <emph>as</emph> the Bullet train [sc.goes]</hi>). To avoid interference between the rules, we found it preferable to let an earlier pass of the rules handle more idiomatic (or exceptional) structures, and let a later pass deal with the more regular grammatical dependencies.</p>
       <p>In many rule sets, however, we found that ordering did not affect the overall result, as we tried to ensure each rule was 'true' in all cases. Since, however, more than one rule sometimes carried out the same tag change to a particular word, the system was not optimised for speed and efficiency.</p>
       
       <p>Besides the ordering of rules within rulesets, it is worth considering the placement of Template Tagger within the tagging schema (Figure 1).  Ideally, it would be sensible to exploit the full pattern-matching functionality of the Template Tagger earlier in the schema, using it in place of the CLAWS Idiomlist not just after statistical disambiguation, where it is undoubtedly necessary, but also before it. In this way Template Tagger could have precluded much unnecessary ambiguity passing to Stage C. above. The reason we did not do this was pragmatic, that TT was in fact developed as a general-purpose annotation tool (See <ref target="#refs">Fligelstone, Pacey and Rayson 1997</ref>), and not exclusively for the POS-tagging of BNC2. In future versions of the tagging software we hope to integrate Template Tagger more fully with CLAWS.</p>
       
       
      </div>
      </div> <!-- end E -->
          <div xml:id="postproc">
     <head>F. Postprocessing, including Ambiguity tagging</head>
     
     <p>The post-processing phase has the task of producing output in the form in which the user is going to find it most usable. 
      
      <list>
       <item>The text is produced in a horizontal format, so that it can be read from left to right across the page or across the screen.</item>
       <item>The tags are enclosed in angle-brackets as follows: <gi>NN1</gi> according to the standard TEI-based CDIF mark-up of the British National Corpus.</item>
       <item>Normally the word will be output with a single tag - the one which CLAWS4 calculates to be most probable.</item>
       <item><emph>"Ambiguity tags"</emph> (such as <gi>NN1-AJ0</gi>) are output if the difference between the probability of the first tag and of the second fails to reach a pre-decided threshold.</item>
      </list></p>
     
     <p>The final phase, "ambiguity tagging", merits a little further discussion. The requirement for such tags is clear when one observes that even using Template Tagger on top of CLAWS, there remains a residuum of error, around 2%, in the corpus. By permitting ambiguity tags we are effectively able to "hedge" in many instances that might otherwise have counted as errors - improving the chances of retrieving a particular tag, but at the cost of retrieving other tags as well. We considered that a reasonable goal would be to employ sufficient ambiguity tags to achieve an overall error rate for the corpus of 1%.</p>
     
     <p>Because CLAWS's reliability in statistical disambiguation varies according to the POS-tags involved, we calculated the thresholds for application of ambiguity tags separately for each relevant tag-pair  A-B (where A is CLAWS's first-choice and B its second-choice tag). First, the tag-pairs were chosen according to their error frequencies in a training corpus of 100,000 words. The proportion of A-B errors to the total number of errors indicated how many errors of that type would be allowed in order to achieve the 1% error rate overall; we will refer to this figure as "the target number of errors" for A-B. We then
      <list type="ordered">
       <item>collected each instance of A-B error, noting the difference in probability score between A and B.</item> 
       <item>plotted each error against the probability difference</item>
        <item>found the threshold on the difference axis that would yield the target number of errors. Below this threshold each instance of A-B would be converted to an ambiguity tag.</item>
      </list></p>
     
     <p>As we report under <ref target="#errorRates">Error
     rates</ref>, the BNC in fact contains a higher error rate than
     1%. This is because some thresholds applied at the 1% rate
     incurred a very high frequency of potential ambiguity tags: we
     hand-adjusted such thresholds if permitting a slight rise in
     errors led to a substantial reduction in the number of
     ambiguities. Further comments on stages E. and F. can be found in <ref target="#refs">Smith 1997</ref>.</p>
     
   </div>
     
   <div xml:id="extra-annot">
    <head>Additional annotation in BNC XML</head>
 <p>As noted above, the linguistic annotation of the corpus was
    enhanced in the BNC XML edition in three respects:
<list>
<item>multiwords and their constituent items are explicitly tagged
using the <gi>mw</gi> and <gi>w</gi> XML elements</item>
<item>an additional wordclass scheme, using a much simplified version
of the C5 tagset was deployed</item>
<item>lemmatization of each word was carried out automatically on the
basis of manually-defined rules.</item>
</list>
    </p>
<p>The simplified wordclass scheme used for the second of these
enhancements is listed in <ptr target="#klettpos"/> of the manual, where the
mapping between these values and the C5 tags from which they are
derived is also specified.</p>

<p>The lemmatization procedure adopted derives ultimately from work
reported in <ref target="#refs">Beale 1987</ref>, as subsequently
refined by others at Lancaster, and applied in a range of projects
including the JAWS program (<ref target="#refs">Fligelstone et al
1996</ref>) and the book <hi>Word Frequencies in Written and Spoken
English</hi> (<ref target="#refs">Leech et al 2001</ref>). The basic
approach is to apply a number of morphological rules, combining simple
POS-sensitive suffix stripping rules with a word list of common
exceptions.</p>
<p>This process was carried out during the XML conversion, using code and a set of rules files kindly supplied by Paul Rayson. </p>
   </div> 


<!-- end XML -->
<!--
  <div xml:id="bnc2ackno"><head>Credits and acknowledgements</head>
  <p>The authors of the manual are Geoffrey Leech and Nicholas Smith (Lancaster University).</p>
   <p>
   The original grammatical tagging of the BNC (version 1.0) was undertaken by a team at UCREL, Lancaster led by Roger Garside and Geoffrey Leech. The main members of the team were: Michael Bryant, Elizabeth Eyes, Mary Hodges and Nicholas Smith. Additional members were Tom Barney, Jean Forrest, Mary Kinane and Xungfeng Xu.
   </p><p>
   The Corpus was automatically tagged by the Claws4 tagging software, originally authored by Roger Garside and Ian Marshall. The tagger was thoroughly improved and adapted to the large-scale task of tagging the BNC by Roger Garside. Michael Bryant wrote and implemented support software.
   </p><p>
   After the completion of the BNC, a phase of tagging improvement was undertaken with the funding of the Engineering and Physical Sciences Research Council (Research Grant No. GR/F 99847). The enhancement project was led by Geoffrey Leech, Roger Garside and Tony McEnery. The main objective of this improvement phase was to correct as many tagging errors as possible. For this purpose, an enhanced version of Claws4 was run over the whole corpus. In addition, a new tool was developed (the Template Tagger) for ‘patching’ the corpus in such a way as to eliminate further sets of errors by rule. This tool was developed by Michael Pacey, building on a prototype written by Steven Fligelstone. The research team working on tagging improvement was Nicholas Smith (lead researcher), Martin Wynne and Paul Baker.
   </p><p>
   In addition, work on manual tagging error correction has been undertaken by Mary Hodges and Jeremy Bateman.</p></div>

--></div></div></div>


